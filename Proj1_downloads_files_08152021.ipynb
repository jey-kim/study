{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GEOS_Logo.png\" width=\"700\" />\n",
    "\n",
    "# Step 1 : <font color=blue>\"download_files.ipynb\"</font>\n",
    "#### Aug 15, 2021  <font color=red>(still working)</font> \n",
    "##### Jeonghyeop Kim (jeonghyeop.kim@gmail.com)\n",
    "\n",
    "\n",
    "\n",
    "> list_full.dat (904 stations) and list_extra.dat (extra 3 stations) \\\n",
    "> total is 907 \\\n",
    "> At some point, a code that downloads (a)a station ID list and (b)a list of their coordinates will be ready \\\n",
    "> And then it will count how many stations, this GPS2FNL algorithm will process and pass this info to the later codes. \\\n",
    "> metadata is needed\n",
    "\n",
    "> input is : list_default.dat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`GPS data processed by the NGL is available at:`**  [click here](http://geodesy.unr.edu)\n",
    "\n",
    "> On the right side of the website, find <font color=red>\"Downloadable Lists of GPS Data Holdings:\"</font> \\\n",
    "> This algorithm uses data from \"stations with 24 hour sample rate solutions, final orbits, 2 week latency.\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask if a user wants all stations (except MAGNET) or NOTA stations \n",
    "# If one choose to use all stations, the vertical position analysis must be done individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location Boundary\n",
    "lon_min=235.43\n",
    "lon_max=246.99\n",
    "lat_min=31.31\n",
    "lat_max=42.99\n",
    "\n",
    "# Later in this code, the threshold of minimum daily position estimates will be determined. \n",
    "# > Minimum number of daily position estimates:\n",
    "# >> if you want the NOTA stations, threshold_num = 0 (to include all NOTA stations regardless of data)\n",
    "# >>> Other than that, threshold_num = 200 ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Read the station list\n",
    "> url_lists=\"http://geodesy.unr.edu/NGLStationPages/DataHoldings.txt\"\n",
    "\n",
    "2. Download metadate (discontinuous steps)\n",
    "> url_metadata=\"http://geodesy.unr.edu/NGLStationPages/steps.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of GPS stations \n",
    "url_list=\"http://geodesy.unr.edu/NGLStationPages/DataHoldings.txt\" # URL\n",
    "list_file=\"list_NGL.txt\" # file name\n",
    "\n",
    "# metadata for steps\n",
    "url_metadata=\"http://geodesy.unr.edu/NGLStationPages/steps.txt\" # URL\n",
    "metadata_file=\"steps_NGL.txt\" # file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded a GPS list and metadata for steps\n"
     ]
    }
   ],
   "source": [
    "# Download the list of GPS stations (final orbits) and metadata \n",
    "urllib.request.urlretrieve(url_list, list_file)\n",
    "urllib.request.urlretrieve(url_metadata, metadata_file)\n",
    "print(\"Downloaded a GPS list and metadata for steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the station list.\n",
    "df_original_list=pd.read_csv(list_file ,header=None, sep=r'(?:,|\\s+)', \n",
    "                comment='#', engine='python',\n",
    "                names=['Sta','lat','lon','3','4','5','6','7','8','9','NumSol','11','12','13'])\n",
    "\n",
    "\n",
    "# Here the first 4 columns will be used.\n",
    "df_four_cols=df_original_list.loc[1:len(df_original_list),['Sta','lat','lon','NumSol']] #first three columns\n",
    "df_four_cols=df_four_cols.reset_index(drop=True)\n",
    "\n",
    "# str to float\n",
    "df_four_cols['lon'] = df_four_cols['lon'].astype(float)\n",
    "df_four_cols['lat'] = df_four_cols['lat'].astype(float)\n",
    "df_four_cols['NumSol'] = df_four_cols['NumSol'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > If you want to include all GPS stations in California, type 'yes'.\n",
      " >> If you type 'no', only NOTA stations will be used.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " type 'yes' or 'no'  yes\n"
     ]
    }
   ],
   "source": [
    "# While the user input is not either yes or no, this loop will repeat\n",
    "\n",
    "while True:      \n",
    "    print(\" > If you want to include all GPS stations in California, type 'yes'.\")\n",
    "    print(\" >> If you type 'no', only NOTA stations will be used.\")\n",
    "    YESorNO=input(\" type 'yes' or 'no' \")\n",
    "    YESorNO=YESorNO.lower()\n",
    "    \n",
    "    while YESorNO not in (\"yes\",\"no\"):\n",
    "        print(\"*** Please type 'yes' or 'no' ***\")\n",
    "        YESorNO=input(\" type 'yes' or 'no' \")\n",
    "        YESorNO=YESorNO.lower()\n",
    "        \n",
    "    if YESorNO == \"no\" or YESorNO == \"yes\":\n",
    "        break \n",
    "        #break the while loop\n",
    "         \n",
    "\n",
    "# YES! => all stations except MAGNET stations will be included\n",
    "if YESorNO.startswith('y'): \n",
    "    # Select stations within the region of interest.\n",
    "    # > lon_min,lon_max,lat_min,lat_max must be defined.\n",
    "    \n",
    "    threshold_num=200\n",
    "    df_interest=df_four_cols.loc[(df_four_cols['lat'] >= lat_min)\\\n",
    "                            & (df_four_cols['lat'] <= lat_max)\\\n",
    "                            & (df_four_cols['lon'] >= lon_min)\\\n",
    "                            & (df_four_cols['lon'] <= lon_max)\\\n",
    "                            & (df_four_cols['NumSol'] >= threshold_num)]\n",
    "\n",
    "    df_interest=df_interest.reset_index(drop=True)\n",
    "    \n",
    "    #REMOVE MAGNET STATIONS FROM THE LIST\n",
    "    URL_MAGNET=\"http://geodesy.unr.edu/magnet/Table2web.html\"\n",
    "    df_MAGNET=pd.read_html(URL_MAGNET, header=1, flavor = 'bs4')\n",
    "    df_MAGNET=df_MAGNET[0]\n",
    "    df_MAGNET.columns=['Sta','1','2','3','4','5','6']\n",
    "    df_no_MAGNAT = df_interest[~df_interest['Sta'].isin(df_MAGNET['Sta'])].reset_index(drop=True)\n",
    "    df_final = df_no_MAGNAT\n",
    "    \n",
    "# NO!\n",
    "else: \n",
    "    threshold_num=0\n",
    "    df_interest=df_four_cols.loc[(df_four_cols['lat'] >= lat_min)\\\n",
    "                            & (df_four_cols['lat'] <= lat_max)\\\n",
    "                            & (df_four_cols['lon'] >= lon_min)\\\n",
    "                            & (df_four_cols['lon'] <= lon_max)\\\n",
    "                            & (df_four_cols['NumSol'] >= threshold_num)]\n",
    "\n",
    "    df_interest=df_interest.reset_index(drop=True)\n",
    "    list_default=\"list_default.dat\"\n",
    "    df_default=pd.read_csv(list_default, header=None, names=['Sta'])\n",
    "    df_NOTA = df_interest[df_interest['Sta'].isin(df_default['Sta'])].reset_index(drop=True)\n",
    "    df_final = df_NOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station=df_final.loc[:,['Sta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coor=df_final.loc[:,['lon','lat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_station' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-43d64196ac10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#SAVE FILES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# coordinates and station list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_station\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'station_list_test.dat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_coor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coordinate_list_test.dat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_station' is not defined"
     ]
    }
   ],
   "source": [
    "#SAVE FILES \n",
    "# coordinates and station list\n",
    "df_station.to_csv('station_list_test.dat',header=None, index=None,sep=' ',float_format='%g')\n",
    "df_coor.to_csv('coordinate_list_test.dat',header=None, index=None, sep=' ',float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
