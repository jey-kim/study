{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GEOS_Logo.png\" width=\"700\" />\n",
    "\n",
    "# Step 6: <font color=blue>\"correct_steps.ipynb\"</font>\n",
    "#### August 1, 2021  <font color=red>(still working)</font> \n",
    "##### Jeonghyeop Kim (jeonghyeop.kim@gmail.com)\n",
    "\n",
    "> input file(s)  : **`time_vector.dat`, `steps.txt` ,`list_full.dat` , `list_extra.dat` & `edited_i`** \\\n",
    "> output file(s) : **`edited_i_corrected`** \\\n",
    "> module(s) used : **`ismember.py`**\n",
    "\n",
    "0. This code is a part of GPS2FNL process \n",
    "1. A GNSS timeseries for years usually has a few discontinuous steps related to maintenance of equipments\n",
    "2. The Nevada Geodetic Lab provides metadata that provide information about these two types of steps. \n",
    "> http://geodesy.unr.edu/NGLStationPages/steps.txt (download this file in the begining of the master shell script)\n",
    "3. This code downloads metadata and will uses to correct listed steps. \n",
    "4. Step correction algorithm is proposed by *Johnson et al., 2021 (Earth and Space Science)*\n",
    "5. This algorithm does NOT correct for coseismic signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from ismember import ismember\n",
    "\n",
    "time_window_size = 4; \n",
    "# 4-month moving time-window\n",
    "time_window_size = time_window_size*30 + 35 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a list of all stations (e.g., 907 stations for california)\n",
    "> For some reasons, two list files exist (7/30/2021) \n",
    "> change this later after the STEP 1 and STEP 2 codes are ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of stations for the analysis is 907\n"
     ]
    }
   ],
   "source": [
    "list1 = \"list_full.dat\"\n",
    "df_list1=pd.read_csv(list1, header=None)\n",
    "\n",
    "list2 = \"list_extra.dat\"\n",
    "df_list2=pd.read_csv(list2, header=None)\n",
    "\n",
    "frames=[df_list1,df_list2]\n",
    "df_list=pd.concat(frames,ignore_index=True) #combine two DFs as a DF\n",
    "\n",
    "N_list = len(df_list) #length of the combine Df?\n",
    "print(\"the total number of stations for the analysis is %i\" % N_list)\n",
    "df_list.columns=['stID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read 'time_vector.dat' & Define datenum\n",
    "> Here **`datenum`** will be defined as **df_time_vector.index+1**. \\\n",
    "> This provides consecutive integers that are equivalent to all of the daily time steps within the analysis. \\\n",
    "> These integers serve as time flags, and they will be used in this code for regressions for functions of time. \\\n",
    "> For instance, 2 = 2006-01-02; 3 = 2006-01-03; 5658 = 2021-06-29; ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps before 20060101 and after 20210630 will be ignored\n"
     ]
    }
   ],
   "source": [
    "inputfile = 'time_vector.dat'\n",
    "df_full_time_vector = pd.read_csv(inputfile,header=None)\n",
    "df_full_time_vector.columns=['date']\n",
    "df_full_time_vector['datenum'] = df_full_time_vector.index + 1 #consecutive integers\n",
    "\n",
    "earliest_time=df_full_time_vector.loc[0,['date']]\n",
    "earliest_time=int(earliest_time)\n",
    "lastest_time=df_full_time_vector.iloc[-1,0]\n",
    "lastest_time=int(lastest_time)\n",
    "print(\"steps before %i and after %i will be ignored\" % (earliest_time,lastest_time))\n",
    "\n",
    "\n",
    "full_date_list=df_full_time_vector['date'].tolist() # a list\n",
    "full_date_df=df_full_time_vector['date'] # a df\n",
    "full_datenum_list=df_full_time_vector['datenum'].tolist() # a list\n",
    "full_datenum_df=df_full_time_vector['datenum'] # a df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. READ metadata and separate them into \n",
    ">(1) equipment-related steps : `df_steps_man_made_interest` \\\n",
    ">(2) coseismic steps : `df_steps_earthquakes_interest` \\\n",
    ">This algorithm only deals with **steps within the analysis time** defined in `time_vector.dat`\n",
    "\n",
    "**`This code also finds datenum of steps!`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = \"steps.txt\" #file name\n",
    "df_metadata=pd.read_csv(metadata, header=None, names=list('0123456'), sep=r'(?:,|\\s+)', \\\n",
    "                        comment='#', engine='python')\n",
    "## steps.txt is in an irregular shape\n",
    "## 'names=list('0123456')' is to fill empty spots with NaN \n",
    "\n",
    "df_steps_man_made = df_metadata[df_metadata['2'] == 1]\n",
    "df_steps_man_made = df_steps_man_made[['0', '1', '2', '3']]\n",
    "df_steps_man_made.columns=['stID','time','flag','log'] #time is in yyMMMdd format\n",
    "\n",
    "## date format conversion\n",
    "date_old = df_steps_man_made.time.tolist() # A DataFrame to a list\n",
    "date_new = pd.to_datetime(date_old, format='%y%b%d').strftime('%Y%m%d') # convert date format\n",
    "df_steps_man_made.loc[:,'time'] = date_new # replaces with the new date  in YYYYMMDD\n",
    "df_steps_man_made['time']=df_steps_man_made['time'].astype(int) #str to int\n",
    "\n",
    "\n",
    "df_steps_man_made_interest=df_steps_man_made.loc[(df_steps_man_made['time'] >= earliest_time) & (df_steps_man_made['time'] <= lastest_time)] \n",
    "df_steps_man_made_interest=df_steps_man_made_interest.reset_index(drop=True)\n",
    "\n",
    "## ADD datenum to df_steps_man_made_interest\n",
    "\n",
    "man_time_list=df_steps_man_made_interest.time.tolist()# To list \n",
    "man_time_index=ismember(man_time_list,full_date_list) # Find time index \n",
    "man_new_time_vector = df_full_time_vector.iloc[man_time_index] # Find values corresponding to the time index\n",
    "man_new_time_vector = man_new_time_vector.reset_index(drop=True) # Reset index\n",
    "    \n",
    "df_steps_man_made_interest['datenum']=man_new_time_vector['datenum'] # add equivalent datenum \n",
    "    ## (datenum will be used to match with steps and will be used for inversions)\n",
    "df_steps_man_made_interest=df_steps_man_made_interest[['stID','time','datenum','flag','log']]\n",
    "    ## change column orders    \n",
    "    \n",
    "#----------------------------------------------------------------------------------------------#   \n",
    "\n",
    "################################################################################################     \n",
    "#######################           *v1.0.0.*       ##############################################\n",
    "################################################################################################ \n",
    "###############  This algorithm does NOT correct co-seismic steps.  ############################ \n",
    "###############  But one can modify the code to correct such steps. ############################ \n",
    "###############  Now the coseismic-step data will be just saved as  ############################ \n",
    "###############  in a DataFrame 'df_steps_earthquakes_interest'.    ############################ \n",
    "###############                                                     ############################ \n",
    "###############  You can make a step list made of both equipment-   ############################ \n",
    "###############  related and earthquakes, sort ascending in time,   ############################ \n",
    "###############  and then correct in the order of time later.       ############################ \n",
    "###############  Save step flag {1=man-made; 2=earthquake} together ############################ \n",
    "###############  because you may need two different ways to correct ############################ \n",
    "###############  steps depending on their types!                    ############################ \n",
    "################################################################################################ \n",
    "#######################         J.K. (yy-mm-dd)       ##########################################\n",
    "################################################################################################ \n",
    "\n",
    "## for column names, see the readme file (http://geodesy.unr.edu/NGLStationPages/steps_readme.txt)\n",
    "df_steps_earthquakes = df_metadata[df_metadata['2'] == 2].reset_index(drop=True)\n",
    "df_steps_earthquakes.columns=['stID','time','flag','threshold','distance','mag','eventID'] \n",
    "## time is in yyMMMdd format\n",
    "## date format conversion\n",
    "date_old2 = df_steps_earthquakes.time.tolist() # A DataFrame to a list\n",
    "date_new2 = pd.to_datetime(date_old2, format='%y%b%d').strftime('%Y%m%d') # convert date format\n",
    "df_steps_earthquakes.loc[:,'time'] = date_new2 # replaces with the new date  in YYYYMMDD \n",
    "df_steps_earthquakes['time']=df_steps_earthquakes['time'].astype(int) #str to int\n",
    "\n",
    "df_steps_earthquakes_interest=df_steps_earthquakes.loc[(df_steps_earthquakes['time'] >= earliest_time) & (df_steps_earthquakes['time'] <= lastest_time)] \n",
    "df_steps_earthquakes_interest=df_steps_earthquakes_interest.reset_index(drop=True)\n",
    "\n",
    "## ADD datenum to df_steps_earthquakes_interest\n",
    "EQ_time_list=df_steps_earthquakes_interest.time.tolist()# To list \n",
    "EQ_time_index=ismember(EQ_time_list,full_date_list) # Find time index \n",
    "EQ_new_time_vector = df_full_time_vector.iloc[EQ_time_index] # Find values corresponding to the time index\n",
    "EQ_new_time_vector = EQ_new_time_vector.reset_index(drop=True) # Reset index\n",
    "    \n",
    "df_steps_earthquakes_interest['datenum']=EQ_new_time_vector['datenum'] # add equivalent datenum \n",
    "    ## (datenum will be used to match with steps and will be used for inversions)\n",
    "df_steps_earthquakes_interest=df_steps_earthquakes_interest[['stID','time','datenum','flag','threshold','distance','mag','eventID']]\n",
    "    ## change column orders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correct steps! \n",
    "> (a) Read input data **`edited_i`** \\\n",
    "> (b) Find and add **`datenum`** for the time-axis of the input data \\\n",
    "> (c) Check if the target station has unwanted steps. \n",
    ">> if no, continue the for loop \\\n",
    ">> if yes, keep going \n",
    "\n",
    "> (d) Save datenum for all steps \\\n",
    "> (e) For loop j in range(steps) \\\n",
    "> (f) Corrections! \\\n",
    "> (g) PLOT or NOT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case3\n",
      "case3\n"
     ]
    }
   ],
   "source": [
    "## Correcting the steps!\n",
    "\n",
    "for i in range(90,91): #range(N_list) later\n",
    "    \n",
    "## (a) Read input data 'edited_i'\n",
    "    target_data=\"edited_\"+str(i+1)\n",
    "    df_GPS=pd.read_csv(target_data, header=None, sep=' ')\n",
    "    df_GPS.columns=['time','lon','lat','e','n','z','se','sn','sz','corr_en','flag']\n",
    "    \n",
    "    station=df_list.loc[i,['stID']].to_string(index=False)\n",
    "    SearchSt=station[1:5] # a space in the first byte of the string\n",
    "    #SearchSt is the target station for corrections\n",
    "    \n",
    "## (b) Add datenum for the input data 'edited_i'    \n",
    "    time_list=df_GPS.time.to_list() #to list    \n",
    "    time_index=ismember(time_list,full_date_list) #find time index \n",
    "    \n",
    "    #Check if everything is okay\n",
    "    if len(time_index)-len(df_GPS) != 0:\n",
    "        print(\"something is wrong\")    \n",
    "    new_time_vector =df_full_time_vector.iloc[time_index]\n",
    "    \n",
    "    new_time_vector=new_time_vector.reset_index() # reset index\n",
    "    \n",
    "    df_GPS['datenum']=new_time_vector['datenum'] # add equivalent datenum \n",
    "    #(datenum will be used to match with steps and will be used for inversions)\n",
    "    df_GPS=df_GPS[['time','datenum','lon','lat','e','n','z','se','sn','sz','corr_en','flag']]\n",
    "    #change column orders\n",
    "    \n",
    "    \n",
    "    # Unit [m] to [mm]\n",
    "    df_GPS.e = df_GPS.e*1000\n",
    "    df_GPS.n = df_GPS.n*1000\n",
    "    df_GPS.z = df_GPS.z*1000\n",
    "    df_GPS.se = df_GPS.se*1000\n",
    "    df_GPS.sn = df_GPS.sn*1000\n",
    "    df_GPS.sz = df_GPS.sz*1000\n",
    "    \n",
    "    \n",
    "    \n",
    "## (c) Check is the target station with unwatned step(s) \n",
    "## > if no, continue the for loop\n",
    "## >> if yes, keep going \n",
    "\n",
    "    itemindex = np.where(df_steps_man_made_interest['stID']==SearchSt) # similar to find() in MATLAB\n",
    "    HowManySteps=itemindex[0].size  # the number of steps\n",
    "    \n",
    "    if HowManySteps==0: # No step      \n",
    "        continue   \n",
    "    else: # step(s) exist\n",
    "        event_idx = itemindex[0]\n",
    "\n",
    "## (d) Save datenum for all steps \n",
    "\n",
    "        all_datenum = df_steps_man_made_interest.datenum\n",
    "        event_datenum = all_datenum.iloc[event_idx]\n",
    "        event_datenum = pd.unique(event_datenum) \n",
    "        # In a day, more than a job can be done.\n",
    "        # In this case, the steps.txt saves all the jobs in multiple logs.\n",
    "        # But the date in the logs are the same. \n",
    "        # Here, the code gets rid of all the overlaps\n",
    "\n",
    "        N_events = len(event_datenum) #How many steps without counting multiple times for overlapped steps\n",
    "        \n",
    "## (e) For loop j in range(N_events)\n",
    "        for j in range(N_events):\n",
    "            step_standards=event_datenum[j]\n",
    "\n",
    "            before_step = list(range(step_standards-14,step_standards)) #14 days before the step (a list)\n",
    "            after_step = list(range(step_standards+1,step_standards+15)) #14 days after the step (a list)\n",
    "            #These are in datenum \n",
    "            \n",
    "            data_datenum = df_GPS.datenum       \n",
    "            date_before=ismember(before_step,data_datenum) \n",
    "            date_after=ismember(after_step,data_datenum)\n",
    "            #find the same datenum in the data, and give the indices!\n",
    "            \n",
    "            idx_before=[x for x in date_before if x == x] # get rid of float('NaN') from the list\n",
    "            idx_after=[x for x in date_after if x == x] # get rid of float('NaN') from the list\n",
    "            \n",
    "\n",
    "## (f) Obtain before_step and after_step (14 days for each)\n",
    "## > 4 cases. \n",
    "\n",
    "\n",
    "## >> (  i) len(idx_before) <  10 and len(idx_after) >= 10\n",
    "            if len(idx_before) < 10 and len(idx_after) >= 10:\n",
    "                \n",
    "                # case1: fewer than 10 position estimates are available before the step\")\n",
    "                # A linear fit will be performed to fill the gap using the time series \n",
    "                # of one-year period before the step. \n",
    "                # If fewer than 250 position estimates are available over the year period,\n",
    "                # 5 month positions before the step will be removed. \n",
    "                # WHY 5 months? The default of the algorithm uses 4-month moving time window\n",
    "                # to obtain seasonal strain. \n",
    "                \n",
    "                One_year_before_step = list(range(step_standards-365,step_standards)) # one year before the step\n",
    "                date_one_year_before=ismember(One_year_before_step,data_datenum)\n",
    "                idx_one_year_before=[x for x in date_one_year_before if x == x]\n",
    "            \n",
    "                if len(idx_one_year_before) < 250:\n",
    "                    Time_window_size_before = list(range(step_standards-Time_window_size_before,step_standards))\n",
    "                    #time_window_size = 4*30 + 35 = ~5 months\n",
    "                    date_time_window_size_before=ismember(Time_window_size_before,data_datenum)\n",
    "                    idx_time_window_size_before = [x for x in date_time_window_size_before if x == x]\n",
    "                    df_GPS=df_GPS.drop(idx_time_window_size_before) #drop the data. #make sure later you need to reset the index of DF!\n",
    "                    \n",
    "                else:\n",
    "                    # Linear fit will be performed.                 \n",
    "                    t=df_GPS.datenum[idx_one_year_before] \n",
    "                    e=df_GPS.e[idx_one_year_before]\n",
    "                    n=df_GPS.n[idx_one_year_before]\n",
    "                    z=df_GPS.z[idx_one_year_before]\n",
    "                    \n",
    "                    se=df_GPS.se[idx_one_year_before]\n",
    "                    sn=df_GPS.sn[idx_one_year_before]\n",
    "                    sz=df_GPS.sz[idx_one_year_before]\n",
    "                    \n",
    "                    inv_se = 1/se \n",
    "                    inv_sn = 1/sn\n",
    "                    inv_sz = 1/sz\n",
    "                    \n",
    "                    We = pd.DataFrame(np.diag(inv_se),index=inv_se.index,columns=inv_se.index) #1/error diagonal matrix\n",
    "                    Wn = pd.DataFrame(np.diag(inv_sn),index=inv_sn.index,columns=inv_sn.index) #1/error diagonal matrix\n",
    "                    Wz = pd.DataFrame(np.diag(inv_sz),index=inv_sz.index,columns=inv_sz.index) #1/error diagonal matrix\n",
    "\n",
    "                    \n",
    "                    Ge = t\n",
    "                    ###HERE\n",
    "                    \n",
    "                \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "## >> ( ii) len(idx_before) >= 10 and len(idx_after) < 10            \n",
    "            elif len(idx_before) >= 10 and len(idx_after) < 10:\n",
    "                print(\"case2\")\n",
    "                \n",
    "                \n",
    "                \n",
    "                        \n",
    "\n",
    "## >> (iii) len(idx_before) >= 10 and len(idx_after) >= 10\n",
    "            elif len(idx_before) >= 10 and len(idx_after) >= 10:\n",
    "                print(\"case3\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "## >> ( iv) len(idx_before) <  10 and len(idx_after) <  10\n",
    "            elif len(idx_before) < 10 and len(idx_after) < 10:\n",
    "                print(\"case4\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            else:\n",
    "                print(\"WARNING!\")\n",
    "            \n",
    "## (g) Plot the time-series and check if the correction works properly. \n",
    "## > Make a plot on and off flag \n",
    "## >> If this code tries to plot 100 time series, it would be very slow to do so ** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1535                                                 1620\n",
       "1536                                                 1621\n",
       "1537                                                 1622\n",
       "1538                                                 1623\n",
       "1539                                                 1624\n",
       "                              ...                        \n",
       "1882                                                 1967\n",
       "1883                                                 1968\n",
       "1884                                                 1969\n",
       "1885                                                 1970\n",
       "ones    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "Name: datenum, Length: 352, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1535    1670\n",
       "1536    1671\n",
       "1537    1672\n",
       "1538    1673\n",
       "1539    1674\n",
       "        ... \n",
       "1881    2016\n",
       "1882    2017\n",
       "1883    2018\n",
       "1884    2019\n",
       "1885    2020\n",
       "Name: datenum, Length: 351, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CVHS'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SearchSt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HowManySteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_datenum = df_GPS.datenum       \n",
    "# IDX_event_data_overlap=ismember(event_datenum,data_datenum) # Find if we have position estimates\n",
    "# cleanedList = [x for x in IDX_event_data_overlap if x == x] # get rid of float('NaN') from the list\n",
    "# print(IDX_event_data_overlap)\n",
    "\n",
    "# df_GPS.loc[cleanedList]\n",
    "# drop at the end of this algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
