{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GEOS_Logo.pdf\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step **8** of **`G2FNL`**: <font color=blue>\"remove_outliers.ipynb\"</font>\n",
    "#### Oct 8, 2021  <font color=red>(v. working)</font>\n",
    "##### Jeonghyeop Kim (jeonghyeop.kim@gmail.com)\n",
    "\n",
    "> input files: **`zeroFilled_i`**, **`days_per_month.dat`**, **`station_list_full.dat`**,  **`steps.txt`**, and **`time_vector.dat`** \\\n",
    "> output files: **`outlierRemoved_i`** \n",
    "\n",
    "\n",
    "0. This code is a part of GPS2FNL process \n",
    "1. It will get rid of outliers.  \n",
    "> Position data for each month will be treated as a set. \\\n",
    "> The code will fit a linear line to each month and then subtract this model from the data. \\\n",
    "> Perform a simple statistical analysis for the residual. \\\n",
    "> Outliers for each month are defined as any data outside of the tolerance level. \\\n",
    "> The default tolerance level is +/- 3 sigma.\n",
    "2. Potential issues: \n",
    "> There exist some stations that still show problematic outliers after this algorithm applied. \\\n",
    "> Possibly some post-seismic signals are identified as outliers and removed, which means a loss of interesting signal. \\\n",
    "> Maybe pass the month if an earthquake occurred in that month?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "Do NOT run this code twice without re-starting the kernel\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jkim/main/GPS2FNL_2021/summer_project_2021'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir=os.getcwd()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. read files for (1) Number of Date per each month \n",
    "#               and (2) Number of Stations \n",
    "#               and (3) time_vector.dat for the first and end dates of the analysis\n",
    "#               and (4) earthquake-related steps\n",
    "\n",
    "\n",
    "#############################################\n",
    "#(1)\n",
    "datefile = 'days_per_month.dat'\n",
    "dateNvec = pd.read_csv(datefile, sep = ' ', header = None)\n",
    "dateNvec.columns = ['NofD']\n",
    "\n",
    "#############################################\n",
    "#(2)\n",
    "list_full = \"station_list_full.dat\"\n",
    "df_list=pd.read_csv(list_full, header=None)\n",
    "df_list.columns=['StID']\n",
    "N_list = len(df_list) \n",
    "\n",
    "\n",
    "#############################################\n",
    "#(3)\n",
    "timefile = 'time_vector.dat'\n",
    "df_time=pd.read_csv(timefile, header=None)\n",
    "startDateAnalysis=int(df_time.iloc[0])\n",
    "endDateAnalysis=int(df_time.iloc[-1])\n",
    "##########################################################################################\n",
    "#(4)\n",
    "metadata = \"steps.txt\" #file name\n",
    "df_metadata=pd.read_csv(metadata, header=None, names=list('0123456'), sep=r'(?:,|\\s+)', \\\n",
    "                        comment='#', engine='python')\n",
    "## steps.txt is in an irregular shape\n",
    "## 'names=list('0123456')' is to fill empty spots with NaN \n",
    "df_steps_earthquakes = df_metadata[df_metadata['2'] == 2].reset_index(drop=True)\n",
    "df_steps_earthquakes.columns=['stID','time','flag','threshold','distance','mag','eventID'] \n",
    "#The step data has a time column in the form of yyMMMdd \n",
    "date_old = df_steps_earthquakes.time.tolist() # A DataFrame to a list\n",
    "date_new = pd.to_datetime(date_old, format='%y%b%d').strftime('%Y%m%d') # convert date format\n",
    "df_steps_earthquakes.loc[:,'time'] = date_new # replaces with the new date  in YYYYMMDD\n",
    "df_steps_earthquakes['time']=df_steps_earthquakes['time'].astype(int) #str to int\n",
    "df_steps_earthquakes = df_steps_earthquakes[(df_steps_earthquakes['time']>=startDateAnalysis) & \\\n",
    "                                            (df_steps_earthquakes['time']<=endDateAnalysis)]\n",
    "df_steps_earthquakes = df_steps_earthquakes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jkim/main/GPS2FNL_2021/summer_project_2021/data/processing'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_dir = os.path.join(current_dir, 'data', 'processing')\n",
    "os.chdir(processing_dir) # cp to processing directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`IDENTIFY AND ELIMINATE OUTLIERS`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n",
      "work from here\n"
     ]
    }
   ],
   "source": [
    "N_months = len(dateNvec) # How many months for the time period of interest?\n",
    "\n",
    "##############################################\n",
    "# STEP 1: Read data files station by station #\n",
    "##############################################\n",
    "\n",
    "column_names = ['datenum','date','lon','lat','ue','un','uz','se','sn','sz','corr_en','flag']\n",
    "\n",
    "for i in range(0,1):  # Later, replace range(0,1) with range(N_list)\n",
    "\n",
    "    inputfile = \"zeroFilled_\"+str(i+1) #input_file = zeroFilled_\"$i\"\n",
    "    df_input=pd.read_csv(inputfile,sep=' ',header=None)   \n",
    "    df_input = df_input.reset_index() #Index column will be added and will be used as 'datenum' consecutive integers.\n",
    "    df_input.columns = column_names\n",
    "    df_input.loc[:,['datenum']]=df_input.loc[:,['datenum']]+1 #datenum starts from 1 instead of 0\n",
    "    \n",
    "    stationID=df_list.loc[i,['StID']]\n",
    "    stationID=stationID.tolist()[0]\n",
    "\n",
    "##############################################\n",
    "# STEP 2: READ DATA MONTH BY MONTH!          #\n",
    "##############################################\n",
    "\n",
    "    FirstMonth = 0\n",
    "    for j in range(N_months):\n",
    "        date_for_the_month=int(dateNvec.iloc[j])\n",
    "        LastMonth = FirstMonth + date_for_the_month\n",
    "        df_month = df_input.loc[FirstMonth:LastMonth-1,:].reset_index(drop=True)\n",
    "        FirstMonth = LastMonth\n",
    "        \n",
    "##############################################\n",
    "# STEP 3: Decide to pass the month or not    #\n",
    "##############################################\n",
    "        df_month_nonzero = df_month[df_month['lon']!=0]\n",
    "    \n",
    "    \n",
    "        # 3-a The number of non-zero values is less than 6 : skip \n",
    "        if len(df_month_nonzero) < 6: \n",
    "            continue\n",
    "            print(\"Small number of data: skip the month\")\n",
    "    \n",
    "        # 3-b An earthquake occurred within that month : skip    \n",
    "        IniTimeNonzeroMonth=df_month_nonzero.iloc[0,1]\n",
    "        EndTimeNonzeroMonth=df_month_nonzero.iloc[-1,1]\n",
    "        df_steps_exist=df_steps_earthquakes[(df_steps_earthquakes['stID']==stationID) & \\\n",
    "                                    (df_steps_earthquakes['time']>=IniTimeNonzeroMonth) & \\\n",
    "                                    (df_steps_earthquakes['time']<=EndTimeNonzeroMonth)]    \n",
    "        \n",
    "        if len(df_steps_exist) != 0: \n",
    "            continue\n",
    "            print(\"Earthquake within the month %s for station %s : skip the month\" %(str(f\"{j:03}\"),stationID))\n",
    "            \n",
    "        else: # otherwise, going!\n",
    "            print(\"work from here : linear fitting and residual and 3sigma ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     df_save=df_save.fillna(float(0))\n",
    "#     savefile = \"zeroFilled_\"+str(i+1) #output file = zeroFilled_\"$i\"\n",
    "#     df_save.to_csv(savefile ,header=None, index=None ,float_format='%.6f', sep=' ') #SAVE AS THEY ARE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
