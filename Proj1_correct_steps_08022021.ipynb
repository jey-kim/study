{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GEOS_Logo.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step **6** of **`G2FNL`**: <font color=blue>\"correct_steps.ipynb\"</font>\n",
    "#### August 2, 2021  <font color=red>(quality checking...)</font> \n",
    "##### Jeonghyeop Kim (jeonghyeop.kim@gmail.com)\n",
    "\n",
    "> input file(s)  : **`time_vector.dat`, `steps.txt` ,`list_full.dat` , `list_extra.dat` & `edited_i`** \\\n",
    "> output file(s) : **`edited_i_corrected`** \\\n",
    "> module(s) used : **`ismember.py`**\n",
    "\n",
    "0. This code is a part of GPS2FNL process \n",
    "1. A GNSS timeseries for years usually has a few discontinuous steps related to maintenance of equipments\n",
    "2. The Nevada Geodetic Lab provides metadata that provide information about these two types of steps. \n",
    "> http://geodesy.unr.edu/NGLStationPages/steps.txt (download this file in the begining of the master shell script)\n",
    "3. This code downloads metadata and will uses to correct listed steps. \n",
    "4. Step correction algorithm is proposed by *Johnson et al., 2021 (Earth and Space Science)*\n",
    "5. This algorithm does NOT correct for coseismic signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from ismember import ismember\n",
    "\n",
    "time_window_size = 4; \n",
    "# 4-month moving time-window\n",
    "time_window_size = time_window_size*30 + 35 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a list of all stations (e.g., 907 stations for california)\n",
    "> For some reasons, two list files exist (7/30/2021) \n",
    "> change this later after the STEP 1 and STEP 2 codes are ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of stations for the analysis is 907\n"
     ]
    }
   ],
   "source": [
    "list1 = \"list_full.dat\"\n",
    "df_list1=pd.read_csv(list1, header=None)\n",
    "\n",
    "list2 = \"list_extra.dat\"\n",
    "df_list2=pd.read_csv(list2, header=None)\n",
    "\n",
    "frames=[df_list1,df_list2]\n",
    "df_list=pd.concat(frames,ignore_index=True) #combine two DFs as a DF\n",
    "\n",
    "N_list = len(df_list) #length of the combine Df?\n",
    "print(\"the total number of stations for the analysis is %i\" % N_list)\n",
    "df_list.columns=['stID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read 'time_vector.dat' & Define datenum\n",
    "> Here **`datenum`** will be defined as **df_time_vector.index+1**. \\\n",
    "> This provides consecutive integers that are equivalent to all of the daily time steps within the analysis. \\\n",
    "> These integers serve as time flags, and they will be used in this code for regressions for functions of time. \\\n",
    "> For instance, 2 = 2006-01-02; 3 = 2006-01-03; 5658 = 2021-06-29; ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps before 20060101 and after 20210630 will be ignored\n"
     ]
    }
   ],
   "source": [
    "inputfile = 'time_vector.dat'\n",
    "df_full_time_vector = pd.read_csv(inputfile,header=None)\n",
    "df_full_time_vector.columns=['date']\n",
    "df_full_time_vector['datenum'] = df_full_time_vector.index + 1 #consecutive integers\n",
    "\n",
    "earliest_time=df_full_time_vector.loc[0,['date']]\n",
    "earliest_time=int(earliest_time)\n",
    "lastest_time=df_full_time_vector.iloc[-1,0]\n",
    "lastest_time=int(lastest_time)\n",
    "print(\"steps before %i and after %i will be ignored\" % (earliest_time,lastest_time))\n",
    "\n",
    "\n",
    "full_date_list=df_full_time_vector['date'].tolist() # a list\n",
    "full_date_df=df_full_time_vector['date'] # a df\n",
    "full_datenum_list=df_full_time_vector['datenum'].tolist() # a list\n",
    "full_datenum_df=df_full_time_vector['datenum'] # a df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. READ metadata and separate them into \n",
    ">(1) equipment-related steps : `df_steps_man_made_interest` \\\n",
    ">(2) coseismic steps : `df_steps_earthquakes_interest` \\\n",
    ">This algorithm only deals with **steps within the analysis time** defined in `time_vector.dat`\n",
    "\n",
    "**`This code also finds datenum of steps!`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = \"steps.txt\" #file name\n",
    "df_metadata=pd.read_csv(metadata, header=None, names=list('0123456'), sep=r'(?:,|\\s+)', \\\n",
    "                        comment='#', engine='python')\n",
    "## steps.txt is in an irregular shape\n",
    "## 'names=list('0123456')' is to fill empty spots with NaN \n",
    "\n",
    "df_steps_man_made = df_metadata[df_metadata['2'] == 1]\n",
    "df_steps_man_made = df_steps_man_made[['0', '1', '2', '3']]\n",
    "df_steps_man_made.columns=['stID','time','flag','log'] #time is in yyMMMdd format\n",
    "\n",
    "## date format conversion\n",
    "date_old = df_steps_man_made.time.tolist() # A DataFrame to a list\n",
    "date_new = pd.to_datetime(date_old, format='%y%b%d').strftime('%Y%m%d') # convert date format\n",
    "df_steps_man_made.loc[:,'time'] = date_new # replaces with the new date  in YYYYMMDD\n",
    "df_steps_man_made['time']=df_steps_man_made['time'].astype(int) #str to int\n",
    "\n",
    "\n",
    "df_steps_man_made_interest=df_steps_man_made.loc[(df_steps_man_made['time'] >= earliest_time) & (df_steps_man_made['time'] <= lastest_time)] \n",
    "df_steps_man_made_interest=df_steps_man_made_interest.reset_index(drop=True)\n",
    "\n",
    "## ADD datenum to df_steps_man_made_interest\n",
    "\n",
    "man_time_list=df_steps_man_made_interest.time.tolist()# To list \n",
    "man_time_index=ismember(man_time_list,full_date_list) # Find time index \n",
    "man_new_time_vector = df_full_time_vector.iloc[man_time_index] # Find values corresponding to the time index\n",
    "man_new_time_vector = man_new_time_vector.reset_index(drop=True) # Reset index\n",
    "    \n",
    "df_steps_man_made_interest['datenum']=man_new_time_vector['datenum'] # add equivalent datenum \n",
    "    ## (datenum will be used to match with steps and will be used for inversions)\n",
    "df_steps_man_made_interest=df_steps_man_made_interest[['stID','time','datenum','flag','log']]\n",
    "    ## change column orders    \n",
    "    \n",
    "#----------------------------------------------------------------------------------------------#   \n",
    "\n",
    "################################################################################################     \n",
    "#######################           *v1.0.0.*       ##############################################\n",
    "################################################################################################ \n",
    "###############  This algorithm does NOT correct co-seismic steps.  ############################ \n",
    "###############  But one can modify the code to correct such steps. ############################ \n",
    "###############  Now the coseismic-step data will be just saved as  ############################ \n",
    "###############  in a DataFrame 'df_steps_earthquakes_interest'.    ############################ \n",
    "###############                                                     ############################ \n",
    "###############  You can make a step list made of both equipment-   ############################ \n",
    "###############  related and earthquakes, sort ascending in time,   ############################ \n",
    "###############  and then correct in the order of time later.       ############################ \n",
    "###############  Save step flag {1=man-made; 2=earthquake} together ############################ \n",
    "###############  because you may need two different ways to correct ############################ \n",
    "###############  steps depending on their types!                    ############################ \n",
    "################################################################################################ \n",
    "#######################         J.K. (yy-mm-dd)       ##########################################\n",
    "################################################################################################ \n",
    "\n",
    "## for column names, see the readme file (http://geodesy.unr.edu/NGLStationPages/steps_readme.txt)\n",
    "df_steps_earthquakes = df_metadata[df_metadata['2'] == 2].reset_index(drop=True)\n",
    "df_steps_earthquakes.columns=['stID','time','flag','threshold','distance','mag','eventID'] \n",
    "## time is in yyMMMdd format\n",
    "## date format conversion\n",
    "date_old2 = df_steps_earthquakes.time.tolist() # A DataFrame to a list\n",
    "date_new2 = pd.to_datetime(date_old2, format='%y%b%d').strftime('%Y%m%d') # convert date format\n",
    "df_steps_earthquakes.loc[:,'time'] = date_new2 # replaces with the new date  in YYYYMMDD \n",
    "df_steps_earthquakes['time']=df_steps_earthquakes['time'].astype(int) #str to int\n",
    "\n",
    "df_steps_earthquakes_interest=df_steps_earthquakes.loc[(df_steps_earthquakes['time'] >= earliest_time) & (df_steps_earthquakes['time'] <= lastest_time)] \n",
    "df_steps_earthquakes_interest=df_steps_earthquakes_interest.reset_index(drop=True)\n",
    "\n",
    "## ADD datenum to df_steps_earthquakes_interest\n",
    "EQ_time_list=df_steps_earthquakes_interest.time.tolist()# To list \n",
    "EQ_time_index=ismember(EQ_time_list,full_date_list) # Find time index \n",
    "EQ_new_time_vector = df_full_time_vector.iloc[EQ_time_index] # Find values corresponding to the time index\n",
    "EQ_new_time_vector = EQ_new_time_vector.reset_index(drop=True) # Reset index\n",
    "    \n",
    "df_steps_earthquakes_interest['datenum']=EQ_new_time_vector['datenum'] # add equivalent datenum \n",
    "    ## (datenum will be used to match with steps and will be used for inversions)\n",
    "df_steps_earthquakes_interest=df_steps_earthquakes_interest[['stID','time','datenum','flag','threshold','distance','mag','eventID']]\n",
    "    ## change column orders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correct steps! \n",
    "> (a) Read input data **`edited_i`** \\\n",
    "> (b) Find and add **`datenum`** for the time-axis of the input data \\\n",
    "> (c) Check if the target station has unwanted steps. \n",
    ">> if no, continue the for loop \\\n",
    ">> if yes, keep going \n",
    "\n",
    "> (d) Save datenum for all steps \\\n",
    "> (e) For loop j in range(steps) \\\n",
    "> (f) Corrections! \\\n",
    "> (g) REMOVE ALL POSITION ESTIMATES on the date of step(s) \\\n",
    "> (h) Save corrected data **`edited_i_corrected`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Attempt to correct time series of 7ODM\n",
      "       Step(s) found: 1/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "1: Attempt to correct time series of ACSB\n",
      "       No step found\n",
      "2: Attempt to correct time series of ACSX\n",
      "       No step found\n",
      "3: Attempt to correct time series of AGMT\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "4: Attempt to correct time series of ALPP\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "5: Attempt to correct time series of ANA1\n",
      "       Step(s) found: 1/4\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/4\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/4\n",
      "              case4: Both before and after step position estimates are not enough\n",
      "              >>>>>> Some position estimates will be removed\n",
      "       Step(s) found: 4/4\n",
      "              case3: Great! \n",
      "6: Attempt to correct time series of APEX\n",
      "       No step found\n",
      "7: Attempt to correct time series of AR27\n",
      "       No step found\n",
      "8: Attempt to correct time series of AR53\n",
      "       No step found\n",
      "9: Attempt to correct time series of ARM1\n",
      "       Step(s) found: 1/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "10: Attempt to correct time series of ARM2\n",
      "       Step(s) found: 1/3\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>Some position estimates will be removed\n",
      "       Step(s) found: 2/3\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "11: Attempt to correct time series of AVRY\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "12: Attempt to correct time series of AZRY\n",
      "       Step(s) found: 1/3\n",
      "              case2: Not enough position estimates after a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "13: Attempt to correct time series of AZU1\n",
      "       Step(s) found: 1/3\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "14: Attempt to correct time series of BAMO\n",
      "       No step found\n",
      "15: Attempt to correct time series of BAR1\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "16: Attempt to correct time series of BASE\n",
      "       No step found\n",
      "17: Attempt to correct time series of BBDM\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "18: Attempt to correct time series of BBRY\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "19: Attempt to correct time series of BCWR\n",
      "       Step(s) found: 1/4\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/4\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/4\n",
      "              case3: Great! \n",
      "       Step(s) found: 4/4\n",
      "              case3: Great! \n",
      "20: Attempt to correct time series of BEAT\n",
      "       No step found\n",
      "21: Attempt to correct time series of BEMT\n",
      "       Step(s) found: 1/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>Some position estimates will be removed\n",
      "       Step(s) found: 2/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "22: Attempt to correct time series of BEPK\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "23: Attempt to correct time series of BGIS\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "24: Attempt to correct time series of BILL\n",
      "       Step(s) found: 1/3\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>Some position estimates will be removed\n",
      "       Step(s) found: 2/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "25: Attempt to correct time series of BKAP\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "26: Attempt to correct time series of BKMS\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "27: Attempt to correct time series of BLKM\n",
      "       No step found\n",
      "28: Attempt to correct time series of BLKS\n",
      "       No step found\n",
      "29: Attempt to correct time series of BLOK\n",
      "       No step found\n",
      "30: Attempt to correct time series of BLYT\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "31: Attempt to correct time series of BMHL\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "32: Attempt to correct time series of BMRY\n",
      "       No step found\n",
      "33: Attempt to correct time series of BOMG\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "34: Attempt to correct time series of BRAN\n",
      "       Step(s) found: 1/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "35: Attempt to correct time series of BRPK\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "36: Attempt to correct time series of BSRY\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "37: Attempt to correct time series of BTDM\n",
      "       Step(s) found: 1/1\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "38: Attempt to correct time series of BUEG\n",
      "       No step found\n",
      "39: Attempt to correct time series of BULL\n",
      "       No step found\n",
      "40: Attempt to correct time series of BURN\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "41: Attempt to correct time series of BVPP\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "42: Attempt to correct time series of CABL\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "43: Attempt to correct time series of CACT\n",
      "       Step(s) found: 1/5\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/5\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/5\n",
      "              case3: Great! \n",
      "       Step(s) found: 4/5\n",
      "              case2: Not enough position estimates after a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 5/5\n",
      "              case3: Great! \n",
      "44: Attempt to correct time series of CAND\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "45: Attempt to correct time series of CARH\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "46: Attempt to correct time series of CASE\n",
      "       No step found\n",
      "47: Attempt to correct time series of CAT1\n",
      "       No step found\n",
      "48: Attempt to correct time series of CAT2\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "49: Attempt to correct time series of CAT3\n",
      "       Step(s) found: 1/1\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "50: Attempt to correct time series of CBHS\n",
      "       Step(s) found: 1/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>Some position estimates will be removed\n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "51: Attempt to correct time series of CCCC\n",
      "       Step(s) found: 1/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>Some position estimates will be removed\n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "52: Attempt to correct time series of CCCO\n",
      "       Step(s) found: 1/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "53: Attempt to correct time series of CCST\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case2: Not enough position estimates after a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "54: Attempt to correct time series of CDMT\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "55: Attempt to correct time series of CGDM\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "56: Attempt to correct time series of CHAB\n",
      "       Step(s) found: 1/1\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "57: Attempt to correct time series of CHIL\n",
      "       Step(s) found: 1/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "58: Attempt to correct time series of CHLO\n",
      "       No step found\n",
      "59: Attempt to correct time series of CHMS\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "60: Attempt to correct time series of CIRX\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "61: Attempt to correct time series of CIT1\n",
      "       Step(s) found: 1/4\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/4\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/4\n",
      "              case3: Great! \n",
      "       Step(s) found: 4/4\n",
      "              case3: Great! \n",
      "62: Attempt to correct time series of CJMG\n",
      "       Step(s) found: 1/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>Some position estimates will be removed\n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "63: Attempt to correct time series of CJMS\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "64: Attempt to correct time series of CJVG\n",
      "       No step found\n",
      "65: Attempt to correct time series of CLAR\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "66: Attempt to correct time series of CLBD\n",
      "       Step(s) found: 1/1\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "67: Attempt to correct time series of CLOV\n",
      "       No step found\n",
      "68: Attempt to correct time series of CMP9\n",
      "       Step(s) found: 1/5\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/5\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 3/5\n",
      "              case4: Both before and after step position estimates are not enough\n",
      "              >>>>>> Some position estimates will be removed\n",
      "       Step(s) found: 4/5\n",
      "              case3: Great! \n",
      "       Step(s) found: 5/5\n",
      "              case3: Great! \n",
      "69: Attempt to correct time series of CNPP\n",
      "       No step found\n",
      "70: Attempt to correct time series of COAG\n",
      "       No step found\n",
      "71: Attempt to correct time series of COKG\n",
      "       No step found\n",
      "72: Attempt to correct time series of COPR\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "73: Attempt to correct time series of COSO\n",
      "       Step(s) found: 1/3\n",
      "              case2: Not enough position estimates after a step to take the median\n",
      "              >>>>>>Some position estimates will be removed\n",
      "       Step(s) found: 2/3\n",
      "              case4: Both before and after step position estimates are not enough\n",
      "              >>>>>> Some position estimates will be removed\n",
      "       Step(s) found: 3/3\n",
      "              case2: Not enough position estimates after a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "74: Attempt to correct time series of COTD\n",
      "       Step(s) found: 1/3\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "75: Attempt to correct time series of CPBN\n",
      "       No step found\n",
      "76: Attempt to correct time series of CRAT\n",
      "       No step found\n",
      "77: Attempt to correct time series of CRBT\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "78: Attempt to correct time series of CRFP\n",
      "       Step(s) found: 1/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>Some position estimates will be removed\n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "79: Attempt to correct time series of CRGG\n",
      "       No step found\n",
      "80: Attempt to correct time series of CRHS\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "81: Attempt to correct time series of CRRS\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "82: Attempt to correct time series of CRU1\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "83: Attempt to correct time series of CSCI\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "84: Attempt to correct time series of CSDH\n",
      "       Step(s) found: 1/2\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "85: Attempt to correct time series of CSN1\n",
      "       Step(s) found: 1/3\n",
      "              case2: Not enough position estimates after a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/3\n",
      "              case2: Not enough position estimates after a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "86: Attempt to correct time series of CSST\n",
      "       Step(s) found: 1/1\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "87: Attempt to correct time series of CTDM\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "88: Attempt to correct time series of CTMS\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "89: Attempt to correct time series of CUHS\n",
      "       Step(s) found: 1/1\n",
      "              case3: Great! \n",
      "90: Attempt to correct time series of CVHS\n",
      "       Step(s) found: 1/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/3\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "91: Attempt to correct time series of DAM2\n",
      "       Step(s) found: 1/1\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>Some position estimates will be removed\n",
      "92: Attempt to correct time series of DAM3\n",
      "       Step(s) found: 1/1\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>Some position estimates will be removed\n",
      "93: Attempt to correct time series of DHLG\n",
      "       Step(s) found: 1/3\n",
      "              case1: Not enough position estimates before a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "       Step(s) found: 2/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n",
      "94: Attempt to correct time series of DIXN\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case2: Not enough position estimates after a step to take the median\n",
      "              >>>>>>A linear fitting will be performed\n",
      "95: Attempt to correct time series of DLUZ\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "96: Attempt to correct time series of DSHS\n",
      "       Step(s) found: 1/2\n",
      "              case3: Great! \n",
      "       Step(s) found: 2/2\n",
      "              case3: Great! \n",
      "97: Attempt to correct time series of DSSC\n",
      "       No step found\n",
      "98: Attempt to correct time series of DTPG\n",
      "       No step found\n",
      "99: Attempt to correct time series of DVPB\n",
      "       Step(s) found: 1/3\n",
      "              case4: Both before and after step position estimates are not enough\n",
      "              >>>>>> Some position estimates will be removed\n",
      "       Step(s) found: 2/3\n",
      "              case3: Great! \n",
      "       Step(s) found: 3/3\n",
      "              case3: Great! \n"
     ]
    }
   ],
   "source": [
    "## Correcting the steps!\n",
    "\n",
    "for i in range(0,100): #range(N_list) later\n",
    "    \n",
    "## (a) Read input data 'edited_i'\n",
    "    target_data=\"edited_\"+str(i+1)\n",
    "    df_GPS=pd.read_csv(target_data, header=None, sep=' ')\n",
    "    df_GPS.columns=['time','lon','lat','e','n','z','se','sn','sz','corr_en','flag']\n",
    "    \n",
    "    station=df_list.loc[i,['stID']].to_string(index=False)\n",
    "    SearchSt=station[1:5] # a space in the first byte of the string\n",
    "    #SearchSt is the target station for corrections\n",
    "    \n",
    "## (b) Add datenum for the input data 'edited_i'    \n",
    "    time_list=df_GPS.time.to_list() #to list    \n",
    "    time_index=ismember(time_list,full_date_list) #find time index \n",
    "    \n",
    "    #Check if everything is okay\n",
    "    if len(time_index)-len(df_GPS) != 0:\n",
    "        print(\"*****************************\")\n",
    "        print(\"*****************************\")\n",
    "        print(\"*****************************\")\n",
    "        print(\"*****************************\")\n",
    "        print(\"WARNING: something is wrong!!\")\n",
    "        print(\"*****************************\")\n",
    "        print(\"*****************************\")\n",
    "        print(\"*****************************\")\n",
    "        print(\"*****************************\")\n",
    "    new_time_vector =df_full_time_vector.iloc[time_index]\n",
    "    \n",
    "    new_time_vector=new_time_vector.reset_index() # reset index\n",
    "    \n",
    "    df_GPS['datenum']=new_time_vector['datenum'] # add equivalent datenum \n",
    "    #(datenum will be used to match with steps and will be used for inversions)\n",
    "    df_GPS=df_GPS[['time','datenum','lon','lat','e','n','z','se','sn','sz','corr_en','flag']]\n",
    "    #change column orders\n",
    "    \n",
    "    \n",
    "    # Unit [m] to [mm]\n",
    "    df_GPS.e = df_GPS.e*1000\n",
    "    df_GPS.n = df_GPS.n*1000\n",
    "    df_GPS.z = df_GPS.z*1000\n",
    "    df_GPS.se = df_GPS.se*1000\n",
    "    df_GPS.sn = df_GPS.sn*1000\n",
    "    df_GPS.sz = df_GPS.sz*1000\n",
    "    \n",
    "    \n",
    "    \n",
    "## (c) Check is the target station with unwatned step(s) \n",
    "## > if no, continue the for loop\n",
    "## >> if yes, keep going \n",
    "\n",
    "    itemindex = np.where(df_steps_man_made_interest['stID']==SearchSt) # similar to find() in MATLAB\n",
    "    HowManySteps=itemindex[0].size  # the number of steps\n",
    "    \n",
    "    \n",
    "    print(\"%i: Attempt to correct time series of %s\" % (i,SearchSt))\n",
    "    \n",
    "    if HowManySteps==0: # No step      \n",
    "        print(\"       No step found\")\n",
    "   \n",
    "    else: # step(s) exist\n",
    "        \n",
    "        event_idx = itemindex[0]\n",
    "\n",
    "## (d) Save datenum for all steps \n",
    "\n",
    "        all_datenum = df_steps_man_made_interest.datenum\n",
    "        event_datenum = all_datenum.iloc[event_idx]\n",
    "        event_datenum = pd.unique(event_datenum) \n",
    "        # In a day, more than a job can be done.\n",
    "        # In this case, the steps.txt saves all the jobs in multiple logs.\n",
    "        # But the date in the logs are the same. \n",
    "        # Here, the code gets rid of all the overlaps\n",
    "\n",
    "        N_events = len(event_datenum) #How many steps without counting multiple times for overlapped steps\n",
    "        \n",
    "## (e) For loop j in range(N_events)\n",
    "        for j in range(N_events):\n",
    "        \n",
    "            print(\"       Step(s) found: %i/%i\" %(j+1,N_events))\n",
    "            step_standards=event_datenum[j]\n",
    "\n",
    "            before_step = list(range(step_standards-14,step_standards)) #14 days before the step (a list)\n",
    "            after_step = list(range(step_standards+1,step_standards+15)) #14 days after the step (a list)\n",
    "            #These are in datenum \n",
    "            \n",
    "            data_datenum = df_GPS.datenum       \n",
    "            date_before=ismember(before_step,data_datenum) \n",
    "            date_after=ismember(after_step,data_datenum)\n",
    "            #find the same datenum in the data, and give the indices!\n",
    "            \n",
    "            idx_before=[x for x in date_before if x == x] # get rid of float('NaN') from the list\n",
    "            idx_after=[x for x in date_after if x == x] # get rid of float('NaN') from the list\n",
    "            \n",
    "\n",
    "## (f) Obtain before_step and after_step (14 days for each)\n",
    "## > 4 cases. \n",
    "\n",
    "\n",
    "## >> (  i) len(idx_before) <  10 and len(idx_after) >= 10\n",
    "            if len(idx_before) < 10 and len(idx_after) >= 10:\n",
    "                print(\"              case1: Not enough position estimates before a step to take the median\")\n",
    "                #print(len(idx_before))\n",
    "                # case1: fewer than 10 position estimates are available before the step\")\n",
    "                # A linear fit will be performed to fill the gap using the time series \n",
    "                # of one-year period before the step. \n",
    "                # If fewer than 250 position estimates are available over the year period,\n",
    "                # 5 month positions before the step will be removed. \n",
    "                # WHY 5 months? The default of the algorithm uses 4-month moving time window\n",
    "                # to obtain seasonal strain. \n",
    "                \n",
    "                One_year_before_step = list(range(step_standards-365,step_standards)) # one year before the step\n",
    "                date_one_year_before=ismember(One_year_before_step,data_datenum)\n",
    "                idx_one_year_before=[x for x in date_one_year_before if x == x]\n",
    "            \n",
    "                if len(idx_one_year_before) < 250:\n",
    "                    print(\"              >>>>>>Some position estimates will be removed\")\n",
    "                    Time_window_size_before = list(range(step_standards-time_window_size,step_standards))\n",
    "                    #time_window_size = 4*30 + 35 = ~5 months\n",
    "                    date_time_window_size_before=ismember(Time_window_size_before,data_datenum)\n",
    "                    idx_time_window_size_before = [x for x in date_time_window_size_before if x == x]\n",
    "                    df_GPS=df_GPS.drop(idx_time_window_size_before) #drop the data. #make sure later you need to reset the index of DF!\n",
    "                    \n",
    "                else:\n",
    "                    print(\"              >>>>>>A linear fitting will be performed\")\n",
    "                    # Linear fit will be performed.      \n",
    "                    \n",
    "                    # data with errors\n",
    "                    t=df_GPS.datenum[idx_one_year_before]\n",
    "                    \n",
    "                    e=df_GPS.e[idx_one_year_before]\n",
    "                    n=df_GPS.n[idx_one_year_before]\n",
    "                    z=df_GPS.z[idx_one_year_before]\n",
    "                    \n",
    "                    se=df_GPS.se[idx_one_year_before]\n",
    "                    sn=df_GPS.sn[idx_one_year_before]\n",
    "                    sz=df_GPS.sz[idx_one_year_before]\n",
    "                    \n",
    "                    inv_se = 1/se \n",
    "                    inv_sn = 1/sn\n",
    "                    inv_sz = 1/sz\n",
    "                    \n",
    "                    # 1/error diagonal matrices\n",
    "                    We = pd.DataFrame(np.diag(inv_se),index=inv_se.index,columns=inv_se.index) #1/error diagonal matrix\n",
    "                    Wn = pd.DataFrame(np.diag(inv_sn),index=inv_sn.index,columns=inv_sn.index) #1/error diagonal matrix\n",
    "                    Wz = pd.DataFrame(np.diag(inv_sz),index=inv_sz.index,columns=inv_sz.index) #1/error diagonal matrix\n",
    "\n",
    "                    \n",
    "                    #G-matrices with errors\n",
    "                    \n",
    "                    Ge=pd.DataFrame(t,index=t.index)\n",
    "                    Ge['ones']=pd.DataFrame(np.array([1] * len(Ge)),index=Ge.index)\n",
    "                    Gew=We@Ge\n",
    "                    \n",
    "                    Gn=pd.DataFrame(t,index=t.index)\n",
    "                    Gn['ones']=pd.DataFrame(np.array([1] * len(Gn)),index=Gn.index)\n",
    "                    Gnw=Wn@Gn\n",
    "                    \n",
    "                    Gz=pd.DataFrame(t,index=t.index)\n",
    "                    Gz['ones']=pd.DataFrame(np.array([1] * len(Gz)),index=Gz.index) \n",
    "                    Gzw=Wz@Gz\n",
    "                    \n",
    "                \n",
    "                    #date vectors with errors\n",
    "                    \n",
    "                    ew = We@e\n",
    "                    nw = Wn@n\n",
    "                    zw = Wz@z\n",
    "                    \n",
    "                    Gew_prime = Gew.transpose()\n",
    "                    Gnw_prime = Gnw.transpose()\n",
    "                    Gzw_prime = Gzw.transpose()\n",
    "                    \n",
    "                    GP_G_e = Gew_prime @ Gew\n",
    "                    GP_G_n = Gnw_prime @ Gnw\n",
    "                    GP_G_z = Gzw_prime @ Gzw\n",
    "                    \n",
    "                    try:\n",
    "                        inv_GP_G_e = pd.DataFrame(np.linalg.inv(GP_G_e.to_numpy()), GP_G_e.columns, GP_G_e.index)\n",
    "                    except:\n",
    "                        inv_GP_G_e = pd.DataFrame(np.linalg.pinv(GP_G_e.to_numpy()), GP_G_e.columns, GP_G_e.index)\n",
    "                        print(\"For station %s, the 'e'-component. Try pseudo inversion\")\n",
    "\n",
    "                    try:\n",
    "                        inv_GP_G_n = pd.DataFrame(np.linalg.inv(GP_G_n.to_numpy()), GP_G_n.columns, GP_G_n.index)\n",
    "                    except:\n",
    "                        inv_GP_G_n = pd.DataFrame(np.linalg.pinv(GP_G_n.to_numpy()), GP_G_n.columns, GP_G_n.index)\n",
    "                        print(\"For station %s, the 'n'-component. Try pseudo inversion\")\n",
    "                        \n",
    "                    try:\n",
    "                        inv_GP_G_z = pd.DataFrame(np.linalg.inv(GP_G_z.to_numpy()), GP_G_z.columns, GP_G_z.index)\n",
    "                    except:\n",
    "                        inv_GP_G_z = pd.DataFrame(np.linalg.pinv(GP_G_z.to_numpy()), GP_G_z.columns, GP_G_z.index)                        \n",
    "                        print(\"For station %s, the 'z'-component. Try pseudo inversion\")\n",
    "                    \n",
    "                    \n",
    "                    #INVERSION MODELs\n",
    "                    model_e = inv_GP_G_e@Gew_prime@ew\n",
    "                    model_n = inv_GP_G_n@Gnw_prime@nw\n",
    "                    model_z = inv_GP_G_z@Gzw_prime@zw\n",
    "                    \n",
    "                    e_model_at_the_step=model_e[0]*step_standards+model_e[1]\n",
    "                    n_model_at_the_step=model_n[0]*step_standards+model_n[1]\n",
    "                    z_model_at_the_step=model_z[0]*step_standards+model_z[1]\n",
    "                    \n",
    "                    median_before_e=e_model_at_the_step #from linear model\n",
    "                    median_before_n=n_model_at_the_step #from linear model\n",
    "                    median_before_z=z_model_at_the_step #from linear model\n",
    "                    \n",
    "                    \n",
    "                    median_after_e=df_GPS.e[idx_after].median() #from data (median value)\n",
    "                    median_after_n=df_GPS.n[idx_after].median() #from data (median value)\n",
    "                    median_after_z=df_GPS.z[idx_after].median() #from data (median value)\n",
    "                    \n",
    "                    \n",
    "                    # Modeled steps\n",
    "                    diff_after_before_e = median_after_e - median_before_e\n",
    "                    diff_after_before_n = median_after_n - median_before_n\n",
    "                    diff_after_before_z = median_after_z - median_before_z\n",
    "                    \n",
    "                    \n",
    "                    #Correcting.. \n",
    "                    idx_start=idx_after[0]\n",
    "                    idx_end=len(df_GPS)\n",
    "                    idx_correction=list(range(idx_start,idx_end))\n",
    "                    \n",
    "                    df_GPS.loc[idx_correction,['e']]=df_GPS.loc[idx_correction,['e']]-diff_after_before_e\n",
    "                    df_GPS.loc[idx_correction,['n']]=df_GPS.loc[idx_correction,['n']]-diff_after_before_n\n",
    "                    df_GPS.loc[idx_correction,['z']]=df_GPS.loc[idx_correction,['z']]-diff_after_before_z\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "## >> ( ii) len(idx_before) >= 10 and len(idx_after) < 10            \n",
    "            elif len(idx_before) >= 10 and len(idx_after) < 10:\n",
    "                print(\"              case2: Not enough position estimates after a step to take the median\")\n",
    "                #print(len(idx_after))\n",
    "                # case2: fewer than 10 position estimates are available after the step\")\n",
    "                # A linear fit will be performed to fill the gap using the time series \n",
    "                # of one-year period after the step. \n",
    "                # If fewer than 250 position estimates are available over the year period,\n",
    "                # 5 month positions before the step will be removed. \n",
    "                # WHY 5 months? The default of the algorithm uses 4-month moving time window\n",
    "                # to obtain seasonal strain. \n",
    "                \n",
    "                One_year_after_step = list(range(step_standards+1,step_standards+366)) # one year after the step\n",
    "                date_one_year_after=ismember(One_year_after_step,data_datenum)\n",
    "                idx_one_year_after=[x for x in date_one_year_after if x == x]\n",
    "\n",
    "                if len(idx_one_year_after) < 250:\n",
    "                    print(\"              >>>>>>Some position estimates will be removed\")\n",
    "                    Time_window_size_after = list(range(step_standards+1,step_standards+time_window_size+1))\n",
    "                    #time_window_size = 4*30 + 35 = ~5 months\n",
    "                    date_time_window_size_after=ismember(Time_window_size_after,data_datenum)\n",
    "                    idx_time_window_size_after = [x for x in date_time_window_size_after if x == x]\n",
    "                    df_GPS=df_GPS.drop(idx_time_window_size_after) #drop the data. #make sure later you need to reset the index of DF!\n",
    "                    \n",
    "                else:\n",
    "                    print(\"              >>>>>>A linear fitting will be performed\")\n",
    "                    # Linear fit will be performed.      \n",
    "                    \n",
    "                    # data with errors\n",
    "                    t=df_GPS.datenum[idx_one_year_after]\n",
    "                    \n",
    "                    e=df_GPS.e[idx_one_year_after]\n",
    "                    n=df_GPS.n[idx_one_year_after]\n",
    "                    z=df_GPS.z[idx_one_year_after]\n",
    "                    \n",
    "                    se=df_GPS.se[idx_one_year_after]\n",
    "                    sn=df_GPS.sn[idx_one_year_after]\n",
    "                    sz=df_GPS.sz[idx_one_year_after]\n",
    "                    \n",
    "                    inv_se = 1/se \n",
    "                    inv_sn = 1/sn\n",
    "                    inv_sz = 1/sz\n",
    "                    \n",
    "                    # 1/error diagonal matrices\n",
    "                    We = pd.DataFrame(np.diag(inv_se),index=inv_se.index,columns=inv_se.index) #1/error diagonal matrix\n",
    "                    Wn = pd.DataFrame(np.diag(inv_sn),index=inv_sn.index,columns=inv_sn.index) #1/error diagonal matrix\n",
    "                    Wz = pd.DataFrame(np.diag(inv_sz),index=inv_sz.index,columns=inv_sz.index) #1/error diagonal matrix\n",
    "\n",
    "                    \n",
    "                    #G-matrices with errors\n",
    "                    \n",
    "                    Ge=pd.DataFrame(t,index=t.index)\n",
    "                    Ge['ones']=pd.DataFrame(np.array([1] * len(Ge)),index=Ge.index)\n",
    "                    Gew=We@Ge\n",
    "                    \n",
    "                    Gn=pd.DataFrame(t,index=t.index)\n",
    "                    Gn['ones']=pd.DataFrame(np.array([1] * len(Gn)),index=Gn.index)\n",
    "                    Gnw=Wn@Gn\n",
    "                    \n",
    "                    Gz=pd.DataFrame(t,index=t.index)\n",
    "                    Gz['ones']=pd.DataFrame(np.array([1] * len(Gz)),index=Gz.index) \n",
    "                    Gzw=Wz@Gz\n",
    "                    \n",
    "                \n",
    "                    #date vectors with errors\n",
    "                    \n",
    "                    ew = We@e\n",
    "                    nw = Wn@n\n",
    "                    zw = Wz@z\n",
    "                    \n",
    "                    Gew_prime = Gew.transpose()\n",
    "                    Gnw_prime = Gnw.transpose()\n",
    "                    Gzw_prime = Gzw.transpose()\n",
    "                    \n",
    "                    GP_G_e = Gew_prime @ Gew\n",
    "                    GP_G_n = Gnw_prime @ Gnw\n",
    "                    GP_G_z = Gzw_prime @ Gzw\n",
    "                    \n",
    "                    try:\n",
    "                        inv_GP_G_e = pd.DataFrame(np.linalg.inv(GP_G_e.to_numpy()), GP_G_e.columns, GP_G_e.index)\n",
    "                    except:\n",
    "                        inv_GP_G_e = pd.DataFrame(np.linalg.pinv(GP_G_e.to_numpy()), GP_G_e.columns, GP_G_e.index)\n",
    "                        print(\"For station %s, the 'e'-component. Try pseudo inversion\")\n",
    "\n",
    "                    try:\n",
    "                        inv_GP_G_n = pd.DataFrame(np.linalg.inv(GP_G_n.to_numpy()), GP_G_n.columns, GP_G_n.index)\n",
    "                    except:\n",
    "                        inv_GP_G_n = pd.DataFrame(np.linalg.pinv(GP_G_n.to_numpy()), GP_G_n.columns, GP_G_n.index)\n",
    "                        print(\"For station %s, the 'n'-component. Try pseudo inversion\")\n",
    "                        \n",
    "                    try:\n",
    "                        inv_GP_G_z = pd.DataFrame(np.linalg.inv(GP_G_z.to_numpy()), GP_G_z.columns, GP_G_z.index)\n",
    "                    except:\n",
    "                        inv_GP_G_z = pd.DataFrame(np.linalg.pinv(GP_G_z.to_numpy()), GP_G_z.columns, GP_G_z.index)                        \n",
    "                        print(\"For station %s, the 'z'-component. Try pseudo inversion\")\n",
    "                    \n",
    "                    \n",
    "                    #INVERSION MODELs\n",
    "                    model_e = inv_GP_G_e@Gew_prime@ew\n",
    "                    model_n = inv_GP_G_n@Gnw_prime@nw\n",
    "                    model_z = inv_GP_G_z@Gzw_prime@zw\n",
    "                    \n",
    "                    e_model_at_the_step=model_e[0]*step_standards+model_e[1]\n",
    "                    n_model_at_the_step=model_n[0]*step_standards+model_n[1]\n",
    "                    z_model_at_the_step=model_z[0]*step_standards+model_z[1]\n",
    "                    \n",
    "                    median_after_e=e_model_at_the_step #from linear model\n",
    "                    median_after_n=n_model_at_the_step #from linear model\n",
    "                    median_after_z=z_model_at_the_step #from linear model\n",
    "                    \n",
    "                    \n",
    "                    median_before_e=df_GPS.e[idx_before].median() #from data (median value)\n",
    "                    median_before_n=df_GPS.n[idx_before].median() #from data (median value)\n",
    "                    median_before_z=df_GPS.z[idx_before].median() #from data (median value)\n",
    "                    \n",
    "                    \n",
    "                    # Modeled steps\n",
    "                    diff_after_before_e = median_after_e - median_before_e\n",
    "                    diff_after_before_n = median_after_n - median_before_n\n",
    "                    diff_after_before_z = median_after_z - median_before_z\n",
    "                    \n",
    "                    \n",
    "                    #Correcting.. \n",
    "                    \n",
    "                    idx_end=len(df_GPS)\n",
    "                    \n",
    "                    if len(idx_after)!=0:             \n",
    "                        idx_start=idx_after[0]\n",
    "                    else: # len(idx_after)==0 Not sure when df_GPS has the first data after the step.\n",
    "                        idx_start=idx_before[-1]+1+15 # First possibility \n",
    "                        \n",
    "                    try:                          \n",
    "                        idx_correction=list(range(idx_start,idx_end))              \n",
    "                        df_GPS.loc[idx_correction,['e']]=df_GPS.loc[idx_correction,['e']]-diff_after_before_e\n",
    "                        df_GPS.loc[idx_correction,['n']]=df_GPS.loc[idx_correction,['n']]-diff_after_before_n\n",
    "                        df_GPS.loc[idx_correction,['z']]=df_GPS.loc[idx_correction,['z']]-diff_after_before_z\n",
    "                    except: \n",
    "                        idx_start = idx_start + 1\n",
    "                        idx_correction=list(range(idx_start,idx_end))\n",
    "                        df_GPS.loc[idx_correction,['e']]=df_GPS.loc[idx_correction,['e']]-diff_after_before_e\n",
    "                        df_GPS.loc[idx_correction,['n']]=df_GPS.loc[idx_correction,['n']]-diff_after_before_n\n",
    "                        df_GPS.loc[idx_correction,['z']]=df_GPS.loc[idx_correction,['z']]-diff_after_before_z                \n",
    "                        \n",
    "\n",
    "## >> (iii) len(idx_before) >= 10 and len(idx_after) >= 10\n",
    "            elif len(idx_before) >= 10 and len(idx_after) >= 10:              \n",
    "                print(\"              case3: Great! \")\n",
    "                #print(len(idx_before),len(idx_after))\n",
    "                median_before_e=df_GPS.e[idx_before].median() #from data (median value)\n",
    "                median_before_n=df_GPS.n[idx_before].median() #from data (median value)\n",
    "                median_before_z=df_GPS.z[idx_before].median() #from data (median value)\n",
    "                    \n",
    "                    \n",
    "                median_after_e=df_GPS.e[idx_after].median() #from data (median value)\n",
    "                median_after_n=df_GPS.n[idx_after].median() #from data (median value)\n",
    "                median_after_z=df_GPS.z[idx_after].median() #from data (median value)\n",
    "                    \n",
    "                    \n",
    "                # Modeled steps\n",
    "                diff_after_before_e = median_after_e - median_before_e\n",
    "                diff_after_before_n = median_after_n - median_before_n\n",
    "                diff_after_before_z = median_after_z - median_before_z\n",
    "                    \n",
    "                #Correcting.. \n",
    "                idx_start=idx_after[0]\n",
    "                idx_end=len(df_GPS)\n",
    "                idx_correction=list(range(idx_start,idx_end))\n",
    "                    \n",
    "                df_GPS.loc[idx_correction,['e']]=df_GPS.loc[idx_correction,['e']]-diff_after_before_e\n",
    "                df_GPS.loc[idx_correction,['n']]=df_GPS.loc[idx_correction,['n']]-diff_after_before_n\n",
    "                df_GPS.loc[idx_correction,['z']]=df_GPS.loc[idx_correction,['z']]-diff_after_before_z\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "## >> ( iv) len(idx_before) <  10 and len(idx_after) <  10 \n",
    "            elif len(idx_before) < 10 and len(idx_after) < 10:\n",
    "                print(\"              case4: Both before and after step position estimates are not enough\")\n",
    "                print(\"              >>>>>> Some position estimates will be removed\")\n",
    "                time_window_size_half = time_window_size/2    \n",
    "                time_window_size_half = int(time_window_size_half)\n",
    "                Time_window_size_worst = list(range(step_standards-time_window_size_half,step_standards+time_window_size_half+1))\n",
    "                #time_window_size = 4*30 + 35 = ~5 months\n",
    "                date_time_window_size_worst=ismember(Time_window_size_worst,data_datenum)\n",
    "                idx_time_window_size_worst = [x for x in date_time_window_size_worst if x == x]\n",
    "                df_GPS=df_GPS.drop(idx_time_window_size_worst) #drop the data. #make sure later you need to reset          \n",
    "            \n",
    "            else:\n",
    "                print(\"*****************************\")\n",
    "                print(\"*****************************\")\n",
    "                print(\"*****************************\")\n",
    "                print(\"*****************************\")\n",
    "                print(\"WARNING! : something is wrong\")\n",
    "                print(\"*****************************\")\n",
    "                print(\"*****************************\")\n",
    "                print(\"*****************************\")\n",
    "                print(\"*****************************\")\n",
    "                \n",
    "## (g) REMOVE ALL POSITION ESTIMATES on the date of step(s)\n",
    "    \n",
    "        IDX_event_data_overlap=ismember(event_datenum,data_datenum) # Find if we have position estimates\n",
    "        cleanedList = [x for x in IDX_event_data_overlap if x == x] # get rid of float('NaN') from the list\n",
    "        if len(cleanedList)!=0:            \n",
    "            try:\n",
    "                df_GPS=df_GPS.drop(cleanedList)                \n",
    "            except: \n",
    "                K = len(cleanedList)               \n",
    "                for k in range(K):\n",
    "                    try:\n",
    "                        df_GPS=df_GPS.drop(cleanedList[k])\n",
    "                    except:\n",
    "                        continue          \n",
    "    \n",
    "## (h) Save corrected data\n",
    "\n",
    "    df_GPS=df_GPS.reset_index() # reset index\n",
    "    df_GPS.e = df_GPS.e/1000\n",
    "    df_GPS.n = df_GPS.n/1000\n",
    "    df_GPS.z = df_GPS.z/1000\n",
    "    df_GPS.se = df_GPS.se/1000\n",
    "    df_GPS.sn = df_GPS.sn/1000\n",
    "    df_GPS.sz = df_GPS.sz/1000\n",
    "    df_GPS=df_GPS[['time','lon','lat','e','n','z','se','sn','sz','corr_en','flag']]\n",
    "    \n",
    "\n",
    "    savefile = \"edited_\"+str(i+1)+\"_corrected_python\" #output file = edited_\"$i\"_corrected_auto_final\n",
    "    df_GPS.to_csv(savefile ,header=None, index=None,sep=' ',float_format='%g') #SAVE AS THEY ARE\n",
    "    \n",
    "#    df_GPS.to_csv(savefile ,header=None, index=None,sep=' ',float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
