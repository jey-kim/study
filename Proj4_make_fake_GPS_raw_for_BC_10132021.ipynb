{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figs/GEOS_logo.pdf\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>\"make_fake_GPS_raw_for_BC.ipynb\"</font>\n",
    "#### Oct 13, 2021  <font color=red>(v. testing)</font> \n",
    "##### Jeonghyeop Kim (jeonghyeop.kim@gmail.com)\n",
    "\n",
    "> output file: **`GPS_raw_fake.dat`** \n",
    "\n",
    "0. This code is a part of the joint inversion project (project4: joint inversion of GNSS and InSAR)\n",
    "1. This code generates `GPS_raw_fake.dat` file that will be used to obtain latlong_gps.dat\n",
    "2. The latlong_gps.dat will be copied as output.dat \n",
    "3. Sparse code will generate UCERF ref. velocity at the boundary as well as at the InSAR reference point. \n",
    "4. A velocity vector at the InSAR reference can be removed. Thus the B.C. data is in the same reference point as the InSAR data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "output = 'GPS_raw_fake_BC.dat'\n",
    "\n",
    "# Boundary longitude, latitude\n",
    "lon_min=-116.680\n",
    "lon_max=-116.540\n",
    "lat_min=33.860\n",
    "lat_max=33.960\n",
    "\n",
    "# Data sampling step on the boundary\n",
    "step = 0.01  #in degree\n",
    "\n",
    "# InSAR reference point:\n",
    "# This can be used to sample the boundary condition velocities (UCERF) \n",
    "# w.r.t. the same reference point. \n",
    "# ref_lon = -116.528\n",
    "# ref_lat = 33.908\n",
    "\n",
    "\n",
    "# As of 10/5/2021,\n",
    "# the frame of the basis-function responses (top right corner) will be used\n",
    "# to sample the boundary condition velocities (UCERF3)\n",
    "ref_lon = -116.54\n",
    "ref_lat = 33.96\n",
    " \n",
    "#print(lon_min,lon_max,lat_min,lat_max,step,ref_lon,ref_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_range=np.arange(lon_min,lon_max,step)\n",
    "lat_max_for_lon_range=np.array(lat_max*np.ones(len(lon_range)))\n",
    "lat_min_for_lon_range=np.array(lat_min*np.ones(len(lon_range)))\n",
    "\n",
    "\n",
    "lat_range=np.arange(lat_min+step,lat_max-step,step)\n",
    "lon_max_for_lat_range=np.array(lon_max*np.ones(len(lat_range)))\n",
    "lon_min_for_lat_range=np.array(lon_min*np.ones(len(lat_range)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_fi=np.concatenate((lon_range, lon_max_for_lat_range, lon_min_for_lat_range,lon_range))\n",
    "lat_fi=np.concatenate((lat_min_for_lon_range, lat_range, lat_range, lat_max_for_lon_range))\n",
    "#Merge all np arrays\n",
    "\n",
    "lon_fi=lon_fi.tolist()\n",
    "lat_fi=lat_fi.tolist()\n",
    "\n",
    "\n",
    "coor_dict = {'lon' : lon_fi, 'lat' : lat_fi}\n",
    "\n",
    "df=pd.DataFrame.from_dict(coor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.round(3)\n",
    "df=df.sort_values(by=['lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = pd.DataFrame({'lon': [ref_lon], 'lat' : [ref_lat]})\n",
    "#make a new df for the reference point\n",
    "\n",
    "df_fi = pd.concat([df_ref, df], ignore_index = True, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi['vx fake']=np.ones(len(df_fi))*-17\n",
    "df_fi['vy fake']=np.ones(len(df_fi))*15\n",
    "df_fi['sx fake']=np.ones(len(df_fi))*0.111\n",
    "df_fi['sy fake']=np.ones(len(df_fi))*0.111\n",
    "df_fi['coxy fake']=np.ones(len(df_fi))*0.05\n",
    "\n",
    "year = np.ones(len(df_fi))*2020\n",
    "year = year.astype(int)\n",
    "\n",
    "flag = np.ones(len(df_fi))*1\n",
    "flag = flag.astype(int)\n",
    "\n",
    "df_fi['year']=year\n",
    "df_fi['flag']=flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi.to_csv(output, index=False, sep=' ',float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
