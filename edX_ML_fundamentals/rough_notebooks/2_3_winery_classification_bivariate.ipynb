{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winery classification with the bivariate Gaussian\n",
    "\n",
    "Our first generative model for Winery classification used just one feature. Now we use two features, modeling each class by a **bivariate Gaussian**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the univariate case, we start by loading in the Wine data set. Make sure the file `wine.data.txt` is in the same directory as this notebook.\n",
    "\n",
    "Recall that there are 178 data points, each with 13 features and a label (1,2,3). As before, we will divide this into a training set of 130 points and a test set of 48 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal \n",
    "# installing packages for interactive graphs\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set.\n",
    "data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']\n",
    "# Split 178 instances into training set (trainx, trainy) of size 130 and test set (testx, testy) of size 48\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Look at the distribution of two features from one of the wineries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to plot the distribution of two features from a particular winery. We will use several helper functions for this. It is worth understanding each of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first helper function fits a Gaussian to a data set, restricting attention to specified features.\n",
    "It returns the mean and covariance matrix of the Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Gaussian to a data set using the selected features\n",
    "def fit_gaussian(x, features):\n",
    "    mu = np.mean(x[:,features], axis=0)\n",
    "    covar = np.cov(x[:,features], rowvar=0, bias=1)\n",
    "    return mu, covar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's look at the Gaussian we get for winery 1, using features 0 ('alcohol') and 6 ('flavanoids')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "[13.78534884  2.99627907]\n",
      "Covariance matrix:\n",
      "[[0.23325279 0.07526874]\n",
      " [0.07526874 0.15240941]]\n"
     ]
    }
   ],
   "source": [
    "f1 = 0\n",
    "f2 = 6\n",
    "label = 1\n",
    "mu, covar = fit_gaussian(trainx[trainy==label,:], [f1,f2])\n",
    "print(\"Mean:\\n\" + str(mu))\n",
    "print(\"Covariance matrix:\\n\" + str(covar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.78534884,  2.99627907])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23325279, 0.07526874],\n",
       "       [0.07526874, 0.15240941]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will construct a routine for displaying points sampled from a two-dimensional Gaussian, as well as a few contour lines. Part of doing this involves deciding what range to use for each axis. We begin with a little helper function that takes as input an array of numbers (values along a single feature) and returns the range in which these numbers lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the range within which an array of numbers lie, with a little buffer\n",
    "def find_range(x):\n",
    "    lower = min(x)\n",
    "    upper = max(x)\n",
    "    width = upper - lower\n",
    "    lower = lower - 0.2 * width\n",
    "    upper = upper + 0.2 * width\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a routine that plots a few contour lines of a given two-dimensional Gaussian.\n",
    "It takes as input:\n",
    "* `mu`, `cov`: the parameters of the Gaussian\n",
    "* `x1g`, `x2g`: the grid (along the two axes) at which the density is to be computed\n",
    "* `col`: the color of the contour lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(mu, cov, x1g, x2g, col):\n",
    "    rv = multivariate_normal(mean=mu, cov=cov)\n",
    "    z = np.zeros((len(x1g),len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            z[j,i] = rv.logpdf([x1g[i], x2g[j]]) \n",
    "    sign, logdet = np.linalg.slogdet(cov) #log of determinant\n",
    "    normalizer = -0.5 * (2 * np.log(6.28) + sign * logdet) #log(2*pi)..?\n",
    "    for offset in range(1,4):\n",
    "        plt.contour(x1g,x2g,z, levels=[normalizer - offset], colors=col, linewidths=2.0, linestyles='solid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **two_features_plot** takes an input two features and a label, and displays the distribution for the specified winery and pair of features.\n",
    "\n",
    "The first line allows you to specify the parameters interactively using sliders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f32fd2e3f6940659e366c71871eca91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1), label=IntSlider(1,1,3,1) ) #(default,start,end,step)\n",
    "def two_features_plot(f1,f2,label):\n",
    "    if f1 == f2: # we need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    \n",
    "    # Set up plot\n",
    "    x1_lower, x1_upper = find_range(trainx[trainy==label,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[trainy==label,f2])\n",
    "    plt.xlim(x1_lower, x1_upper) # limit along x1-axis\n",
    "    plt.ylim(x2_lower, x2_upper) # limit along x2-axis\n",
    "    \n",
    "    # Plot the training points along the two selected features\n",
    "    plt.plot(trainx[trainy==label, f1], trainx[trainy==label, f2], 'ro')\n",
    "\n",
    "    # Define a grid along each axis; the density will be computed at each grid point\n",
    "    res = 200 # resolution\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Now plot a few contour lines of the density\n",
    "    mu, cov = fit_gaussian(trainx[trainy==label,:], [f1,f2])\n",
    "    plot_contours(mu, cov, x1g, x2g, 'k')\n",
    "    \n",
    "    # Finally, display\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.title('Class ' + str(label), fontsize=14, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit a Gaussian to each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that will fit a Gaussian generative model to the three classes, restricted to a given list of features. The function returns:\n",
    "* `mu`: the means of the Gaussians, one per row\n",
    "* `covar`: covariance matrices of each of the Gaussians\n",
    "* `pi`: list of three class weights summing to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes y takes on values 1,2,3\n",
    "def fit_generative_model(x, y, features):\n",
    "    k = 3 # number of classes\n",
    "    d = len(features) # number of features\n",
    "    mu = np.zeros((k+1,d)) # list of means\n",
    "    covar = np.zeros((k+1,d,d)) # list of covariance matrices\n",
    "    pi = np.zeros(k+1) # list of class weights\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y==label)\n",
    "        mu[label,:], covar[label,:,:] = fit_gaussian(x[indices,:], features)\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, covar, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the three Gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c1753a8c64493aa3c7aaaedeb2b40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def three_class_plot(f1,f2):\n",
    "    if f1 == f2: # we need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    \n",
    "    # Set up plot\n",
    "    x1_lower, x1_upper = find_range(trainx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[:,f2])\n",
    "    plt.xlim(x1_lower, x1_upper) # limit along x1-axis\n",
    "    plt.ylim(x2_lower, x2_upper) # limit along x2-axis\n",
    "    \n",
    "    # Plot the training points along the two selected features\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(trainx[trainy==label,f1], trainx[trainy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a grid along each axis; the density will be computed at each grid point\n",
    "    res = 200 # resolution\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Show the Gaussian fit to each class, using features f1,f2\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    for label in range(1,4):\n",
    "        gmean = mu[label,:]\n",
    "        gcov = covar[label,:,:]\n",
    "        plot_contours(gmean, gcov, x1g, x2g, colors[label-1])\n",
    "\n",
    "    # Finally, display\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.title('Wine data', fontsize=14, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict labels for the test points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well we can predict the class (1,2,3) based just on these two features?\n",
    "\n",
    "We start with a testing procedure that is analogous to what we developed in the 1-d case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d239178310bd4ae1a0494472e3d9540f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now test the performance of a predictor based on a subset of features\n",
    "@interact( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def test_model(f1, f2):\n",
    "    if f1 == f2: # need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    features= [f1,f2]\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, features)\n",
    "    \n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    nt = len(testy) # Number of test points\n",
    "    score = np.zeros((nt,k+1))\n",
    "    for i in range(0,nt):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            multivariate_normal.logpdf(testx[i,features], mean=mu[label,:], cov=covar[label,:,:])\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != testy)\n",
    "    print(\"Test error using feature(s): \")\n",
    "    for f in features:\n",
    "        print(\"'\" + featurenames[f] + \"'\" + \" \",)\n",
    "    print()\n",
    "    print(\"Errors: \" + str(errors) + \"/\" + str(nt))# Now test the performance of a predictor based on a subset of features\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different pairs of features yield different test errors.\n",
    "* What is the smallest achievable test error? \n",
    "3/48\n",
    "* Which pair of features achieves this minimum test error?\n",
    "6 and 9\n",
    "*Make a note of your answers to these questions, as you will need to enter them as part of this week's assignment.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The decision boundary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **show_decision_boundary** takes as input two features, builds a classifier based only on these two features, and shows a plot that contains both the training data and the decision boundary.\n",
    "\n",
    "To compute the decision boundary, a dense grid is defined on the two-dimensional input space and the classifier is applied to every grid point. The built-in `pyplot.contour` function can then be invoked to depict the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_decision_boundary(f1,f2):\n",
    "    # Fit Gaussian to each class\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    \n",
    "    # Set up dimensions of plot\n",
    "    x1_lower, x1_upper = find_range(trainx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[:,f2])\n",
    "    plt.xlim([x1_lower,x1_upper])\n",
    "    plt.ylim([x2_lower,x2_upper])\n",
    "\n",
    "    # Plot points in training set\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(trainx[trainy==label,f1], trainx[trainy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a dense grid; every point in the grid will be classified according to the generative model\n",
    "    res = 200\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Declare random variables corresponding to each class density\n",
    "    random_vars = {}\n",
    "    for label in range(1,4):\n",
    "        random_vars[label] = multivariate_normal(mean=mu[label,:],cov=covar[label,:,:])\n",
    "\n",
    "    # Classify every point in the grid; these are stored in an array Z[]\n",
    "    Z = np.zeros((len(x1g), len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            scores = []\n",
    "            for label in range(1,4):\n",
    "                scores.append(np.log(pi[label]) + random_vars[label].logpdf([x1g[i],x2g[j]]))\n",
    "            Z[i,j] = np.argmax(scores) + 1\n",
    "\n",
    "    # Plot the contour lines\n",
    "    plt.contour(x1g,x2g,Z.T,3,cmap='seismic')\n",
    "    \n",
    "    # Finally, show the image\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the function above to draw the decision boundary using features 0 ('alcohol') and 6 ('flavanoids')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_decision_boundary(0,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you add interactive sliders to function **show_decision_boundary**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3c971d551c4588bb8077ab50d51032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def show_decision_boundary(f1,f2):\n",
    "    # Fit Gaussian to each class\n",
    "    \n",
    "        \n",
    "    if f1 == f2: # need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return\n",
    "    \n",
    "\n",
    "\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    \n",
    "    # Set up dimensions of plot\n",
    "    x1_lower, x1_upper = find_range(trainx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[:,f2])\n",
    "    plt.xlim([x1_lower,x1_upper])\n",
    "    plt.ylim([x2_lower,x2_upper])\n",
    "\n",
    "    # Plot points in training set\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(trainx[trainy==label,f1], trainx[trainy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a dense grid; every point in the grid will be classified according to the generative model\n",
    "    res = 200\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Declare random variables corresponding to each class density\n",
    "    random_vars = {}\n",
    "    for label in range(1,4):\n",
    "        random_vars[label] = multivariate_normal(mean=mu[label,:],cov=covar[label,:,:])\n",
    "\n",
    "    # Classify every point in the grid; these are stored in an array Z[]\n",
    "    Z = np.zeros((len(x1g), len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            scores = []\n",
    "            for label in range(1,4):\n",
    "                scores.append(np.log(pi[label]) + random_vars[label].logpdf([x1g[i],x2g[j]]))\n",
    "            Z[i,j] = np.argmax(scores) + 1\n",
    "\n",
    "    # Plot the contour lines\n",
    "    plt.contour(x1g,x2g,Z.T,3,cmap='seismic')\n",
    "    \n",
    "    # Finally, show the image\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.title('Wine data', fontsize=14, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 3</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a plot similar to that of **show_decision_boundary**, but in which just the **test** data is shown.\n",
    "Look back at your answer to *Fast exercise 1*. Is it corroborated by your plot? Are the errors clearly visible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b104aa454b840dab7fc8062864ab594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def show_decision_boundary(f1,f2):\n",
    "    # Fit Gaussian to each class\n",
    "    \n",
    "        \n",
    "    if f1 == f2: # need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return\n",
    "    \n",
    "\n",
    "\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    \n",
    "    # Set up dimensions of plot\n",
    "    x1_lower, x1_upper = find_range(trainx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[:,f2])\n",
    "    plt.xlim([x1_lower,x1_upper])\n",
    "    plt.ylim([x2_lower,x2_upper])\n",
    "\n",
    "    # Plot points in training set\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(testx[testy==label,f1], testx[testy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a dense grid; every point in the grid will be classified according to the generative model\n",
    "    res = 200\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Declare random variables corresponding to each class density\n",
    "    random_vars = {}\n",
    "    for label in range(1,4):\n",
    "        random_vars[label] = multivariate_normal(mean=mu[label,:],cov=covar[label,:,:])\n",
    "\n",
    "    # Classify every point in the grid; these are stored in an array Z[]\n",
    "    Z = np.zeros((len(x1g), len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            scores = []\n",
    "            for label in range(1,4):\n",
    "                scores.append(np.log(pi[label]) + random_vars[label].logpdf([x1g[i],x2g[j]]))\n",
    "            Z[i,j] = np.argmax(scores) + 1\n",
    "\n",
    "    # Plot the contour lines\n",
    "    plt.contour(x1g,x2g,Z.T,3,cmap='seismic')\n",
    "    \n",
    "    # Finally, show the image\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.title('Wine data', fontsize=14, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
