{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<img src=\"Figs/GEOS_logo.pdf\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invert BC, InSAR and GNSS data (weighted and damped LSM): \n",
    "## <font color=blue>\"inversion_BC_InSAR_GNSS_weighting_damping.ipynb\"</font>\n",
    "#### Dec 20, 2021  <font color=red>(v. testing)</font>\n",
    "##### Jeonghyeop Kim (jeonghyeop.kim@gmail.com)\n",
    "\n",
    "1. This code is a part of the joint inversion project (project4: joint inversion of GNSS and InSAR)\n",
    "2. The G-matrix will be built using two types of basis functions : BC and FT \n",
    "3. Damped and Weighted LSM will be performed to find the best coefficients of the basis functions\n",
    "4. The goal is to find the best linear combination of the basis functions that predicted the data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_BC = sys.argv[1]\n",
    "weight_for_BC = float(weight_for_BC)\n",
    "weight_for_GNSS = weight_for_BC\n",
    "\n",
    "weight_for_InSAR = sys.argv[2]\n",
    "weight_for_InSAR = float(weight_for_InSAR)\n",
    "\n",
    "damping_for_horizontal = sys.argv[3]\n",
    "damping_for_horizontal = float(damping_for_horizontal)\n",
    "damping_for_rotation = damping_for_horizontal\n",
    "\n",
    "damping_for_vertical = sys.argv[4]\n",
    "damping_for_vertical = float(damping_for_vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 is simple LSM\n",
    "# 2 is Pseudo LSM \n",
    "# 3 is Damped LSM (Tikhonov)\n",
    "# 4 is Damped LSM ( WORKING...)\n",
    "\n",
    "inversion_flag = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output files\n",
    "outputFILE_GNSS_XandY=\"vel_GNSS_pred.gmt\" #Prediction for GNSS\n",
    "outputFILE_D=\"dsd_InSAR_pred.dat\" #Prediction for (Descending) InSAR\n",
    "outputFILE_A=\"asd_InSAR_pred.dat\" #Prediction for (Ascending) InSAR\n",
    "outputFILE_BC_XandY=\"vel_BC_pred.dat\" #Prediction for BC velocity field\n",
    "outputFILE_model=\"model_coef.dat\" # LSM model coefficients\n",
    "outputFILE_hori=\"vel_horizontal_cont_pred.gmt\" #Continuous horizontal field\n",
    "outputFILE_vert=\"vel_vertical_cont_pred.dat\" #Continuous vertical field \n",
    "outputFILE_strain=\"average_strain_cont_pred.out\" #Continuous Strain rate field (midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HowManyRot=38\n",
    "HowManyCell=360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `STEP 1:` **BUILD a data vector,  $\\vec{d}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input files\n",
    "\n",
    "# 1. Boundary velocity (on the boundary)\n",
    "inputBC = \"vel_BC_input.gmt\"  #velocity boundary condition\n",
    "df_inputBC = pd.read_csv(inputBC, header = None, sep =' ')\n",
    "df_inputBC.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "df_inputBC.loc[:,['ve']] = df_inputBC.loc[:,['ve']]  \n",
    "df_inputBC.loc[:,['vn']] = df_inputBC.loc[:,['vn']]\n",
    "\n",
    "# 2. GNSS data\n",
    "inputGNSS = \"vel_GNSS_input.gmt\"  # GNSS\n",
    "df_inputGNSS = pd.read_csv(inputGNSS, header = None, sep=r'(?:,|\\s+)', comment='#', engine='python')\n",
    "df_inputGNSS.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "df_inputGNSS.loc[:,['ve']] = df_inputGNSS.loc[:,['ve']] \n",
    "df_inputGNSS.loc[:,['vn']] = df_inputGNSS.loc[:,['vn']]\n",
    "\n",
    "# 2. InSAR Descending \n",
    "inputInSAR_D = \"dsd_InSAR_input.dat\"\n",
    "df_inputInSAR_D = pd.read_csv(inputInSAR_D, header = None, sep = ' ')\n",
    "df_inputInSAR_D.columns = ['lon','lat','velo','Px','Py','Pz']  \n",
    "df_inputInSAR_D.loc[:,['velo']] = df_inputInSAR_D.loc[:,['velo']]\n",
    "\n",
    "# 3. InSAR Ascending \n",
    "inputInSAR_A = \"asd_InSAR_input.dat\"\n",
    "df_inputInSAR_A = pd.read_csv(inputInSAR_A, header = None, sep = ' ')\n",
    "df_inputInSAR_A.columns = ['lon','lat','velo','Px','Py','Pz'] \n",
    "df_inputInSAR_A.loc[:,['velo']] = df_inputInSAR_A.loc[:,['velo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>NOTE: the pointing vectors are from the perspective of the ground! NOT of the satellite </b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################         GNSS         ######################################################    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "\n",
    "# BUILD GNSS data vector along with coordinate information.\n",
    "# The x components are first and then the y components of the GNSS velocity.\n",
    "df_data_x_GNSS = df_inputGNSS.iloc[:,[0,1,2]]  # saved vx data on the boudnary\n",
    "df_data_y_GNSS = df_inputGNSS.iloc[:,[0,1,3]]  # saved vn data on the boundary\n",
    "df_data_x_GNSS=df_data_x_GNSS.rename(columns ={'ve': 'velo'}) #column name change\n",
    "df_data_y_GNSS=df_data_y_GNSS.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "# !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "# This step is very important to build the G matrix, G, which\n",
    "# has rows correspoding to the rows of the data vector, d, that have\n",
    "# the same coordinates!\n",
    "df_data_x_GNSS=df_data_x_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "df_data_y_GNSS=df_data_y_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "\n",
    "# MERGE two columns (n*2) into a column (2n*1)\n",
    "# > ignore_index = True : \n",
    "# >   have one continuous index numbers,\n",
    "# >     ignorning each of the two dfs original indices\n",
    "framesGNSS=[df_data_x_GNSS,df_data_y_GNSS]\n",
    "df_data_GNSS_all=pd.concat(framesGNSS,ignore_index=True) # merge the two dataFrames into one\n",
    "\n",
    "# SAVE GNSS velocity separately\n",
    "df_data_GNSS=df_data_GNSS_all.loc[:,['velo']]\n",
    "\n",
    "\n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################       Boundary       ######################################################    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "\n",
    "# BUILD a boundary condition data vector along with coordinate information.\n",
    "# The x components are first and then the y components of the velocity.\n",
    "df_data_x_BC = df_inputBC.iloc[:,[0,1,2]]  # saved vx data on the boudnary\n",
    "df_data_y_BC = df_inputBC.iloc[:,[0,1,3]]  # saved vn data on the boundary\n",
    "df_data_x_BC=df_data_x_BC.rename(columns ={'ve': 'velo'}) #column name change\n",
    "df_data_y_BC=df_data_y_BC.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "# !! SORT_VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "# This step is very important to build the G matrix, G, which\n",
    "# has rows correspoding to the rows of the data vector, d, that have\n",
    "# the same coordinates!\n",
    "df_data_x_BC=df_data_x_BC.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "df_data_y_BC=df_data_y_BC.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "\n",
    "# MERGE two columns (n*2) into a column (2n*1)\n",
    "# > ignore_index = True : \n",
    "# >   have one continuous index numbers,\n",
    "# >     ignorning each of the two dfs original indices\n",
    "framesBC=[df_data_x_BC,df_data_y_BC]\n",
    "df_data_BC_all=pd.concat(framesBC,ignore_index=True) # merge the two dataFrames into one\n",
    "\n",
    "# SAVE BC velocity separately\n",
    "df_data_BC=df_data_BC_all.loc[:,['velo']]\n",
    "\n",
    "\n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################        InSAR         ######################################################    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "\n",
    "# BUILD a InSAR data vector along with coordinate information.\n",
    "# The rows of the InSAR data vector is in the order of descending-orbit data, and ascending-orbit data. \n",
    "# Track the pointing vector values together with the rate data for the G-matrix.\n",
    "\n",
    "# !! SORT_VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "# This step is very important to build the G matrix, G, which\n",
    "# has rows correspoding to the rows of the data vector, d, that have\n",
    "# the same coordinates!\n",
    "df_inputInSAR_D=df_inputInSAR_D.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "df_inputInSAR_A=df_inputInSAR_A.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "\n",
    "# MERGE two columns (n*2) into a column (2n*1)\n",
    "# > ignore_index = True : \n",
    "# >   have one continuous index numbers,\n",
    "# >     ignorning each of the two dfs original indices\n",
    "framesInSAR=[df_inputInSAR_D,df_inputInSAR_A]\n",
    "df_data_InSAR_all=pd.concat(framesInSAR,ignore_index=True) # merge the four dataFrames into one\n",
    "\n",
    "# SAVE InSAR velocity separately\n",
    "df_data_InSAR = df_data_InSAR_all.loc[:,['velo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the GNSS, InSAR, and BC data vectors into the final data vector\n",
    "framesFinal = [df_data_GNSS, df_data_InSAR, df_data_BC]\n",
    "df_data_total = pd.concat(framesFinal,ignore_index=True) # merge the two dataFrames into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_total.columns = ['data'] # DATA VECTOR [[GNSSx], [GNSSy], [InSAR_D], [InSAR_A], [BCx], [BCy]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `STEP 2:` **BUILD G-Matrix, $\\bar{\\bar{G}}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `STEP 2-a :` Build G matrix parts related to Rotations for Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G_BC_on_GNSS = pd.DataFrame(index = range(len(df_data_GNSS))) \n",
    "# Make a blank G matrix part related to Boundary Condition on GNSS points\n",
    "\n",
    "df_G_BC_on_BC= pd.DataFrame(index = range(len(df_data_BC))) \n",
    "# Make a blank G matrix part related to Boundary Condition on boundary points\n",
    "\n",
    "df_G_BC_on_InSAR = pd.DataFrame(index = range(len(df_data_InSAR))) \n",
    "# Make a blank G matrix part related to Boundary Condition on InSAR points\n",
    "# df_data_InSAR : velocity only\n",
    "# df_data_InSAR_all : lon lat vel px py pz\n",
    "df_px = df_data_InSAR_all.iloc[:,[3]]\n",
    "df_py = df_data_InSAR_all.iloc[:,[4]]\n",
    "df_pz = df_data_InSAR_all.iloc[:,[5]]\n",
    "\n",
    "\n",
    "continuous_sample = np.loadtxt('vel_hori_BC_1_1_continuous.gmt')\n",
    "continuous_XandY=len(continuous_sample)*2\n",
    "df_G_BC_continuous = pd.DataFrame(index = range(continuous_XandY)) \n",
    "# Make a blank G matrix part for continuous horizontal velocity\n",
    "# NOTE: no vertical motions in the BC basis functions \n",
    "\n",
    "midpoints_sample = np.loadtxt('average_strain_BC_1_1_RECTANGULAR.out')\n",
    "midpoints_XXandYYandXY = len(midpoints_sample)*3\n",
    "df_G_BC_on_midpoints_strain =pd.DataFrame(index = range(midpoints_XXandYYandXY)) \n",
    "# Make a blank G matrix part for strain\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,HowManyRot+1): \n",
    "\n",
    "    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################         GNSS         ######################################################    \n",
    "##################################################################################################################################\n",
    "################################################################################################################################## \n",
    "\n",
    "    \n",
    "    inputfile_xrot_GNSS = \"vel_BC_x_\"+str(f\"{i:03}\")+\"_on_GNSS.gmt\" # x-rot \n",
    "    inputfile_yrot_GNSS = \"vel_BC_y_\"+str(f\"{i:03}\")+\"_on_GNSS.gmt\" # y-rot \n",
    "    inputfile_zrot_GNSS = \"vel_BC_z_\"+str(f\"{i:03}\")+\"_on_GNSS.gmt\" # z-rot \n",
    "\n",
    "# READ files in order {xrot1, yrot1, zrot1, ..., xrotHowManyRot, yrotHowManyRot, zrotHowManyRot}\n",
    "\n",
    "    df_xrot_GNSS=pd.read_csv(inputfile_xrot_GNSS ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_yrot_GNSS=pd.read_csv(inputfile_yrot_GNSS ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_zrot_GNSS=pd.read_csv(inputfile_zrot_GNSS ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "\n",
    "# CHANGE the column names \n",
    "\n",
    "    df_xrot_GNSS.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_yrot_GNSS.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_zrot_GNSS.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    \n",
    "# BUILD a column vector Gx (i)\n",
    "\n",
    "    df_xrot_x_GNSS = df_xrot_GNSS.iloc[:,[0,1,2]]  # saved vx basis function on the GNSS data points\n",
    "    df_xrot_y_GNSS = df_xrot_GNSS.iloc[:,[0,1,3]]  # saved vn basis function on the GNSS data points\n",
    "\n",
    "    df_xrot_x_GNSS=df_xrot_x_GNSS.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_xrot_y_GNSS=df_xrot_y_GNSS.rename(columns ={'vn': 'velo'}) #column name change\n",
    "    \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_xrot_x_GNSS=df_xrot_x_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_xrot_y_GNSS=df_xrot_y_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gx_GNSS=[df_xrot_x_GNSS,df_xrot_y_GNSS]\n",
    "    df_Gx_GNSS=pd.concat(frames_Gx_GNSS,ignore_index=True) # merge the two dataFrames into one\n",
    "\n",
    "    \n",
    "    \n",
    "# BUILD a column vector Gy (i)\n",
    "\n",
    "    df_yrot_x_GNSS = df_yrot_GNSS.iloc[:,[0,1,2]]  # saved vx basis function on the GNSS data points\n",
    "    df_yrot_y_GNSS = df_yrot_GNSS.iloc[:,[0,1,3]]  # saved vn basis function on the GNSS data points\n",
    "\n",
    "    df_yrot_x_GNSS=df_yrot_x_GNSS.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_yrot_y_GNSS=df_yrot_y_GNSS.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_yrot_x_GNSS=df_yrot_x_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_yrot_y_GNSS=df_yrot_y_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Gy_GNSS=[df_yrot_x_GNSS,df_yrot_y_GNSS]\n",
    "    df_Gy_GNSS=pd.concat(frames_Gy_GNSS,ignore_index=True) # merge the two dataFrames into one\n",
    "    \n",
    "    \n",
    "# BUILD a column vector Gz (i)\n",
    "\n",
    "    df_zrot_x_GNSS = df_zrot_GNSS.iloc[:,[0,1,2]]  # saved vx basis function on the GNSS data points\n",
    "    df_zrot_y_GNSS = df_zrot_GNSS.iloc[:,[0,1,3]]  # saved vn basis function on the GNSS data points\n",
    "\n",
    "    df_zrot_x_GNSS=df_zrot_x_GNSS.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_zrot_y_GNSS=df_zrot_y_GNSS.rename(columns ={'vn': 'velo'}) #column name change\n",
    "   \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_zrot_x_GNSS=df_zrot_x_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_zrot_y_GNSS=df_zrot_y_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Gz_GNSS=[df_zrot_x_GNSS,df_zrot_y_GNSS]\n",
    "    df_Gz_GNSS=pd.concat(frames_Gz_GNSS,ignore_index=True) # merge the two dataFrames into one\n",
    "    \n",
    "    \n",
    "# SAVE G-matrix\n",
    "# Gmatrix = [Gxrot(1) Gyrot(1) Gzrot(1) ... Gxrot(HowManyRot) Gyrot(HowManyRot) Gzrot(HowManyRot)]\n",
    "    \n",
    "    df_G_BC_on_GNSS[\"G_xrot\"+str(i)] = df_Gx_GNSS.loc[:,['velo']]\n",
    "    df_G_BC_on_GNSS[\"G_yrot\"+str(i)] = df_Gy_GNSS.loc[:,['velo']]\n",
    "    df_G_BC_on_GNSS[\"G_zrot\"+str(i)] = df_Gz_GNSS.loc[:,['velo']]\n",
    "    \n",
    "    \n",
    "\n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################       Boundary       ######################################################    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    inputfile_xrot_on_boundary = \"vel_BC_x_\"+str(f\"{i:03}\")+\"_on_boundary.gmt\" # x-rot \n",
    "    inputfile_yrot_on_boundary = \"vel_BC_y_\"+str(f\"{i:03}\")+\"_on_boundary.gmt\" # y-rot \n",
    "    inputfile_zrot_on_boundary = \"vel_BC_z_\"+str(f\"{i:03}\")+\"_on_boundary.gmt\" # z-rot \n",
    "\n",
    "# READ files in order {xrot1, yrot1, zrot1, ..., xrotHowManyRot, yrotHowManyRot, zrotHowManyRot}\n",
    "\n",
    "    df_xrot_on_boundary=pd.read_csv(inputfile_xrot_on_boundary ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_yrot_on_boundary=pd.read_csv(inputfile_yrot_on_boundary ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_zrot_on_boundary=pd.read_csv(inputfile_zrot_on_boundary ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "\n",
    "# CHANGE the column names \n",
    "\n",
    "    df_xrot_on_boundary.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_yrot_on_boundary.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_zrot_on_boundary.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    \n",
    "# BUILD a column vector Gx (i)\n",
    "\n",
    "    df_xrot_x_on_boundary = df_xrot_on_boundary.iloc[:,[0,1,2]]  # saved vx basis function on the boudnary\n",
    "    df_xrot_y_on_boundary = df_xrot_on_boundary.iloc[:,[0,1,3]]  # saved vn basis function on the boundary\n",
    "\n",
    "    df_xrot_x_on_boundary=df_xrot_x_on_boundary.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_xrot_y_on_boundary=df_xrot_y_on_boundary.rename(columns ={'vn': 'velo'}) #column name change\n",
    "    \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_xrot_x_on_boundary=df_xrot_x_on_boundary.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_xrot_y_on_boundary=df_xrot_y_on_boundary.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gx_on_boundary=[df_xrot_x_on_boundary,df_xrot_y_on_boundary]\n",
    "    df_Gx_on_boundary=pd.concat(frames_Gx_on_boundary,ignore_index=True) # merge the two dataFrames into one\n",
    "\n",
    "    \n",
    "    \n",
    "# BUILD a column vector Gy (i)\n",
    "\n",
    "    df_yrot_x_on_boundary = df_yrot_on_boundary.iloc[:,[0,1,2]]  # saved vx basis function on the boudnary\n",
    "    df_yrot_y_on_boundary = df_yrot_on_boundary.iloc[:,[0,1,3]]  # saved vn basis function on the boundary\n",
    "\n",
    "    df_yrot_x_on_boundary=df_yrot_x_on_boundary.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_yrot_y_on_boundary=df_yrot_y_on_boundary.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "\n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_yrot_x_on_boundary=df_yrot_x_on_boundary.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_yrot_y_on_boundary=df_yrot_y_on_boundary.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Gy_on_boundary=[df_yrot_x_on_boundary,df_yrot_y_on_boundary]\n",
    "    df_Gy_on_boundary=pd.concat(frames_Gy_on_boundary,ignore_index=True) # merge the two dataFrames into one\n",
    "    \n",
    "    \n",
    "# BUILD a column vector Gz (i)\n",
    "\n",
    "    df_zrot_x_on_boundary = df_zrot_on_boundary.iloc[:,[0,1,2]]  # saved vx basis function on the boudnary\n",
    "    df_zrot_y_on_boundary = df_zrot_on_boundary.iloc[:,[0,1,3]]  # saved vn basis function on the boundary\n",
    "\n",
    "    df_zrot_x_on_boundary=df_zrot_x_on_boundary.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_zrot_y_on_boundary=df_zrot_y_on_boundary.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "   \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_zrot_x_on_boundary=df_zrot_x_on_boundary.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_zrot_y_on_boundary=df_zrot_y_on_boundary.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Gz_on_boundary=[df_zrot_x_on_boundary,df_zrot_y_on_boundary]\n",
    "    df_Gz_on_boundary=pd.concat(frames_Gz_on_boundary,ignore_index=True) # merge the two dataFrames into one\n",
    "    \n",
    "    \n",
    "# SAVE G-matrix\n",
    "# Gmatrix = [Gxrot(1) Gyrot(1) Gzrot(1) ... Gxrot(HowManyRot) Gyrot(HowManyRot) Gzrot(HowManyRot)]\n",
    "    \n",
    "    df_G_BC_on_boundary[\"G_xrot\"+str(i)] = df_Gx_on_boundary.loc[:,['velo']]\n",
    "    df_G_BC_on_boundary[\"G_yrot\"+str(i)] = df_Gy_on_boundary.loc[:,['velo']]\n",
    "    df_G_BC_on_boundary[\"G_zrot\"+str(i)] = df_Gz_on_boundary.loc[:,['velo']]\n",
    "\n",
    "    \n",
    "    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################        InSAR         ######################################################    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "\n",
    "\n",
    "    inputfile_xrot_InSAR = \"vel_BC_x_\"+str(f\"{i:03}\")+\"_on_InSAR.gmt\" # x-rot \n",
    "    inputfile_yrot_InSAR = \"vel_BC_y_\"+str(f\"{i:03}\")+\"_on_InSAR.gmt\" # y-rot \n",
    "    inputfile_zrot_InSAR = \"vel_BC_z_\"+str(f\"{i:03}\")+\"_on_InSAR.gmt\" # z-rot \n",
    "\n",
    "# READ files in order {xrot1, yrot1, zrot1, ..., xrotHowManyRot, yrotHowManyRot, zrotHowManyRot}\n",
    "\n",
    "    df_xrot_InSAR=pd.read_csv(inputfile_xrot_InSAR ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_yrot_InSAR=pd.read_csv(inputfile_yrot_InSAR ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_zrot_InSAR=pd.read_csv(inputfile_zrot_InSAR ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "\n",
    "# CHANGE the column names \n",
    "    # ve = Px\n",
    "    # vn = Py\n",
    "    # This is because later on ...\n",
    "    # 've' will be multiplied by a dataFrame named 'Px'\n",
    "    # 'vn' will be multiplied by a dataFrame named 'Py'\n",
    "    # pandas does NOT allow to multiply (element-wise) DataFrames if they have different names\n",
    "\n",
    "    df_xrot_InSAR.columns = ['lon','lat','Px','Py','se','sn','corr']  \n",
    "    df_yrot_InSAR.columns = ['lon','lat','Px','Py','se','sn','corr']\n",
    "    df_zrot_InSAR.columns = ['lon','lat','Px','Py','se','sn','corr']\n",
    "    \n",
    "\n",
    "    \n",
    "# SORT THEM by the same order of the InSAR data,\n",
    "# which was already sorted in the beginning of this code.\n",
    "    df_xrot_InSAR=df_xrot_InSAR.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_yrot_InSAR=df_yrot_InSAR.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_zrot_InSAR=df_zrot_InSAR.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "\n",
    "# STACK the entire basis function responses vertically TWICE!\n",
    "# InSAR data vector is made of TWO different data sets (Descending and Ascending Orbits)\n",
    "# But the 2 data sets are sampled in the same coordinates. \n",
    "    frames_xrot_stack_InSAR = [df_xrot_InSAR,df_xrot_InSAR]\n",
    "    df_xrot_stacked_InSAR=pd.concat(frames_xrot_stack_InSAR,ignore_index=True) # merge the two dataFrames into one    \n",
    "    frames_yrot_stack_InSAR = [df_yrot_InSAR,df_yrot_InSAR]\n",
    "    df_yrot_stacked_InSAR=pd.concat(frames_yrot_stack_InSAR,ignore_index=True) # merge the two dataFrames into one   \n",
    "    frames_zrot_stack_InSAR = [df_zrot_InSAR,df_zrot_InSAR]\n",
    "    df_zrot_stacked_InSAR=pd.concat(frames_zrot_stack_InSAR,ignore_index=True) # merge the two dataFrames into one\n",
    "    \n",
    "    \n",
    "# # BUILD a column vector Gx (i)\n",
    "    df_LOS_Gxrot_x_InSAR = df_xrot_stacked_InSAR.loc[:,['Px']] * df_px \n",
    "    df_LOS_Gxrot_y_InSAR = df_xrot_stacked_InSAR.loc[:,['Py']] * df_py\n",
    "    df_LOS_Gxrot_x_InSAR.columns=['Py'] # pandas doesn't add columns with different names directly\n",
    "    df_LOS_Gxrot_InSAR = df_LOS_Gxrot_x_InSAR + df_LOS_Gxrot_y_InSAR\n",
    "    \n",
    "\n",
    "    df_LOS_Gyrot_x_InSAR = df_yrot_stacked_InSAR.loc[:,['Px']] * df_px \n",
    "    df_LOS_Gyrot_y_InSAR = df_yrot_stacked_InSAR.loc[:,['Py']] * df_py\n",
    "    df_LOS_Gyrot_x_InSAR.columns=['Py'] # pandas doesn't add columns with different names directly\n",
    "    df_LOS_Gyrot_InSAR = df_LOS_Gyrot_x_InSAR + df_LOS_Gyrot_y_InSAR\n",
    "    \n",
    "\n",
    "    df_LOS_Gzrot_x_InSAR = df_zrot_stacked_InSAR.loc[:,['Px']] * df_px \n",
    "    df_LOS_Gzrot_y_InSAR = df_zrot_stacked_InSAR.loc[:,['Py']] * df_py\n",
    "    df_LOS_Gzrot_x_InSAR.columns=['Py'] # pandas doesn't add columns with different names directly\n",
    "    df_LOS_Gzrot_InSAR = df_LOS_Gzrot_x_InSAR + df_LOS_Gzrot_y_InSAR\n",
    "    \n",
    "\n",
    "# SAVE G-matrix\n",
    "# df_G_FT_on_InSAR_hori = [(xrot1_x*px + xrot1_y*py), ... , (zrotHowManyRot_x*px + zrotHowManyRot_y*py)]\n",
    "\n",
    "    \n",
    "    df_G_BC_on_InSAR[\"GxrotXPx+GxrotYPy \"+str(i)] = df_LOS_Gxrot_InSAR.loc[:,['Py']]\n",
    "    df_G_BC_on_InSAR[\"GyrotXPx+GyrotYPy \"+str(i)] = df_LOS_Gyrot_InSAR.loc[:,['Py']]\n",
    "    df_G_BC_on_InSAR[\"GzrotXPx+GzrotYPy \"+str(i)] = df_LOS_Gzrot_InSAR.loc[:,['Py']]\n",
    "\n",
    "    \n",
    "    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################   Continuous Field   ######################################################    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################    \n",
    "\n",
    "    inputfile_xrot_continuous = \"vel_BC_x_\"+str(f\"{i:03}\")+\"_continuous.gmt\" # x-rot \n",
    "    inputfile_yrot_continuous = \"vel_BC_y_\"+str(f\"{i:03}\")+\"_continuous.gmt\" # y-rot \n",
    "    inputfile_zrot_continuous = \"vel_BC_z_\"+str(f\"{i:03}\")+\"_continuous.gmt\" # z-rot \n",
    "\n",
    "# READ files in order {xrot1, yrot1, zrot1, ..., xrotHowManyRot, yrotHowManyRot, zrotHowManyRot}\n",
    "\n",
    "    df_xrot_continuous=pd.read_csv(inputfile_xrot_continuous ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_yrot_continuous=pd.read_csv(inputfile_yrot_continuous ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_zrot_continuous=pd.read_csv(inputfile_zrot_continuous ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "\n",
    "# CHANGE the column names \n",
    "\n",
    "    df_xrot_continuous.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_yrot_continuous.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_zrot_continuous.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    \n",
    "# BUILD a column vector Gx (i)\n",
    "\n",
    "    df_xrot_x_continuous = df_xrot_continuous.iloc[:,[0,1,2]]  # saved CONTINUOUS vx basis function \n",
    "    df_xrot_y_continuous = df_xrot_continuous.iloc[:,[0,1,3]]  # saved CONTINUOUS vn basis function \n",
    "\n",
    "    df_xrot_x_continuous=df_xrot_x_continuous.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_xrot_y_continuous=df_xrot_y_continuous.rename(columns ={'vn': 'velo'}) #column name change\n",
    "    \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_xrot_x_continuous=df_xrot_x_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_xrot_y_continuous=df_xrot_y_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gx_continuous=[df_xrot_x_continuous,df_xrot_y_continuous]\n",
    "    df_Gx_continuous=pd.concat(frames_Gx_continuous,ignore_index=True) # merge the two dataFrames into one\n",
    "\n",
    "    \n",
    "# BUILD a column vector Gy (i)\n",
    "\n",
    "    df_yrot_x_continuous = df_yrot_continuous.iloc[:,[0,1,2]]  # saved CONTINUOUS vx basis function\n",
    "    df_yrot_y_continuous = df_yrot_continuous.iloc[:,[0,1,3]]  # saved CONTINUOUS vn basis function\n",
    "\n",
    "    df_yrot_x_continuous=df_yrot_x_continuous.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_yrot_y_continuous=df_yrot_y_continuous.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_yrot_x_continuous=df_yrot_x_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_yrot_y_continuous=df_yrot_y_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Gy_continuous=[df_yrot_x_continuous,df_yrot_y_continuous]\n",
    "    df_Gy_continuous=pd.concat(frames_Gy_continuous,ignore_index=True) # merge the two dataFrames into one\n",
    "    \n",
    "    \n",
    "# BUILD a column vector Gz (i)\n",
    "\n",
    "    df_zrot_x_continuous = df_zrot_continuous.iloc[:,[0,1,2]]  # saved CONTINUOUS vx basis function \n",
    "    df_zrot_y_continuous = df_zrot_continuous.iloc[:,[0,1,3]]  # saved CONTINUOUS vn basis function\n",
    "\n",
    "    df_zrot_x_continuous=df_zrot_x_continuous.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_zrot_y_continuous=df_zrot_y_continuous.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_zrot_x_continuous=df_zrot_x_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_zrot_y_continuous=df_zrot_y_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Gz_continuous=[df_zrot_x_continuous,df_zrot_y_continuous]\n",
    "    df_Gz_continuous=pd.concat(frames_Gz_continuous,ignore_index=True) # merge the two dataFrames into one\n",
    "    \n",
    "    \n",
    "# SAVE G-matrix\n",
    "# Gmatrix = [Gxrot(1) Gyrot(1) Gzrot(1) ... Gxrot(HowManyRot) Gyrot(HowManyRot) Gzrot(HowManyRot)]\n",
    "    \n",
    "    df_G_BC_continuous[\"G_xrot\"+str(i)] = df_Gx_continuous.loc[:,['velo']]\n",
    "    df_G_BC_continuous[\"G_yrot\"+str(i)] = df_Gy_continuous.loc[:,['velo']]\n",
    "    df_G_BC_continuous[\"G_zrot\"+str(i)] = df_Gz_continuous.loc[:,['velo']]\n",
    "    \n",
    "\n",
    "\n",
    "#########STRAIN ###########\n",
    "\n",
    "    inputfile_strain_xrot = \"average_strain_BC_x_\"+str(f\"{i:03}\")+\"_RECTANGULAR.out\" # x-rot \n",
    "    inputfile_strain_yrot = \"average_strain_BC_y_\"+str(f\"{i:03}\")+\"_RECTANGULAR.out\" # y-rot \n",
    "    inputfile_strain_zrot = \"average_strain_BC_z_\"+str(f\"{i:03}\")+\"_RECTANGULAR.out\" # z-rot \n",
    "\n",
    "# READ files in order {xrot1, yrot1, zrot1, ..., xrotHowMany, yrotHowMany, zrotHowMany}\n",
    "    df_xrot_strain=pd.read_csv(inputfile_strain_xrot ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_yrot_strain=pd.read_csv(inputfile_strain_yrot ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_zrot_strain=pd.read_csv(inputfile_strain_zrot ,header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "# CHANGE the column names \n",
    "    df_xrot_strain.columns = ['num','lat','lon','exx','eyy','exy','sxx','syy','sxy']\n",
    "    df_yrot_strain.columns = ['num','lat','lon','exx','eyy','exy','sxx','syy','sxy']\n",
    "    df_zrot_strain.columns = ['num','lat','lon','exx','eyy','exy','sxx','syy','sxy']\n",
    "\n",
    "# BUILD a column vector Gx (i)\n",
    "    df_xrot_exx = df_xrot_strain.iloc[:,[2,1,3]]  # saved exx basis function on the midpoints for strain\n",
    "    df_xrot_eyy = df_xrot_strain.iloc[:,[2,1,4]]  # saved eyy basis function on the midpoints for strain\n",
    "    df_xrot_exy = df_xrot_strain.iloc[:,[2,1,5]]  # saved exy basis function on the midpoints for strain\n",
    "    \n",
    "    df_xrot_exx=df_xrot_exx.rename(columns ={'exx': 'strain'}) #column name change\n",
    "    df_xrot_eyy=df_xrot_eyy.rename(columns ={'eyy': 'strain'}) #column name change\n",
    "    df_xrot_exy=df_xrot_exy.rename(columns ={'exy': 'strain'}) #column name change\n",
    "    \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_xrot_exx=df_xrot_exx.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_xrot_eyy=df_xrot_eyy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_xrot_exy=df_xrot_exy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gx_strain=[df_xrot_exx,df_xrot_eyy,df_xrot_exy]\n",
    "    df_Gx_strain=pd.concat(frames_Gx_strain,ignore_index=True) # merge the three dataFrames into one\n",
    "    \n",
    "    \n",
    "# BUILD a column vector Gy (i)\n",
    "    df_yrot_exx = df_yrot_strain.iloc[:,[2,1,3]]  # saved exx basis function on the midpoints for strain\n",
    "    df_yrot_eyy = df_yrot_strain.iloc[:,[2,1,4]]  # saved eyy basis function on the midpoints for strain\n",
    "    df_yrot_exy = df_yrot_strain.iloc[:,[2,1,5]]  # saved exy basis function on the midpoints for strain\n",
    "    \n",
    "    df_yrot_exx=df_yrot_exx.rename(columns ={'exx': 'strain'}) #column name change\n",
    "    df_yrot_eyy=df_yrot_eyy.rename(columns ={'eyy': 'strain'}) #column name change\n",
    "    df_yrot_exy=df_yrot_exy.rename(columns ={'exy': 'strain'}) #column name change\n",
    "    \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_yrot_exx=df_yrot_exx.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_yrot_eyy=df_yrot_eyy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_yrot_exy=df_yrot_exy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gy_strain=[df_yrot_exx,df_yrot_eyy,df_yrot_exy]\n",
    "    df_Gy_strain=pd.concat(frames_Gy_strain,ignore_index=True) # merge the three dataFrames into one    \n",
    "    \n",
    "# BUILD a column vector Gz (i)\n",
    "    df_zrot_exx = df_zrot_strain.iloc[:,[2,1,3]]  # saved exx basis function on the midpoints for strain\n",
    "    df_zrot_eyy = df_zrot_strain.iloc[:,[2,1,4]]  # saved eyy basis function on the midpoints for strain\n",
    "    df_zrot_exy = df_zrot_strain.iloc[:,[2,1,5]]  # saved exy basis function on the midpoints for strain\n",
    "    \n",
    "    df_zrot_exx=df_zrot_exx.rename(columns ={'exx': 'strain'}) #column name change\n",
    "    df_zrot_eyy=df_zrot_eyy.rename(columns ={'eyy': 'strain'}) #column name change\n",
    "    df_zrot_exy=df_zrot_exy.rename(columns ={'exy': 'strain'}) #column name change\n",
    "    \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_zrot_exx=df_zrot_exx.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_zrot_eyy=df_zrot_eyy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_zrot_exy=df_zrot_exy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gz_strain=[df_zrot_exx,df_zrot_eyy,df_zrot_exy]\n",
    "    df_Gz_strain=pd.concat(frames_Gz_strain,ignore_index=True) # merge the three dataFrames into one \n",
    "    \n",
    "    \n",
    "    df_G_BC_on_midpoints_strain[\"G_xrot\"+str(i)] = df_Gx_strain.loc[:,['strain']]\n",
    "    df_G_BC_on_midpoints_strain[\"G_yrot\"+str(i)] = df_Gy_strain.loc[:,['strain']]\n",
    "    df_G_BC_on_midpoints_strain[\"G_zrot\"+str(i)] = df_Gz_strain.loc[:,['strain']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `STEP 2-b :` Build G matrix part related to Force Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G_FT_on_GNSS_eij = pd.DataFrame(index = range(len(df_data_GNSS))) \n",
    "df_G_FT_on_GNSS_ezz = pd.DataFrame(index = range(len(df_data_GNSS)))\n",
    "# Make a blank G matrix part related to Boundary Condition on GNSS data points\n",
    "\n",
    "df_G_FT_on_InSAR_hori = pd.DataFrame(index = range(len(df_data_InSAR))) \n",
    "df_G_FT_on_InSAR_vert = pd.DataFrame(index = range(len(df_data_InSAR))) \n",
    "# Make a blank G matrix part related to Force Terms on InSAR data points\n",
    "# df_data_InSAR : velocity only\n",
    "# df_data_InSAR_all : lon lat vel px py pz\n",
    "df_px = df_data_InSAR_all.iloc[:,[3]]\n",
    "df_py = df_data_InSAR_all.iloc[:,[4]]\n",
    "df_pz = df_data_InSAR_all.iloc[:,[5]]\n",
    "\n",
    "\n",
    "continuous_sample = np.loadtxt('vel_hori_FT_1_1_continuous.gmt')\n",
    "continuous_XandY=len(continuous_sample)*2\n",
    "continuous_Z=len(continuous_sample)\n",
    "\n",
    "df_G_FT_continuous_eij = pd.DataFrame(index = range(continuous_XandY)) \n",
    "df_G_FT_continuous_ezz = pd.DataFrame(index = range(continuous_XandY)) \n",
    "df_G_FT_continuous_zzz = pd.DataFrame(index = range(continuous_Z))\n",
    "# Make a blank G matrix part for velocity\n",
    "\n",
    "midpoints_sample = np.loadtxt('average_strain_FT_1_1_RECTANGULAR.out')\n",
    "midpoints_XXandYYandXY = len(midpoints_sample)*3\n",
    "\n",
    "df_G_FT_on_midpoints_eij =pd.DataFrame(index = range(midpoints_XXandYYandXY))\n",
    "df_G_FT_on_midpoints_ezz =pd.DataFrame(index = range(midpoints_XXandYYandXY))\n",
    "# Make a blank G matrix part for strain\n",
    "\n",
    "\n",
    "for i in range(1,HowManyCell+1): \n",
    "\n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################         GNSS         ######################################################    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################     \n",
    "    \n",
    "    inputfile_exx_GNSS = \"vel_hori_FT_\"+str(i)+\"_1\"+\"_on_GNSS.gmt\" #exx horizontal\n",
    "    inputfile_eyy_GNSS = \"vel_hori_FT_\"+str(i)+\"_2\"+\"_on_GNSS.gmt\" #eyy horizontal\n",
    "    inputfile_exy_GNSS = \"vel_hori_FT_\"+str(i)+\"_3\"+\"_on_GNSS.gmt\" #exy horizontal \n",
    "    inputfile_ezz_GNSS = \"vel_hori_FT_\"+str(i)+\"_4\"+\"_on_GNSS.gmt\" # z  horizontal\n",
    "    \n",
    "## READ files into two separate structures in the following orders:\n",
    "## 1st stru = {exx1, eyy1, exy1, ..., exxHowManyCell, eyyHowManyCell, exyHowManyCell} \n",
    "## 2nd stru = {z1 .. zHowManyCell}\n",
    "##\n",
    "## And then merge these two structures into one in the order of ...\n",
    "##            {exx1, eyy1, exy1, ..., exxHowManyCell, eyyHowManyCell, exyHowManyCell, z1 .. zHowManyCell}\n",
    "\n",
    "\n",
    "    df_exx_GNSS=pd.read_csv(inputfile_exx_GNSS, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_eyy_GNSS=pd.read_csv(inputfile_eyy_GNSS, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_exy_GNSS=pd.read_csv(inputfile_exy_GNSS, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')   \n",
    "    df_ezz_GNSS=pd.read_csv(inputfile_ezz_GNSS, header=None, sep=r'(?:,|\\s+)',\n",
    "                           comment='#', engine='python')\n",
    "\n",
    "# CHANGE the column names \n",
    "\n",
    "    df_exx_GNSS.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_eyy_GNSS.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_exy_GNSS.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_ezz_GNSS.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    \n",
    "# BUILD a column vector Gexx (i)\n",
    "\n",
    "    df_exx_x_GNSS = df_exx_GNSS.iloc[:,[0,1,2]]  # saved vx basis function on the GNSS data points\n",
    "    df_exx_y_GNSS = df_exx_GNSS.iloc[:,[0,1,3]]  # saved vn basis function on the GNSS data points\n",
    "\n",
    "    df_exx_x_GNSS=df_exx_x_GNSS.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_exx_y_GNSS=df_exx_y_GNSS.rename(columns ={'vn': 'velo'}) #column name change\n",
    "    \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_exx_x_GNSS=df_exx_x_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_exx_y_GNSS=df_exx_y_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gexx_GNSS=[df_exx_x_GNSS,df_exx_y_GNSS]\n",
    "    df_Gexx_GNSS=pd.concat(frames_Gexx_GNSS,ignore_index=True) # merge the two dataFrames into one\n",
    "\n",
    "# BUILD a column vector Geyy (i)\n",
    "\n",
    "    df_eyy_x_GNSS = df_eyy_GNSS.iloc[:,[0,1,2]]  # saved vx basis function on the GNSS data points\n",
    "    df_eyy_y_GNSS = df_eyy_GNSS.iloc[:,[0,1,3]]  # saved vn basis function on the GNSS data points\n",
    "\n",
    "    df_eyy_x_GNSS=df_eyy_x_GNSS.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_eyy_y_GNSS=df_eyy_y_GNSS.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_eyy_x_GNSS=df_eyy_x_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_eyy_y_GNSS=df_eyy_y_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Geyy_GNSS=[df_eyy_x_GNSS,df_eyy_y_GNSS]\n",
    "    df_Geyy_GNSS=pd.concat(frames_Geyy_GNSS,ignore_index=True) # merge the two dataFrames into one\n",
    "    \n",
    "# BUILD a column vector Gexy (i)\n",
    "\n",
    "    df_exy_x_GNSS = df_exy_GNSS.iloc[:,[0,1,2]]  # saved vx basis function on the GNSS data points\n",
    "    df_exy_y_GNSS = df_exy_GNSS.iloc[:,[0,1,3]]  # saved vn basis function on the GNSS data points\n",
    "\n",
    "    df_exy_x_GNSS=df_exy_x_GNSS.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_exy_y_GNSS=df_exy_y_GNSS.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "   \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_exy_x_GNSS=df_exy_x_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_exy_y_GNSS=df_exy_y_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Gexy_GNSS=[df_exy_x_GNSS,df_exy_y_GNSS]\n",
    "    df_Gexy_GNSS=pd.concat(frames_Gexy_GNSS,ignore_index=True) # merge the two dataFrames into one\n",
    "\n",
    "\n",
    "# BUILD a column vector G_ezz (i)\n",
    "\n",
    "    df_ezz_x_GNSS = df_ezz_GNSS.iloc[:,[0,1,2]]  # saved vx basis function on the GNSS data points\n",
    "    df_ezz_y_GNSS = df_ezz_GNSS.iloc[:,[0,1,3]]  # saved vn basis function on the GNSS data points\n",
    "\n",
    "    df_ezz_x_GNSS=df_ezz_x_GNSS.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_ezz_y_GNSS=df_ezz_y_GNSS.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "   \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_ezz_x_GNSS=df_ezz_x_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_ezz_y_GNSS=df_ezz_y_GNSS.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Gezz_GNSS=[df_ezz_x_GNSS,df_ezz_y_GNSS]\n",
    "    df_Gezz_GNSS=pd.concat(frames_Gezz_GNSS,ignore_index=True) # merge the two dataFrames into one (vertically)\n",
    "    \n",
    "    \n",
    "    \n",
    "# SAVE a part of G-matrix (as in two different structures and then they will be merged later)\n",
    "\n",
    "    # 1st structure = [Gexx(1) Geyy(1) Gexy(1) ... Gexx(HowManyCell) Geyy(HowManyCell) Gexy(HowManyCell)]   \n",
    "    df_G_FT_on_GNSS_eij[\"G_exx\"+str(i)] = df_Gexx_GNSS.loc[:,['velo']]\n",
    "    df_G_FT_on_GNSS_eij[\"G_eyy\"+str(i)] = df_Geyy_GNSS.loc[:,['velo']]\n",
    "    df_G_FT_on_GNSS_eij[\"G_exy\"+str(i)] = df_Gexy_GNSS.loc[:,['velo']]\n",
    "\n",
    "    # 2nd structure = [Gezz(1) Gezz(2) ... Gezz(HowManyCell)] \n",
    "    df_G_FT_on_GNSS_ezz[\"G_ezz\"+str(i)] = df_Gezz_GNSS.loc[:,['velo']]\n",
    "\n",
    "    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################       Boundary       ######################################################    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "    \n",
    "# A np.zeros matrix will be generated at the end of this block of the code\n",
    "    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################        InSAR         ######################################################    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "    \n",
    "    inputfile_exx_InSAR = \"vel_hori_FT_\"+str(i)+\"_1\"+\"_on_InSAR.gmt\" #exx horizontal\n",
    "    inputfile_eyy_InSAR = \"vel_hori_FT_\"+str(i)+\"_2\"+\"_on_InSAR.gmt\" #eyy horizontal\n",
    "    inputfile_exy_InSAR = \"vel_hori_FT_\"+str(i)+\"_3\"+\"_on_InSAR.gmt\" #exy horizontal \n",
    "    inputfile_ezz_InSAR = \"vel_vert_FT_\"+str(i)+\"_4\"+\"_on_InSAR.gmt\" # z  vertical\n",
    "    \n",
    "## READ files into two separate structures in the following orders:\n",
    "## 1st stru = {exx1_x*px + exx1_y*py, eyy1_x*px + eyy1_y*py , exy1_x*px + exy1_y*px, ..., \n",
    "##             eyyHowManyCell_x*px + eyyHowManyCell_y*py, exyHowManyCell_x*px + exyHowManyCell_y*py} \n",
    "## 2nd stru = {ezz1_z*pz, ezz2_z*pz, ..., ezzHowManyCell_z*pz}\n",
    "##\n",
    "## And then merge these two structures into one in the order of ...\n",
    "##            {exx1_x*px + exx1_y*py,...,exyHowManyCell_x*px + exyHowManyCell_y*py,ezz1_z*pz, ..., ezzHowManyCell_z*pz}\n",
    "\n",
    "\n",
    "    df_exx_InSAR=pd.read_csv(inputfile_exx_InSAR, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_eyy_InSAR=pd.read_csv(inputfile_eyy_InSAR, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_exy_InSAR=pd.read_csv(inputfile_exy_InSAR, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')   \n",
    "    df_ezz_InSAR=pd.read_csv(inputfile_ezz_InSAR, header=None, sep=r'(?:,|\\s+)',\n",
    "                           comment='#', engine='python')\n",
    "\n",
    "# CHANGE the column names \n",
    "\n",
    "    # ve = Px\n",
    "    # vn = Py\n",
    "    # vz = Pz \n",
    "    # This is because later on ...\n",
    "    # 've' will be multiplied by a dataFrame named 'Px'\n",
    "    # 'vn' will be multiplied by a dataFrame named 'Py'\n",
    "    # 'vz' will be multiplied by a dataFrame named 'Pz'\n",
    "    # pandas does NOT allow to multiply (element wise) two different DataFrames if they have different names\n",
    "    \n",
    "    df_exx.columns = ['lon','lat','Px','Py','se','sn','corr']\n",
    "    df_eyy.columns = ['lon','lat','Px','Py','se','sn','corr']\n",
    "    df_exy.columns = ['lon','lat','Px','Py','se','sn','corr']\n",
    "    df_ezz.columns = ['lon','lat','Pz']\n",
    "\n",
    "# SORT THEM by the same order of the InSAR data,\n",
    "# which was already sorted in the beginning of this code.\n",
    "    df_exx_InSAR=df_exx_InSAR.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_eyy_InSAR=df_eyy_InSAR.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_exy_InSAR=df_exy_InSAR.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_ezz_InSAR=df_ezz_InSAR.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "\n",
    "# STACK the entire basis function responses vertically TWICE!\n",
    "# InSAR data vector is made of TWO different data sets (Descending and Ascending Orbits)\n",
    "# But the 2 data sets are sampled in the same coordinates. \n",
    "    frames_exx_stack_InSAR = [df_exx_InSAR,df_exx_InSAR] # Two insar data sets!\n",
    "    df_exx_stacked_InSAR=pd.concat(frames_exx_stack_InSAR,ignore_index=True) \n",
    "    # merge the two dataFrames into one\n",
    "\n",
    "    frames_eyy_stack_InSAR = [df_eyy_InSAR,df_eyy_InSAR] # Two insar data sets!\n",
    "    df_eyy_stacked_InSAR=pd.concat(frames_eyy_stack_InSAR,ignore_index=True) \n",
    "    # merge the two dataFrames into one    \n",
    "\n",
    "    frames_exy_stack_InSAR = [df_exy_InSAR,df_exy_InSAR] # Two insar data sets!\n",
    "    df_exy_stacked_InSAR=pd.concat(frames_exy_stack_InSAR,ignore_index=True) \n",
    "    # merge the two dataFrames into one\n",
    "\n",
    "    frames_ezz_stack_InSAR = [df_ezz_InSAR,df_ezz_InSAR] # Two insar data sets!\n",
    "    df_ezz_stacked_InSAR=pd.concat(frames_ezz_stack_InSAR,ignore_index=True) \n",
    "    # merge the two dataFrames into one\n",
    "\n",
    "    \n",
    "    \n",
    "# # BUILD a column vector Gx (i)\n",
    "    df_LOS_Gexx_x_InSAR = df_exx_stacked_InSAR.loc[:,['Px']] * df_px \n",
    "    df_LOS_Gexx_y_InSAR = df_exx_stacked_InSAR.loc[:,['Py']] * df_py\n",
    "    df_LOS_Gexx_x_InSAR.columns=['Py'] # pandas doesn't add columns with different names directly\n",
    "    df_LOS_Gexx_InSAR = df_LOS_Gexx_x_InSAR + df_LOS_Gexx_y_InSAR\n",
    "    \n",
    "    \n",
    "    df_LOS_Geyy_x_InSAR = df_eyy_stacked_InSAR.loc[:,['Px']] * df_px \n",
    "    df_LOS_Geyy_y_InSAR = df_eyy_stacked_InSAR.loc[:,['Py']] * df_py\n",
    "    df_LOS_Geyy_x_InSAR.columns=['Py'] # pandas doesn't add columns with different names directly\n",
    "    df_LOS_Geyy_InSAR = df_LOS_Geyy_x_InSAR + df_LOS_Geyy_y_InSAR\n",
    "    \n",
    "    \n",
    "    df_LOS_Gexy_x_InSAR = df_exy_stacked_InSAR.loc[:,['Px']] * df_px \n",
    "    df_LOS_Gexy_y_InSAR = df_exy_stacked_InSAR.loc[:,['Py']] * df_py\n",
    "    df_LOS_Gexy_x_InSAR.columns=['Py'] # pandas doesn't add columns with different names directly\n",
    "    df_LOS_Gexy_InSAR = df_LOS_Gexy_x_InSAR + df_LOS_Gexy_y_InSAR\n",
    "\n",
    "    df_LOS_Gezz_InSAR = df_ezz_stacked_InSAR.loc[:,['Pz']] * df_pz\n",
    "    \n",
    "\n",
    "# SAVE G-matrix\n",
    "# df_G_FT_on_InSAR_hori = [(exx1_x*px + exx1_y*py), ... , (exyHowManyCell_x*px + exyHowManyCell_y*py)]\n",
    "    df_G_FT_on_InSAR_hori[\"GexxXPx+GexxYPy \"+str(i)] = df_LOS_Gexx_InSAR.loc[:,['Py']]\n",
    "    df_G_FT_on_InSAR_hori[\"GeyyXPx+GeyyYPy \"+str(i)] = df_LOS_Geyy_InSAR.loc[:,['Py']]\n",
    "    df_G_FT_on_InSAR_hori[\"GexyXPx+GexyYPy \"+str(i)] = df_LOS_Gexy_InSAR.loc[:,['Py']]\n",
    "    df_G_FT_on_InSAR_vert[\"GezzZPz \"+str(i)] = df_LOS_Gezz_InSAR['Pz']\n",
    "\n",
    "    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "######################################################   Continuous Field   ######################################################    \n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "    \n",
    "\n",
    "\n",
    "    inputfile_exx_continuous = \"vel_hori_FT_\"+str(i)+\"_1\"+\"_continuous.gmt\" #exx horizontal\n",
    "    inputfile_eyy_continuous = \"vel_hori_FT_\"+str(i)+\"_2\"+\"_continuous.gmt\" #eyy horizontal\n",
    "    inputfile_exy_continuous = \"vel_hori_FT_\"+str(i)+\"_3\"+\"_continuous.gmt\" #exy horizontal \n",
    "    inputfile_ezz_continuous = \"vel_hori_FT_\"+str(i)+\"_4\"+\"_continuous.gmt\" # z  horizontal   \n",
    "    inputfile_zzz_continuous = \"vel_vert_FT_\"+str(i)+\"_4\"+\"_continuous.gmt\" # z  vertical\n",
    "    \n",
    "    \n",
    "    df_exx_continuous=pd.read_csv(inputfile_exx_continuous, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_eyy_continuous=pd.read_csv(inputfile_eyy_continuous, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_exy_continuous=pd.read_csv(inputfile_exy_continuous, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')   \n",
    "    df_ezz_continuous=pd.read_csv(inputfile_ezz_continuous, header=None, sep=r'(?:,|\\s+)',\n",
    "                           comment='#', engine='python')\n",
    "    df_zzz_continuous=pd.read_csv(inputfile_zzz_continuous, header=None, sep=r'(?:,|\\s+)',\n",
    "                           comment='#', engine='python')\n",
    "    \n",
    "# CHANGE the column names \n",
    "\n",
    "    df_exx_continuous.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_eyy_continuous.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_exy_continuous.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_ezz_continuous.columns = ['lon','lat','ve','vn','se','sn','corr']\n",
    "    df_zzz_continuous.columns = ['lon','lat','vz']\n",
    "    \n",
    "    \n",
    "# BUILD a column vector Gexx (i)\n",
    "\n",
    "    df_exx_x_continuous = df_exx_continuous.iloc[:,[0,1,2]]  # saved CONTINUOUS vx basis function\n",
    "    df_exx_y_continuous = df_exx_continuous.iloc[:,[0,1,3]]  # saved CONTINUOUS vn basis function\n",
    "\n",
    "    df_exx_x_continuous=df_exx_x_continuous.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_exx_y_continuous=df_exx_y_continuous.rename(columns ={'vn': 'velo'}) #column name change\n",
    "    \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_exx_x_continuous=df_exx_x_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_exx_y_continuous=df_exx_y_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gexx_continuous=[df_exx_x_continuous,df_exx_y_continuous]\n",
    "    df_Gexx_continuous=pd.concat(frames_Gexx_continuous,ignore_index=True) # merge the two dataFrames into one\n",
    "\n",
    "    \n",
    "# BUILD a column vector Geyy (i)\n",
    "\n",
    "    df_eyy_x_continuous = df_eyy_continuous.iloc[:,[0,1,2]]  # saved CONTINUOS vx basis function\n",
    "    df_eyy_y_continuous = df_eyy_continuous.iloc[:,[0,1,3]]  # saved CONTINUOUS vn basis function\n",
    "\n",
    "    df_eyy_x_continuous=df_eyy_x_continuous.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_eyy_y_continuous=df_eyy_y_continuous.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_eyy_x_continuous=df_eyy_x_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_eyy_y_continuous=df_eyy_y_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Geyy_continuous=[df_eyy_x_continuous,df_eyy_y_continuous]\n",
    "    df_Geyy_continuous=pd.concat(frames_Geyy_continuous,ignore_index=True) # merge the two dataFrames into one\n",
    "    \n",
    "    \n",
    "# BUILD a column vector Gexy (i)\n",
    "    df_exy_x_continuous = df_exy_continuous.iloc[:,[0,1,2]]  # saved CONTINUOUS vx basis function\n",
    "    df_exy_y_continuous = df_exy_continuous.iloc[:,[0,1,3]]  # saved CONTINUOUS vn basis function\n",
    "\n",
    "    df_exy_x_continuous=df_exy_x_continuous.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_exy_y_continuous=df_exy_y_continuous.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "   \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_exy_x_continuous=df_exy_x_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_exy_y_continuous=df_exy_y_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Gexy_continuous=[df_exy_x_continuous,df_exy_y_continuous]\n",
    "    df_Gexy_continuous=pd.concat(frames_Gexy_continuous,ignore_index=True) # merge the two dataFrames into one\n",
    "\n",
    "\n",
    "# BUILD a column vector G_ezz (i)\n",
    "    df_ezz_x_continuous = df_ezz_continuous.iloc[:,[0,1,2]]  # saved CONTINUOUS vx basis function\n",
    "    df_ezz_y_continuous = df_ezz_continuous.iloc[:,[0,1,3]]  # saved CONTINUOUS vn basis function\n",
    "\n",
    "    df_ezz_x_continuous=df_ezz_x_continuous.rename(columns ={'ve': 'velo'}) #column name change\n",
    "    df_ezz_y_continuous=df_ezz_y_continuous.rename(columns ={'vn': 'velo'}) #column name change\n",
    "\n",
    "   \n",
    "    # !! SORT VALUES !! # lat (ascending) first, and then lon (ascending).\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_ezz_x_continuous=df_ezz_x_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_ezz_y_continuous=df_ezz_y_continuous.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    \n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices\n",
    "    frames_Gezz_continuous=[df_ezz_x_continuous,df_ezz_y_continuous]\n",
    "    df_Gezz_continuous=pd.concat(frames_Gezz_continuous,ignore_index=True) # merge the two dataFrames into one (vertically)\n",
    "    \n",
    "# BUILD a column vector G_zzz (i)   \n",
    "    df_zzz_continuous=df_zzz_continuous.sort_values(['lat','lon'], ascending=[True, True])\n",
    "    df_zzz_continuous=df_zzz_continuous.reset_index(drop=True)\n",
    "# SAVE a part of G-matrix (as in two different structures and then they will be merged later)\n",
    "\n",
    "    # 1st structure = [Gexx(1) Geyy(1) Gexy(1) ... Gexx(HowManyCell) Geyy(HowManyCell) Gexy(HowManyCell)]   \n",
    "    df_G_FT_continuous_eij[\"G_exx\"+str(i)] = df_Gexx_continuous.loc[:,['velo']]\n",
    "    df_G_FT_continuous_eij[\"G_eyy\"+str(i)] = df_Geyy_continuous.loc[:,['velo']]\n",
    "    df_G_FT_continuous_eij[\"G_exy\"+str(i)] = df_Gexy_continuous.loc[:,['velo']]\n",
    "\n",
    "    # 2nd structure = [Gezz(1) Gezz(2) ... Gezz(HowManyCell)] \n",
    "    df_G_FT_continuous_ezz[\"G_ezz\"+str(i)] = df_Gezz_continuous.loc[:,['velo']]\n",
    "    df_G_FT_continuous_zzz[\"G_zzz\"+str(i)] = df_zzz_continuous.loc[:,['vz']]\n",
    "    \n",
    "\n",
    "    \n",
    "#########STRAIN ###########\n",
    "    inputfile_strain_exx = \"average_strain_FT_\"+str(i)+\"_1_RECTANGULAR.out\" #exx strain \n",
    "    inputfile_strain_eyy = \"average_strain_FT_\"+str(i)+\"_2_RECTANGULAR.out\" #eyy strain \n",
    "    inputfile_strain_exy = \"average_strain_FT_\"+str(i)+\"_3_RECTANGULAR.out\" #exy strain \n",
    "    inputfile_strain_ezz = \"average_strain_FT_\"+str(i)+\"_4_RECTANGULAR.out\" #ezz strain \n",
    "\n",
    "    \n",
    "    df_exx_strain=pd.read_csv(inputfile_strain_exx, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_eyy_strain=pd.read_csv(inputfile_strain_eyy, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_exy_strain=pd.read_csv(inputfile_strain_exy, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')   \n",
    "    df_ezz_strain=pd.read_csv(inputfile_strain_ezz, header=None, sep=r'(?:,|\\s+)',\n",
    "                           comment='#', engine='python')\n",
    "    \n",
    "    df_exx_strain.columns = ['num','lat','lon','exx','eyy','exy','sxx','syy','sxy']\n",
    "    df_eyy_strain.columns = ['num','lat','lon','exx','eyy','exy','sxx','syy','sxy']\n",
    "    df_exy_strain.columns = ['num','lat','lon','exx','eyy','exy','sxx','syy','sxy']\n",
    "    df_ezz_strain.columns = ['num','lat','lon','exx','eyy','exy','sxx','syy','sxy']\n",
    "    \n",
    "    # BUILD a column vector Gexx (i) : STRAIN\n",
    "    df_exx_exx = df_exx_strain.iloc[:,[2,1,3]]  # saved exx basis function on the midpoints\n",
    "    df_exx_eyy = df_exx_strain.iloc[:,[2,1,4]]  # saved eyy basis function on the midpoints\n",
    "    df_exx_exy = df_exx_strain.iloc[:,[2,1,5]]  # saved exy basis function on the midpoints\n",
    "    df_exx_exx=df_exx_exx.rename(columns ={'exx': 'strain'}) #column name change\n",
    "    df_exx_eyy=df_exx_eyy.rename(columns ={'eyy': 'strain'}) #column name change\n",
    "    df_exx_exy=df_exx_exy.rename(columns ={'exy': 'strain'}) #column name change  \n",
    "    # !! SORT_VALUES !! # lat ascending first, and then lon ascending.\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_exx_exx=df_exx_exx.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_exx_eyy=df_exx_eyy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_exx_exy=df_exx_exy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gexx_strain=[df_exx_exx,df_exx_eyy,df_exx_exy]\n",
    "    df_Gexx_strain=pd.concat(frames_Gexx_strain,ignore_index=True) # merge the three dataFrames into one\n",
    "    \n",
    "    # BUILD a column vector Geyy (i) : STRAIN\n",
    "    df_eyy_exx = df_eyy_strain.iloc[:,[2,1,3]]  # saved exx basis function on the midpoints\n",
    "    df_eyy_eyy = df_eyy_strain.iloc[:,[2,1,4]]  # saved eyy basis function on the midpoints\n",
    "    df_eyy_exy = df_eyy_strain.iloc[:,[2,1,5]]  # saved exy basis function on the midpoints\n",
    "    df_eyy_exx=df_eyy_exx.rename(columns ={'exx': 'strain'}) #column name change\n",
    "    df_eyy_eyy=df_eyy_eyy.rename(columns ={'eyy': 'strain'}) #column name change\n",
    "    df_eyy_exy=df_eyy_exy.rename(columns ={'exy': 'strain'}) #column name change  \n",
    "    # !! SORT_VALUES !! # lat ascending first, and then lon ascending.\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_eyy_exx=df_eyy_exx.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_eyy_eyy=df_eyy_eyy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_eyy_exy=df_eyy_exy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Geyy_strain=[df_eyy_exx,df_eyy_eyy,df_eyy_exy]\n",
    "    df_Geyy_strain=pd.concat(frames_Geyy_strain,ignore_index=True) # merge the three dataFrames into one    \n",
    "    \n",
    "\n",
    "    # BUILD a column vector Gexy (i) : STRAIN\n",
    "    df_exy_exx = df_exy_strain.iloc[:,[2,1,3]]  # saved exx basis function on the midpoints\n",
    "    df_exy_eyy = df_exy_strain.iloc[:,[2,1,4]]  # saved eyy basis function on the midpoints\n",
    "    df_exy_exy = df_exy_strain.iloc[:,[2,1,5]]  # saved exy basis function on the midpoints\n",
    "    df_exy_exx=df_exy_exx.rename(columns ={'exx': 'strain'}) #column name change\n",
    "    df_exy_eyy=df_exy_eyy.rename(columns ={'eyy': 'strain'}) #column name change\n",
    "    df_exy_exy=df_exy_exy.rename(columns ={'exy': 'strain'}) #column name change  \n",
    "    # !! SORT_VALUES !! # lat ascending first, and then lon ascending.\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_exy_exx=df_exy_exx.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_exy_eyy=df_exy_eyy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_exy_exy=df_exy_exy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gexy_strain=[df_exy_exx,df_exy_eyy,df_exy_exy]\n",
    "    df_Gexy_strain=pd.concat(frames_Gexy_strain,ignore_index=True) # merge the three dataFrames into one   \n",
    "    \n",
    "\n",
    "    # BUILD a column vector Gezz (i) : STRAIN\n",
    "    df_ezz_exx = df_ezz_strain.iloc[:,[2,1,3]]  # saved exx basis function on the midpoints\n",
    "    df_ezz_eyy = df_ezz_strain.iloc[:,[2,1,4]]  # saved eyy basis function on the midpoints\n",
    "    df_ezz_exy = df_ezz_strain.iloc[:,[2,1,5]]  # saved exy basis function on the midpoints\n",
    "    df_ezz_exx=df_ezz_exx.rename(columns ={'exx': 'strain'}) #column name change\n",
    "    df_ezz_eyy=df_ezz_eyy.rename(columns ={'eyy': 'strain'}) #column name change\n",
    "    df_ezz_exy=df_ezz_exy.rename(columns ={'exy': 'strain'}) #column name change  \n",
    "    # !! SORT_VALUES !! # lat ascending first, and then lon ascending.\n",
    "    # This step is very important to build the G matrix, G, which\n",
    "    # has rows correspoding to the rows of the data vector, d, that have\n",
    "    # the same coordinates!\n",
    "    df_ezz_exx=df_ezz_exx.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_ezz_eyy=df_ezz_eyy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    df_ezz_exy=df_ezz_exy.sort_values(['lat', 'lon'], ascending=[True, True])\n",
    "    # MERGE two columns (n*1) into a new column (2n*1)\n",
    "    # > ignore_index = True : \n",
    "    # >   have one continuous index numbers,\n",
    "    # >     ignorning each of the two dfs original indices   \n",
    "    frames_Gezz_strain=[df_ezz_exx,df_ezz_eyy,df_ezz_exy]\n",
    "    df_Gezz_strain=pd.concat(frames_Gezz_strain,ignore_index=True) # merge the three dataFrames into one     \n",
    "    \n",
    "    \n",
    "\n",
    "    df_G_FT_on_midpoints_eij[\"G_exx\"+str(i)] = df_Gexx_strain.loc[:,['strain']]\n",
    "    df_G_FT_on_midpoints_eij[\"G_eyy\"+str(i)] = df_Geyy_strain.loc[:,['strain']]\n",
    "    df_G_FT_on_midpoints_eij[\"G_exy\"+str(i)] = df_Gexy_strain.loc[:,['strain']]\n",
    "\n",
    "    # 2nd structure = [Gezz(1) Gezz(2) ... Gezz(HowManyCell)] \n",
    "    df_G_FT_on_midpoints_ezz[\"G_ezz\"+str(i)] = df_Gezz_strain.loc[:,['strain']]\n",
    "    \n",
    "\n",
    "    \n",
    "# GNSS: Merge the two structures horizontally !\n",
    "frames_Geij_Gezz = [df_G_FT_on_GNSS_eij, df_G_FT_on_GNSS_ezz]\n",
    "df_G_FT_on_GNSS=pd.concat(frames_Geij_Gezz, axis=1) # merge the two dataFrames into one\n",
    "\n",
    "# BC: Make a blank G matrix part related to Force Terms for Boundary Conditions == zeros\n",
    "df_G_FT_on_boundary = pd.DataFrame(np.zeros((len(df_data_BC),HowManyCell*4)), columns=df_G_FT_on_GNSS.columns) \n",
    "\n",
    "# InSAR: Merge the two structures horizontally !\n",
    "frames_FT_InSAR=[df_G_FT_on_InSAR_hori, df_G_FT_on_InSAR_vert]\n",
    "df_G_FT_on_InSAR = pd.concat(frames_FT_InSAR, axis=1)  \n",
    "\n",
    "# Continuous velocity Field (regular_lat_lon): Merge the two structures horizontally !\n",
    "frames_Geij_Gezz = [df_G_FT_continuous_eij, df_G_FT_continuous_ezz]\n",
    "df_G_FT_continuous=pd.concat(frames_Geij_Gezz, axis=1) # merge the two dataFrames into one\n",
    "\n",
    "# Strain Field (Midpoints): Merge the two structures horizontally ! FOR strain\n",
    "frames_Geij_Gezz_strain = [df_G_FT_on_midpoints_eij, df_G_FT_on_midpoints_ezz]\n",
    "df_G_FT_on_midpoints_strain=pd.concat(frames_Geij_Gezz_strain, axis=1) # merge the two dataFrames into one  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `STEP 2-c :` Build the complete G matrix for the inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNSS part FT and BC\n",
    "frames_FT_BC_on_GNSS = [df_G_FT_on_GNSS, df_G_BC_on_GNSS]\n",
    "df_G_FT_BC_on_GNSS = pd.concat(frames_FT_BC_on_GNSS, axis=1) #merge the two DataFrames into one DF horizontally (axis = 1)\n",
    " \n",
    "# InSAR part FT and BC\n",
    "frames_FT_BC_on_InSAR = [df_G_FT_on_InSAR, df_G_BC_on_InSAR]\n",
    "df_G_FT_BC_on_InSAR = pd.concat(frames_FT_BC_on_InSAR, axis=1) #merge the two DataFrames into one DF horizontally (axis = 1)\n",
    "\n",
    "# boundary part FT and BC\n",
    "frame_FT_BC_on_boundary = [df_G_FT_on_boundary, df_G_BC_on_boundary]\n",
    "df_G_FT_BC_on_boundary = pd.concat(frame_FT_BC_on_boundary, axis=1) #merge the two DataFrames into one DF horizontally (axis = 1)\n",
    "\n",
    "##################################################################################################################################\n",
    "\n",
    "df_G_FT_BC_on_boundary.columns = df_G_FT_BC_on_InSAR.columns\n",
    "df_G_FT_BC_on_GNSS.columns = df_G_FT_BC_on_InSAR.columns\n",
    "# change column names of the df_G_FT_BC_on_boundary\n",
    "# change column names of the df_G_FT_BC_on_GNSS\n",
    "\n",
    "frames_FT_BC_final=[df_G_FT_BC_on_GNSS, df_G_FT_BC_on_InSAR, df_G_FT_BC_on_boundary]\n",
    "df_G_final = pd.concat(frames_FT_BC_final, ignore_index=True) #merge the two dataFrames into one vertically (axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_data_total)!=len(df_G_final):\n",
    "    print(\"WARNING: Something went wrong!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `STEP 3:` RUN Joint Inversion (LSM)\n",
    "> G-matrix = **df_G_final** \\\n",
    "> data vec = **df_data_total**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Diagonal Weighting Matrix W\n",
    "nGNSS=len(df_data_GNSS)\n",
    "nBC=len(df_data_BC)\n",
    "nInSAR=len(df_data_InSAR)\n",
    "nTotal=len(df_data_total)\n",
    "\n",
    "errorGNSS = np.ones(nGNSS)*weight_for_GNSS\n",
    "errorInSAR = np.ones(nInSAR)*weight_for_InSAR \n",
    "errorBC = np.ones(nBC)*weight_for_BC\n",
    "\n",
    "errorTotal = np.concatenate((errorGNSS,errorInSAR, errorBC),axis=0)\n",
    "errorTotalinv = 1/errorTotal\n",
    "W = np.diag(errorTotalinv)\n",
    "\n",
    "# convert into a dataframe\n",
    "dfW = pd.DataFrame(W)\n",
    "\n",
    "# When calculating predictions, the non-weighted G-matrix is needed. \n",
    "# SAVE it!\n",
    "df_G_final_save = df_G_final\n",
    "\n",
    "# When calculating the misfit, the non-weighted data is needed. \n",
    "# SAVE it!\n",
    "df_data_total_save = df_data_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the Diagonal Weighting Matrix dfW to the data vector and Gmatrix\n",
    "\n",
    "df_G_final = dfW @ df_G_final_save\n",
    "df_data_total = dfW @ df_data_total_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G_prime = df_G_final.transpose() \n",
    "\n",
    "# G'G\n",
    "# >Two different ways to compute a matrix multiplication\n",
    "# >1st method\n",
    "GpG1=df_G_prime.dot(df_G_final) #G'G\n",
    "# >2nd method\n",
    "GpG2=df_G_prime @ df_G_final #G'G\n",
    "# >These results are same.\n",
    "# >Let's take the second one as G'G\n",
    "GpG = GpG2 #GpG is G'G\n",
    "# inv(G'G)\n",
    "# > Two different ways to obtain inverse matrix\n",
    "# > 1st method: np.linalg.inv \n",
    "\n",
    "\n",
    "###############################\n",
    "## inv(G'G)*G'*d = model(LSM) #\n",
    "###############################\n",
    "if inversion_flag == 1:\n",
    "    # > 1st method: np.linalg.inv\n",
    "    df_inv_GpG = pd.DataFrame(np.linalg.inv(GpG.to_numpy()), GpG.columns, GpG.index)\n",
    "    df_model1=df_inv_GpG@df_G_prime@df_data_total #inversion\n",
    "    \n",
    "elif inversion_flag == 2:\n",
    "    # > 2nd method: np.linalg.pinv (Moore-Penrose inverse (SVD))\n",
    "    df_pinv_GpG = pd.DataFrame(np.linalg.pinv(GpG.to_numpy()), GpG.columns, GpG.index)\n",
    "    df_model1=df_pinv_GpG@df_G_prime@df_data_total #pseudo inversion\n",
    "    \n",
    "elif inversion_flag == 3:\n",
    "    # > 3rd method: Damping (Tikhonov Regularization)\n",
    "    alp=damping_for_horizontal*np.ones((360*3,1))**2 # damping parameter for hori\n",
    "    bet=damping_for_vertical*np.ones((360,1))**2 # damping parameter for vert\n",
    "    gam=damping_for_rotation*np.ones((38*3,1))**2 # damping parameter for rot\n",
    "    array_tuple = (alp, bet, gam)\n",
    "    lamb = np.vstack(array_tuple) \n",
    "    lamb = lamb[:,0]\n",
    "    damping_matrix=np.diag(lamb) # a*a*I    \n",
    "    GpG_damping = GpG + damping_matrix #(G'G + a*a*I)\n",
    "    GpD=df_G_prime@df_data_total\n",
    "    df_model_damping= np.linalg.solve(GpG_damping,GpD)\n",
    "    df_model1=pd.DataFrame(df_model_damping[:,0])\n",
    "    df_model1.index=df_G_final_save.columns.values  \n",
    "else: \n",
    "######################################\n",
    "#       Try L1 for model norm        #\n",
    "#              EDIT HERE             #\n",
    "######################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_data_predicted = df_G_final_save @ df_model1\n",
    "# 'df_G_final_save' is the non-weighted G-matrix\n",
    "\n",
    "# squared norm2 misfit\n",
    "df_norm2=(df_data_total_save.to_numpy()-df_data_predicted.to_numpy())**2\n",
    "df_norm2=df_norm2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the predicted data vector into\n",
    "# (1) GNSS x and y\n",
    "# (2) InSAR 1\n",
    "# (3) InSAR 2\n",
    "# (4) BC vel x and y\n",
    "\n",
    "num_velo_pointGNSS=len(df_data_GNSS_all) # GNSS\n",
    "num_velo_pointGNSS=int(num_velo_point0)\n",
    "\n",
    "num_velo_pointInSAR=len(df_data_InSAR_all)/2  # 2 InSAR data sets in a column vector\n",
    "num_velo_pointInSAR=int(num_velo_point1)\n",
    "\n",
    "num_velo_pointBC=len(df_data_BC_all) #BC vel\n",
    "num_velo_pointBC=int(num_velo_point2)\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "#####  GNSS  #######\n",
    "####################\n",
    "\n",
    "#GNSS predicted x\n",
    "df_prediction_GNSS_x=df_data_predicted.iloc[0:int(num_velo_pointGNSS/2)] \n",
    "df_prediction_GNSS_x=df_prediction_GNSS_x.reset_index(drop=True)\n",
    "#BC predicted y\n",
    "df_prediction_GNSS_y=df_data_predicted.iloc[int(num_velo_pointGNSS/2):num_velo_pointGNSS] \n",
    "df_prediction_GNSS_y=df_prediction_GNSS_y.reset_index(drop=True)\n",
    "\n",
    "# Coordinate Template To Save Predicted BC Data\n",
    "df_GNSS_save = df_data_GNSS_all.iloc[0:int(num_velo_pointGNSS/2),[0,1]]\n",
    "\n",
    "df_save_GNSS_XandY = df_GNSS_save.reset_index(drop=True)\n",
    "df_save_GNSS_XandY['vx'] = df_prediction_GNSS_x\n",
    "df_save_GNSS_XandY['vn'] = df_prediction_GNSS_y\n",
    "df_save_GNSS_XandY['se'] = np.zeros(len(df_prediction_GNSS_y))\n",
    "df_save_GNSS_XandY['sn'] = np.zeros(len(df_prediction_GNSS_y))\n",
    "df_save_GNSS_XandY['corr'] = np.zeros(len(df_prediction_GNSS_y))\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "#####  INSAR  #######\n",
    "#####################\n",
    "\n",
    "df_prediction_D=df_data_predicted.iloc[num_velo_pointGNSS:num_velo_pointGNSS+num_velo_pointInSAR] #dLOS Descending\n",
    "df_prediction_D=df_prediction_D.reset_index(drop=True)\n",
    "\n",
    "df_prediction_A=df_data_predicted.iloc[num_velo_pointGNSS+num_velo_pointInSAR:num_velo_pointGNSS+2*num_velo_pointInSAR] #dLOS Ascending\n",
    "df_prediction_A=df_prediction_A.reset_index(drop=True)\n",
    "\n",
    "# Coordinate Template To Save Predicted InSAR Data\n",
    "df_InSAR_save = df_inputInSAR1.iloc[:,[0,1]]   \n",
    "\n",
    "df_save_D = df_InSAR_save.reset_index(drop=True)\n",
    "df_save_D['dLOS'] = df_prediction_D #append predicted dLOS Descending\n",
    "df_save_D['dLOS'] = df_save_D['dLOS']\n",
    "\n",
    "df_save_A = df_InSAR_save.reset_index(drop=True)\n",
    "df_save_A['dLOS'] = df_prediction_A #append predicted dLOS Ascending\n",
    "df_save_A['dLOS'] = df_save_A['dLOS']\n",
    "\n",
    "########################\n",
    "#####  Boundary ########\n",
    "########################\n",
    "\n",
    "#BC predicted x\n",
    "df_prediction_BC_x=df_data_predicted.iloc[num_velo_pointGNSS+2*num_velo_pointInSAR:num_velo_pointGNSS+2*num_velo_pointInSAR+int(num_velo_pointBC/2)] \n",
    "df_prediction_BC_x=df_prediction_BC_x.reset_index(drop=True)\n",
    "#BC predicted y\n",
    "df_prediction_BC_y=df_data_predicted.iloc[num_velo_pointGNSS+2*num_velo_pointInSAR+int(num_velo_pointBC/2):num_velo_pointGNSS+2*num_velo_pointInSAR+num_velo_pointBC] \n",
    "df_prediction_BC_y=df_prediction_BC_y.reset_index(drop=True)\n",
    "# Coordinate Template To Save Predicted BC Data\n",
    "df_BC_save = df_data_BC_all.iloc[0:int(num_velo_pointBC/2),[0,1]]\n",
    "df_save_BC_XandY = df_BC_save.reset_index(drop=True)\n",
    "df_save_BC_XandY['vx'] = df_prediction_BC_x\n",
    "df_save_BC_XandY['vn'] = df_prediction_BC_y\n",
    "df_save_BC_XandY['se'] = np.zeros(len(df_prediction_BC_y))\n",
    "df_save_BC_XandY['sn'] = np.zeros(len(df_prediction_BC_y))\n",
    "df_save_BC_XandY['corr'] = np.zeros(len(df_prediction_BC_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE predicted data sets\n",
    "df_save_GNSS_XandY.to_csv(outputFILE_GNSS_XandY, header=None, index=None, sep=' ', float_format='%g')\n",
    "df_save_D.to_csv(outputFILE_D, header=None, index=None, sep=' ',float_format='%g')\n",
    "df_save_A.to_csv(outputFILE_A, header=None, index=None, sep=' ',float_format='%g')\n",
    "df_save_BC_XandY.to_csv(outputFILE_BC_XandY, header=None, index=None, sep=' ', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE model coefficients\n",
    "df_model1.to_csv(outputFILE_model, header=None, index=None, float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"chi-square statistics is : %f [mm/yr]**2\"  % df_norm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<div class=\"alert--icon\"> <i class=\"far fa-times-circle\"></i> </div>\n",
    "    <p> Weighted Tikhonov Regularization works pretty well. </p>\n",
    "    <b> But this approach cannot resolve short-wavelength features. </b>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b> TRY the L1 regularization. </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `STEP 4:` Obtain 3-D continuous surface velocity & horizontal strain field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#                         Horizontal continuous velocity model.                        #\n",
    "########################################################################################\n",
    "frames_horizontal = [df_G_FT_continuous, df_G_BC_continuous]\n",
    "df_G_horizontal_continuous=pd.concat(frames_horizontal, axis=1) # merge the two dataFrames into one\n",
    "continuous_hor_model = df_G_horizontal_continuous.to_numpy() @ df_model1.to_numpy()\n",
    "continuous_num=int(len(continuous_hor_model)/2)\n",
    "Xmodel=continuous_hor_model[0:continuous_num,0]\n",
    "Ymodel=continuous_hor_model[continuous_num:,0]\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "#                         Vertical continuous velocity model.                          #\n",
    "########################################################################################\n",
    "df_G_vertical_continuous=df_G_FT_continuous_zzz\n",
    "continuous_ver_model = df_G_vertical_continuous.to_numpy() @ df_model1.to_numpy()[HowManyCell*3:HowManyCell*4,]\n",
    "Zmodel=continuous_ver_model[:,0]\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "#                         Horizontal continuous strain rate model.                     #\n",
    "########################################################################################\n",
    "frames_horizontal_strain = [df_G_FT_on_midpoints_strain, df_G_BC_on_midpoints_strain]\n",
    "df_G_horizontal_continuous_strain=pd.concat(frames_horizontal_strain, axis=1) # merge the two dataFrames into one\n",
    "continuous_hor_model_strain = df_G_horizontal_continuous_strain.to_numpy() @ df_model1.to_numpy()\n",
    "midpointnum=int(len(continuous_hor_model_strain)/3)\n",
    "eXXmodel=continuous_hor_model_strain[0:midpointnum,0]\n",
    "eYYmodel=continuous_hor_model_strain[midpointnum:2*midpointnum,0]\n",
    "eXYmodel=continuous_hor_model_strain[2*midpointnum:3*midpointnum,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE continuous 3-D velocity field.\n",
    "df_hori = df_zzz.loc[:,['lon','lat']]\n",
    "df_hori['ve'] = Xmodel\n",
    "df_hori['vn'] = Ymodel\n",
    "df_hori['se'] = np.zeros(len(Ymodel))\n",
    "df_hori['sn'] = np.zeros(len(Ymodel))\n",
    "df_hori['corr'] = np.zeros(len(Ymodel))\n",
    "\n",
    "df_vert = df_zzz.loc[:,['lon','lat']]\n",
    "df_vert['vz'] = Zmodel\n",
    "\n",
    "df_hori.to_csv(outputFILE_hori, header=None, index=None, sep=' ', float_format='%g')\n",
    "df_vert.to_csv(outputFILE_vert, header=None, index=None, sep=' ', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE horizontal strain rate field.\n",
    "df_strain=df_xrot_exx.loc[:,['lon','lat']]\n",
    "df_strain['exx']=eXXmodel\n",
    "df_strain['eyy']=eYYmodel\n",
    "df_strain['exy']=eXYmodel\n",
    "df_strain['num']=range(len(eXXmodel))\n",
    "df_strain['sxx']=np.zeros((len(eXXmodel),))\n",
    "df_strain['syy']=np.zeros((len(eXXmodel),))\n",
    "df_strain['sxy']=np.zeros((len(eXXmodel),))\n",
    "df_strain_save = df_strain[['num','lat','lon','exx','eyy','exy','sxx','syy','sxy']]\n",
    "\n",
    "df_strain_save.to_csv(outputFILE_strain, header=None, index=None, sep=' ', float_format='%g')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
