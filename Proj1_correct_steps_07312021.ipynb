{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GEOS_Logo.png\" width=\"700\" />\n",
    "\n",
    "# Step 6: <font color=blue>\"correct_steps.ipynb\"</font>\n",
    "#### July 31, 2021  <font color=red>(still working)</font> \n",
    "##### Jeonghyeop Kim (jeonghyeop.kim@gmail.com)\n",
    "\n",
    "> input file(s)  : **`time_vector.dat`, `steps.txt` ,`list_full.dat` , `list_extra.dat` & `edited_i`** \\\n",
    "> output file(s) : **`edited_i_corrected`** \\\n",
    "> module(s) used : **`ismember.py`**\n",
    "\n",
    "0. This code is a part of GPS2FNL process \n",
    "1. A GNSS timeseries for years usually has a few discontinuous steps related to maintenance of equipments\n",
    "2. The Nevada Geodetic Lab provides metadata that provide information about these two types of steps. \n",
    "> http://geodesy.unr.edu/NGLStationPages/steps.txt (download this file in the begining of the master shell script)\n",
    "3. This code downloads metadata and will uses to correct listed steps. \n",
    "4. Step correction algorithm is proposed by *Johnson et al., 2021 (Earth and Space Science)*\n",
    "5. This algorithm does NOT correct for coseismic signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from ismember import ismember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a list of all stations (e.g., 907 stations for california)\n",
    "> For some reasons, two list files exist (7/30/2021) \n",
    "> change this later after the STEP 1 and STEP 2 codes are ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of stations for the analysis is 907\n"
     ]
    }
   ],
   "source": [
    "list1 = \"list_full.dat\"\n",
    "df_list1=pd.read_csv(list1, header=None)\n",
    "\n",
    "list2 = \"list_extra.dat\"\n",
    "df_list2=pd.read_csv(list2, header=None)\n",
    "\n",
    "frames=[df_list1,df_list2]\n",
    "df_list=pd.concat(frames,ignore_index=True) #combine two DFs as a DF\n",
    "\n",
    "N_list = len(df_list) #length of the combine Df?\n",
    "print(\"the total number of stations for the analysis is %i\" % N_list)\n",
    "df_list.columns=['stID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read 'time_vector.dat' & Define datenum\n",
    "> Here **`datenum`** will be defined as **df_time_vector.index+1**. \\\n",
    "> This provides consecutive integers that are equivalent to all of the daily time steps within the analysis. \\\n",
    "> These integers serve as time flags, and they will be used in this code for regressions for functions of time. \\\n",
    "> For instance, 2 = 2006-01-02; 3 = 2006-01-03; 5658 = 2021-06-29; ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps before 20060101 and after 20210630 will be ignored\n"
     ]
    }
   ],
   "source": [
    "inputfile = 'time_vector.dat'\n",
    "df_full_time_vector = pd.read_csv(inputfile,header=None)\n",
    "df_full_time_vector.columns=['date']\n",
    "df_full_time_vector['datenum'] = df_full_time_vector.index + 1 #consecutive integers\n",
    "\n",
    "earliest_time=df_full_time_vector.loc[0,['date']]\n",
    "earliest_time=int(earliest_time)\n",
    "lastest_time=df_full_time_vector.iloc[-1,0]\n",
    "lastest_time=int(lastest_time)\n",
    "print(\"steps before %i and after %i will be ignored\" % (earliest_time,lastest_time))\n",
    "\n",
    "\n",
    "full_date_list=df_full_time_vector['date'].tolist() # a list\n",
    "full_date_df=df_full_time_vector['date'] # a df\n",
    "full_datenum_list=df_full_time_vector['datenum'].tolist() # a list\n",
    "full_datenum_df=df_full_time_vector['datenum'] # a df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. READ metadata and separate them into \n",
    ">(1) equipment-related steps : `df_steps_man_made_interest` \\\n",
    ">(2) coseismic steps : `df_steps_earthquakes_interest` \\\n",
    ">This algorithm only deals with **steps within the analysis time** defined in `time_vector.dat`\n",
    "\n",
    "**`This code also finds datenum of steps!`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = \"steps.txt\" #file name\n",
    "df_metadata=pd.read_csv(metadata, header=None, names=list('0123456'), sep=r'(?:,|\\s+)', \\\n",
    "                        comment='#', engine='python')\n",
    "## steps.txt is in an irregular shape\n",
    "## 'names=list('0123456')' is to fill empty spots with NaN \n",
    "\n",
    "df_steps_man_made = df_metadata[df_metadata['2'] == 1]\n",
    "df_steps_man_made = df_steps_man_made[['0', '1', '2', '3']]\n",
    "df_steps_man_made.columns=['stID','time','flag','log'] #time is in yyMMMdd format\n",
    "\n",
    "## date format conversion\n",
    "date_old = df_steps_man_made.time.tolist() # A DataFrame to a list\n",
    "date_new = pd.to_datetime(date_old, format='%y%b%d').strftime('%Y%m%d') # convert date format\n",
    "df_steps_man_made.loc[:,'time'] = date_new # replaces with the new date  in YYYYMMDD\n",
    "df_steps_man_made['time']=df_steps_man_made['time'].astype(int) #str to int\n",
    "\n",
    "\n",
    "df_steps_man_made_interest=df_steps_man_made.loc[(df_steps_man_made['time'] >= earliest_time) & (df_steps_man_made['time'] <= lastest_time)] \n",
    "df_steps_man_made_interest=df_steps_man_made_interest.reset_index(drop=True)\n",
    "\n",
    "## ADD datenum to df_steps_man_made_interest\n",
    "\n",
    "man_time_list=df_steps_man_made_interest.time.tolist()# To list \n",
    "man_time_index=ismember(man_time_list,full_date_list) # Find time index \n",
    "man_new_time_vector = df_full_time_vector.iloc[man_time_index] # Find values corresponding to the time index\n",
    "man_new_time_vector = man_new_time_vector.reset_index(drop=True) # Reset index\n",
    "    \n",
    "df_steps_man_made_interest['datenum']=man_new_time_vector['datenum'] # add equivalent datenum \n",
    "    ## (datenum will be used to match with steps and will be used for inversions)\n",
    "df_steps_man_made_interest=df_steps_man_made_interest[['stID','time','datenum','flag','log']]\n",
    "    ## change column orders    \n",
    "    \n",
    "#----------------------------------------------------------------------------------------------#   \n",
    "\n",
    "################################################################################################     \n",
    "#######################           *v1.0.0.*       ##############################################\n",
    "################################################################################################ \n",
    "###############  This algorithm does NOT correct co-seismic steps.  ############################ \n",
    "###############  But one can modify the code to correct such steps. ############################ \n",
    "###############  Now the coseismic-step data will be just saved as  ############################ \n",
    "###############  in a DataFrame 'df_steps_earthquakes_interest'.    ############################ \n",
    "###############                                                     ############################ \n",
    "###############  You can make a step list made of both equipment-   ############################ \n",
    "###############  related and earthquakes, sort ascending in time,   ############################ \n",
    "###############  and then correct in the order of time later.       ############################ \n",
    "###############  Save step flag {1=man-made; 2=earthquake} together ############################ \n",
    "###############  because you may need two different ways to correct ############################ \n",
    "###############  steps depending on their types!                    ############################ \n",
    "################################################################################################ \n",
    "#######################         J.K. (yy-mm-dd)       ##########################################\n",
    "################################################################################################ \n",
    "\n",
    "## for column names, see the readme file (http://geodesy.unr.edu/NGLStationPages/steps_readme.txt)\n",
    "df_steps_earthquakes = df_metadata[df_metadata['2'] == 2].reset_index(drop=True)\n",
    "df_steps_earthquakes.columns=['stID','time','flag','threshold','distance','mag','eventID'] \n",
    "## time is in yyMMMdd format\n",
    "## date format conversion\n",
    "date_old2 = df_steps_earthquakes.time.tolist() # A DataFrame to a list\n",
    "date_new2 = pd.to_datetime(date_old2, format='%y%b%d').strftime('%Y%m%d') # convert date format\n",
    "df_steps_earthquakes.loc[:,'time'] = date_new2 # replaces with the new date  in YYYYMMDD \n",
    "df_steps_earthquakes['time']=df_steps_earthquakes['time'].astype(int) #str to int\n",
    "\n",
    "df_steps_earthquakes_interest=df_steps_earthquakes.loc[(df_steps_earthquakes['time'] >= earliest_time) & (df_steps_earthquakes['time'] <= lastest_time)] \n",
    "df_steps_earthquakes_interest=df_steps_earthquakes_interest.reset_index(drop=True)\n",
    "\n",
    "## ADD datenum to df_steps_earthquakes_interest\n",
    "EQ_time_list=df_steps_earthquakes_interest.time.tolist()# To list \n",
    "EQ_time_index=ismember(EQ_time_list,full_date_list) # Find time index \n",
    "EQ_new_time_vector = df_full_time_vector.iloc[EQ_time_index] # Find values corresponding to the time index\n",
    "EQ_new_time_vector = EQ_new_time_vector.reset_index(drop=True) # Reset index\n",
    "    \n",
    "df_steps_earthquakes_interest['datenum']=EQ_new_time_vector['datenum'] # add equivalent datenum \n",
    "    ## (datenum will be used to match with steps and will be used for inversions)\n",
    "df_steps_earthquakes_interest=df_steps_earthquakes_interest[['stID','time','datenum','flag','threshold','distance','mag','eventID']]\n",
    "    ## change column orders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correct steps! \n",
    "> (a) Read input data **`edited_i`** \\\n",
    "> (b) Find and add **`datenum`** for the time-axis of the input data \\\n",
    "> (c) Check if the target station has unwanted steps. \n",
    ">> if no, continue the for loop \\\n",
    ">> if yes, keep going \n",
    "\n",
    "> (d) Save datenum for all steps \\\n",
    "> (e) For loop j in range(steps) \\\n",
    "> (f) Corrections! \\\n",
    "> (g) PLOT or NOT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why this makes other values ****.0 ???\n"
     ]
    }
   ],
   "source": [
    "## Correcting the steps!\n",
    "\n",
    "for i in range(21,22): #range(N_list) later\n",
    "    \n",
    "## (a) Read input data 'edited_i'\n",
    "    target_data=\"edited_\"+str(i+1)\n",
    "    df_GPS=pd.read_csv(target_data, header=None, sep=' ')\n",
    "    df_GPS.columns=['time','lon','lat','e','n','z','se','sn','sz','corr_en','flag']\n",
    "    \n",
    "    station=df_list.loc[i,['stID']].to_string(index=False)\n",
    "    SearchSt=station[1:5] # a space in the first byte of the string\n",
    "    #SearchSt is the target station for corrections\n",
    "    \n",
    "## (b) Add datenum for the input data 'edited_i'    \n",
    "    time_list=df_GPS.time.to_list() #to list    \n",
    "    time_index=ismember(time_list,full_date_list) #find time index \n",
    "    \n",
    "    #Check if everything is okay\n",
    "    if len(time_index)-len(df_GPS) != 0:\n",
    "        print(\"something is wrong\")    \n",
    "    new_time_vector =df_full_time_vector.iloc[time_index]\n",
    "    \n",
    "    new_time_vector=new_time_vector.reset_index() # reset index\n",
    "    \n",
    "    df_GPS['datenum']=new_time_vector['datenum'] # add equivalent datenum \n",
    "    #(datenum will be used to match with steps and will be used for inversions)\n",
    "    df_GPS=df_GPS[['time','datenum','lon','lat','e','n','z','se','sn','sz','corr_en','flag']]\n",
    "    #change column orders\n",
    "    \n",
    "    \n",
    "    # Unit [m] to [mm]\n",
    "    df_GPS.e = df_GPS.e*1000\n",
    "    df_GPS.n = df_GPS.n*1000\n",
    "    df_GPS.z = df_GPS.z*1000\n",
    "    df_GPS.se = df_GPS.se*1000\n",
    "    df_GPS.sn = df_GPS.sn*1000\n",
    "    df_GPS.sz = df_GPS.sz*1000\n",
    "    \n",
    "    \n",
    "    \n",
    "## (c) Check is the target station with unwatned step(s) \n",
    "## >> if no, continue the for loop\n",
    "## >> if yes, keep going \n",
    "\n",
    "    itemindex = np.where(df_steps_man_made_interest['stID']==SearchSt) # similar to find() in MATLAB\n",
    "    HowManySteps=itemindex[0].size  # the number of steps\n",
    "    \n",
    "    if HowManySteps==0:        \n",
    "        continue  \n",
    "    else: \n",
    "        event_idx = itemindex[0]\n",
    "## (d) Save datenum for all steps \n",
    "\n",
    "        all_datenum = df_steps_man_made_interest.datenum\n",
    "        event_datenum = all_datenum.iloc[event_idx]\n",
    "        event_datenum = pd.unique(event_datenum) \n",
    "        # In a day, more than a job can be done.\n",
    "        # In this case, the steps.txt saves all the jobs in multiple logs.\n",
    "        # But the date in the logs are the same. \n",
    "        # Here, the code gets rid of all the overlaps\n",
    "        \n",
    "## >> delete position estimates for the day of steps, if there exist.        \n",
    "        \n",
    "        data_datenum = df_GPS.datenum\n",
    "        \n",
    "        IDX_event_data_overlap=ismember(event_datenum,data_datenum) # Find if we have position estimates\n",
    "        cleanedList = [x for x in IDX_event_data_overlap if x == x] # get rid of float('NaN') from the list\n",
    "        if len(cleanedList)!=0:\n",
    "            df_GPS.loc[cleanedList]=np.nan\n",
    "            print(\"why this makes other values ****.0 ???\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        N_events = len(event_datenum) #without the overlaps\n",
    "        \n",
    "## (e) For loop j in range(N_events)\n",
    "        for j in range(N_events):\n",
    "            step_standards=event_datenum[j]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## (f) Obtain before_step and after_step (14 days for each)\n",
    "## > 4 cases. \n",
    "## >> (  i) len(before_step) <  10 and len(after_step) >= 10\n",
    "## >> ( ii) len(before_step) >= 10 and len(after_step) <  10\n",
    "## >> (iii) len(before_step) >= 10 and len(after_step) >= 10\n",
    "## >> ( iv) len(before_step) <  10 and len(after_step) <  10\n",
    "\n",
    "\n",
    "## (g) Plot the time-series and check if the correction works properly. \n",
    "## > Make a plot on and off flag \n",
    "## >> If this code tries to plot 100 time series, it would be very slow to do so ** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_GPS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why this makes other values ****.0 ???\n"
     ]
    }
   ],
   "source": [
    "print(\"why this makes other values ****.0 ???\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
