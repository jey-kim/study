{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<img src=\"Figs/GEOS_Logo.png\" width=\"700\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step **1** of **`G2FNL`**: <font color=blue>\"download_files.ipynb\"</font>\n",
    "#### Aug 18, 2021  <font color=red>(v. still working)</font> \n",
    "##### Jeonghyeop Kim (jeonghyeop.kim@gmail.com) \n",
    "\n",
    "> subfunction: **`?`** \\\n",
    "> input prompts: **`yes`** or **`no`** & **`yes`** or **`no`**\\\n",
    "> input files: **`list_default.dat`** \\\n",
    "> output files: **`steps.txt`**, **`station_list_full.txt`**, and **`coordinate_list_full.dat`**\n",
    "\n",
    "\n",
    "0. This code is a part of G2FNL process (Project1: GNSS to FNL)\n",
    "1. It is required to specify a longitude and latitude boundary (see the first block of this notebook).\n",
    "2. This code will download GNSS position data provided by the Nevada Geodetic Laboratory \n",
    "3. This code will also download metadata for steps (steps.txt), which will be used for corrections.\n",
    "4. **One can choose to download all data (except MAGNET), PBO (old), or NOTA.** \n",
    "5. If one chose to download all data or NOTA only, analyses of the vertical position estimates will be required later.\n",
    "6. Later in this code, the threshold of minimum daily position estimates will be determined. \n",
    " > The minimum number of daily position estimates: \\\n",
    " > if one wants the PBO or NOTA stations, threshold_num = 0 (to include all NOTA stations) \\\n",
    " > Otherwise, threshold_num = 200\n",
    "\n",
    "\n",
    "**`The NGL website is available at:`**  [click here](http://geodesy.unr.edu)\n",
    "\n",
    "> On the right side of the website, find **\"Downloadable Lists of GPS Data Holdings:\"** \\\n",
    "> This algorithm uses data from \"stations with 24 hour sample rate solutions, final orbits, 2 week latency.\" \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Location Boundary\n",
    "lon_min=235.43\n",
    "lon_max=246.99\n",
    "lat_min=31.31\n",
    "lat_max=42.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of all GNSS stations from the NGL \n",
    "url_list=\"http://geodesy.unr.edu/NGLStationPages/DataHoldings.txt\" # URL\n",
    "list_file=\"list_NGL.txt\" # file name. # This file will be removed\n",
    "\n",
    "# metadata for steps from the NGL\n",
    "url_metadata=\"http://geodesy.unr.edu/NGLStationPages/steps.txt\" # URL\n",
    "metadata_file=\"steps.txt\" # file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded metadata for discontinuous steps from the NGL\n"
     ]
    }
   ],
   "source": [
    "# Download the list of GNSS stations (final orbits) and metadata \n",
    "urllib.request.urlretrieve(url_list, list_file)\n",
    "urllib.request.urlretrieve(url_metadata, metadata_file)\n",
    "print(\"Downloaded metadata for discontinuous steps from the NGL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the station list.\n",
    "df_original_list=pd.read_csv(list_file ,header=None, sep=r'(?:,|\\s+)', \n",
    "                comment='#', engine='python',\n",
    "                names=['Sta','lat','lon','3','4','5','6','7','8','9','NumSol','11','12','13'])\n",
    "\n",
    "\n",
    "# Here the first 4 columns will be used.\n",
    "df_four_cols=df_original_list.loc[1:len(df_original_list),['Sta','lat','lon','NumSol']] #first three columns\n",
    "df_four_cols=df_four_cols.reset_index(drop=True)\n",
    "\n",
    "# str to float\n",
    "df_four_cols['lon'] = df_four_cols['lon'].astype(float)\n",
    "df_four_cols['lat'] = df_four_cols['lat'].astype(float)\n",
    "df_four_cols['NumSol'] = df_four_cols['NumSol'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > If you want to include all GNSS stations in California, type 'yes'.\n",
      " >> If you type 'no', only NOTA stations will be downloaded.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " type 'yes' or 'no'  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > You chose to download NOTA stations only.\n",
      " >> Do you want to include some decommissioned PBO stations (~120) in addition to NOTA stations?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " type 'yes' or 'no'  yes\n"
     ]
    }
   ],
   "source": [
    "# While the user input is not either yes or no, this loop will repeat\n",
    "\n",
    "while True:      \n",
    "    print(\" > If you want to include all GNSS stations in California, type 'yes'.\")\n",
    "    print(\" >> If you type 'no', only NOTA stations will be downloaded.\")\n",
    "    YESorNO=input(\" type 'yes' or 'no' \")\n",
    "    YESorNO=YESorNO.lower()\n",
    "    \n",
    "    while YESorNO not in (\"yes\",\"no\"):\n",
    "        print(\"*** Please type 'yes' or 'no' ***\")\n",
    "        YESorNO=input(\" type 'yes' or 'no' \")\n",
    "        YESorNO=YESorNO.lower()\n",
    "        \n",
    "    if YESorNO == \"no\" or YESorNO == \"yes\":\n",
    "        break \n",
    "        #break the while loop\n",
    "         \n",
    "\n",
    "# YES! => all stations (except MAGNET stations) will be downloaded.\n",
    "if YESorNO.startswith('y'): \n",
    "    # Select stations within the region of interest.\n",
    "    # > lon_min,lon_max,lat_min,lat_max must be defined.\n",
    "    \n",
    "    threshold_num=200\n",
    "    df_interest=df_four_cols.loc[(df_four_cols['lat'] >= lat_min)\\\n",
    "                            & (df_four_cols['lat'] <= lat_max)\\\n",
    "                            & (df_four_cols['lon'] >= lon_min)\\\n",
    "                            & (df_four_cols['lon'] <= lon_max)\\\n",
    "                            & (df_four_cols['NumSol'] >= threshold_num)]\n",
    "\n",
    "    df_interest=df_interest.reset_index(drop=True)\n",
    "    \n",
    "    #REMOVE MAGNET STATIONS FROM THE LIST\n",
    "    URL_MAGNET=\"http://geodesy.unr.edu/magnet/Table2web.html\"\n",
    "    df_MAGNET=pd.read_html(URL_MAGNET, header=1, flavor = 'bs4')\n",
    "    df_MAGNET=df_MAGNET[0]\n",
    "    df_MAGNET.columns=['Sta','1','2','3','4','5','6']\n",
    "    df_no_MAGNAT = df_interest[~df_interest['Sta'].isin(df_MAGNET['Sta'])].reset_index(drop=True)\n",
    "    df_final = df_no_MAGNAT\n",
    "    \n",
    "# NO!\n",
    "else: \n",
    "    \n",
    "    threshold_num=0\n",
    "    df_interest=df_four_cols.loc[(df_four_cols['lat'] >= lat_min)\\\n",
    "                            & (df_four_cols['lat'] <= lat_max)\\\n",
    "                            & (df_four_cols['lon'] >= lon_min)\\\n",
    "                            & (df_four_cols['lon'] <= lon_max)\\\n",
    "                            & (df_four_cols['NumSol'] >= threshold_num)]\n",
    "\n",
    "    df_interest=df_interest.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    #NOTA vs PBO?\n",
    "    while True:      \n",
    "        print(\" > You chose to download NOTA stations only.\")\n",
    "        print(\" >> Do you want to include some decommissioned PBO stations (~120) in addition to NOTA stations?\")\n",
    "        YESorNO=input(\" type 'yes' or 'no' \")\n",
    "        YESorNO=YESorNO.lower()\n",
    "    \n",
    "        while YESorNO not in (\"yes\",\"no\"):\n",
    "            print(\"*** Please type 'yes' or 'no' ***\")\n",
    "            YESorNO=input(\" type 'yes' or 'no' \")\n",
    "            YESorNO=YESorNO.lower()\n",
    "        \n",
    "        if YESorNO == \"no\" or YESorNO == \"yes\":\n",
    "            break \n",
    "            #break the while loop\n",
    "    \n",
    "    if YESorNO.startswith('y'): #YES => use PBO\n",
    "        list_default=\"list_default.dat\" # pre-existing PBO stations for California. \n",
    "        df_default=pd.read_csv(list_default, header=None, names=['Sta'])    \n",
    "        df_NOTA = df_interest[df_interest['Sta'].isin(df_default['Sta'])].reset_index(drop=True)\n",
    "        df_final = df_NOTA\n",
    "    else: #NO => use NOTA only! \n",
    "        \n",
    "        url_UNAVCO=\"https://data.unavco.org/archive/gnss/products/position/gage_gps.igs14.txt\"\n",
    "        list_UNAVCO=\"list_UNAVCO.txt\" # LIST is from UNAVCO webpage.\n",
    "        urllib.request.urlretrieve(url_UNAVCO, list_UNAVCO)\n",
    "        df_UNAVCO_list=pd.read_csv(list_UNAVCO , sep=',', \n",
    "                comment='#', engine='python',\n",
    "                names=['Sta','1','2','3','4','5','6','7','8','9','10','11','12','13'])\n",
    "        df_NOTA = df_interest[df_interest['Sta'].isin(df_UNAVCO_list['Sta'])].reset_index(drop=True)\n",
    "        df_final = df_NOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station=df_final.loc[:,['Sta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coor=df_final.loc[:,['lon','lat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE FILES \n",
    "# coordinates and station list\n",
    "df_station.to_csv('station_list_full.dat',header=None, index=None,sep=' ',float_format='%g')\n",
    "df_coor.to_csv('coordinate_list_full.dat',header=None, index=None, sep=' ',float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: list_UNAVCO.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#Remove some unwanted files\n",
    "!rm list_NGL.txt \n",
    "!rm list_UNAVCO.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir archive folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sh downloading shell scripting.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
